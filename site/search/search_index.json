{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"terrain-maker Documentation","text":"<p>Welcome to the terrain-maker documentation. This library makes it easy to create 3D terrain visualizations with Blender from Digital Elevation Model (DEM) data.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li>Install - Set up Python environment</li> <li>Quick Start Tutorial - Get your first terrain in 5 minutes</li> <li>Examples - See it in action with real data</li> <li>API Reference - Detailed method documentation</li> </ol>"},{"location":"#what-is-terrain-maker","title":"What is terrain-maker?","text":"<p>A Python library for:</p> <ul> <li>Loading and processing Digital Elevation Models (SRTM, GeoTIFF, etc.)</li> <li>Applying transforms (downsampling, smoothing, reprojection)</li> <li>Creating custom color mappings</li> <li>Generating 3D terrain meshes for Blender</li> <li>High-quality terrain visualization and rendering</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<p>\u2705 Multi-source DEM loading - SRTM, GeoTIFF, and other formats \u2705 Flexible transform pipeline - Downsample, smooth, reproject, flip \u2705 Advanced color mapping - Elevation, slope, custom functions \u2705 Blender integration - Direct mesh generation with materials \u2705 Smart caching - Hash-based caching for fast reprocessing</p>"},{"location":"#example-real-detroit-terrain","title":"Example: Real Detroit Terrain","text":"<p>The library includes a complete example that demonstrates all key features:</p> <pre><code>from src.terrain.core import (\n    Terrain, load_dem_files,\n    downsample_raster\n)\n\n# Load 110 SRTM tiles covering Detroit\ndem, transform = load_dem_files('/path/to/tiles', pattern='*.hgt')\n\n# Create terrain object\nterrain = Terrain(dem, transform)\n\n# Apply transforms\nterrain.transforms.append(downsample_raster(zoom_factor=0.1))\nterrain.apply_transforms()\n\n# Color by elevation\ndef color_by_elevation(dem):\n    normalized = (dem - dem.min()) / (dem.max() - dem.min() + 1e-8)\n    purple = np.array([0.5, 0, 1, 1])\n    yellow = np.array([1, 1, 0, 1])\n    colors = np.outer(normalized.flat, purple) + np.outer(1-normalized.flat, yellow)\n    return (colors.reshape(dem.shape + (4,)) * 255).astype(np.uint8)\n\nterrain.set_color_mapping(color_by_elevation)\n\n# Generate mesh and render\nmesh = terrain.create_mesh(scale_factor=400, height_scale=0.0035)\n</code></pre>"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li>Install dependencies - Set up Python environment</li> <li>Read API Reference - Understand available methods</li> <li>Explore examples/ - Run provided examples</li> <li>Build your own - Adapt examples for your data</li> </ol>"},{"location":"#common-patterns","title":"Common Patterns","text":""},{"location":"#load-process-visualize","title":"Load, Process, Visualize","text":"<pre><code># Load multiple DEMs and merge\ndem, transform = load_dem_files('/srtm/tiles')\n\n# Create terrain object\nterrain = Terrain(dem, transform)\n\n# Apply transforms in sequence\nterrain.transforms.append(downsample_raster(zoom_factor=0.1))\nterrain.transforms.append(smooth_raster(window_size=5))\nterrain.apply_transforms()\n\n# Set color scheme\nterrain.set_color_mapping(my_color_function)\n\n# Generate mesh\nmesh = terrain.create_mesh()\n</code></pre>"},{"location":"#blender-rendering","title":"Blender Rendering","text":"<pre><code>from src.terrain.core import (\n    clear_scene, setup_camera_and_light,\n    setup_render_settings, create_background_plane\n)\nfrom math import radians\n\n# Clean scene\nclear_scene()\n\n# Configure rendering\nsetup_render_settings(samples=128, use_denoising=True)\n\n# Position camera\ncamera, light = setup_camera_and_light(\n    camera_angle=(radians(63.6), 0, radians(46.7)),\n    camera_location=(7.36, -6.93, 4.96),\n    scale=20\n)\n\n# Add background\nbackground = create_background_plane(mesh)\n\n# Render to file\nimport bpy\nbpy.context.scene.render.filepath = \"/output/terrain.png\"\nbpy.ops.render.render(write_still=True)\n</code></pre>"},{"location":"#architecture","title":"Architecture","text":"<p>Data Pipeline:</p> <pre><code>Raw DEM Files\n    \u2193\nload_dem_files() \u2192 Merged DEM\n    \u2193\nTerrain(dem, transform)\n    \u2193\ntransforms (downsample, smooth, reproject, etc.)\n    \u2193\napply_transforms() \u2192 Transformed DEM\n    \u2193\nset_color_mapping() \u2192 Color function\n    \u2193\ncreate_mesh() \u2192 Blender mesh\n    \u2193\nBlender rendering \u2192 PNG/GLTF/etc.\n</code></pre>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>API_REFERENCE.md</li> <li>Complete reference for all methods</li> <li>Parameter documentation</li> <li>Code examples</li> <li> <p>Performance benchmarks</p> </li> <li> <p>PYTHON_SETUP.md</p> </li> <li>Environment setup</li> <li>Dependency installation</li> <li>Troubleshooting</li> </ul>"},{"location":"#support","title":"Support","text":"<p>For issues or questions:</p> <ol> <li>Check the API Reference for method details</li> <li>Review examples in <code>examples/</code> directory</li> <li>Check existing issues/discussions</li> </ol> <p>Version: 1.0 Last Updated: 2025-11-20</p>"},{"location":"AGENT_PATTERNS/","title":"Claude Code Agent Patterns and Best Practices","text":""},{"location":"AGENT_PATTERNS/#overview","title":"Overview","text":"<p>This guide documents patterns for creating and using Claude Code agents effectively, based on the implementations in this repository.</p>"},{"location":"AGENT_PATTERNS/#core-agent-patterns","title":"Core Agent Patterns","text":""},{"location":"AGENT_PATTERNS/#1-the-analysis-agent-pattern","title":"1. The Analysis Agent Pattern","text":"<p>Purpose: Process large datasets to extract insights and patterns</p> <p>Structure:</p> <pre><code>---\nagent-type: general-purpose\nallowed-tools: [Read, Glob, Grep, Bash, Write]\ndescription: [Specific analysis purpose]\n---\n\n# Agent Name\n\n## Objective\nClear statement of what analysis will be performed\n\n## Task Instructions\n### Phase 1: Data Discovery\n### Phase 2: Analysis\n### Phase 3: Pattern Recognition\n### Phase 4: Report Generation\n\n## Output Format\nSpecific format for results\n\n## Success Criteria\nMeasurable outcomes\n</code></pre> <p>Examples: <code>session-insights</code>, <code>command-analyzer</code></p> <p>When to use: When you need to understand patterns across multiple files or time periods</p>"},{"location":"AGENT_PATTERNS/#2-the-optimization-agent-pattern","title":"2. The Optimization Agent Pattern","text":"<p>Purpose: Identify improvement opportunities and provide actionable recommendations</p> <p>Key characteristics:</p> <ul> <li>Analyzes current state vs optimal state</li> <li>Provides specific, measurable improvements</li> <li>Includes implementation roadmap</li> <li>Quantifies benefits (token savings, time improvements)</li> </ul> <p>Example: <code>command-optimizer</code></p> <p>When to use: When you want to improve efficiency of existing systems</p>"},{"location":"AGENT_PATTERNS/#3-the-audit-agent-pattern","title":"3. The Audit Agent Pattern","text":"<p>Purpose: Systematically check quality and completeness</p> <p>Key characteristics:</p> <ul> <li>Comprehensive checking across multiple dimensions</li> <li>Categorized findings by severity</li> <li>Clear success/failure criteria</li> <li>Actionable remediation steps</li> </ul> <p>Example: <code>documentation-auditor</code></p> <p>When to use: When you need to ensure standards compliance</p>"},{"location":"AGENT_PATTERNS/#4-the-composer-agent-pattern","title":"4. The Composer Agent Pattern","text":"<p>Purpose: Create new artifacts based on analysis and requirements</p> <p>Key characteristics:</p> <ul> <li>Takes high-level goals and creates detailed implementations</li> <li>Combines multiple existing patterns</li> <li>Provides usage examples and documentation</li> <li>Considers integration with existing systems</li> </ul> <p>When to use: When you need to create custom solutions for complex problems</p>"},{"location":"AGENT_PATTERNS/#design-principles","title":"Design Principles","text":""},{"location":"AGENT_PATTERNS/#1-clear-objective-definition","title":"1. Clear Objective Definition","text":"<p>Every agent must have a specific, measurable objective:</p> <pre><code>## Objective\nPerform comprehensive analysis of X to identify Y and provide Z recommendations\n</code></pre> <p>Good: \"Analyze command usage patterns to identify optimization opportunities\" Bad: \"Make commands better\"</p>"},{"location":"AGENT_PATTERNS/#2-phased-execution","title":"2. Phased Execution","text":"<p>Break complex tasks into logical phases:</p> <ol> <li>Discovery Phase: Find and catalog relevant data</li> <li>Analysis Phase: Process data to extract insights</li> <li>Synthesis Phase: Combine insights into recommendations</li> <li>Reporting Phase: Generate actionable outputs</li> </ol>"},{"location":"AGENT_PATTERNS/#3-structured-output","title":"3. Structured Output","text":"<p>Define specific output formats that provide value:</p> <pre><code>## Output Format\nCreate `.claude/agents/reports/[agent-name]-[date].md` with:\n- Executive summary\n- Detailed findings\n- Prioritized recommendations\n- Success metrics\n</code></pre>"},{"location":"AGENT_PATTERNS/#4-error-resilience","title":"4. Error Resilience","text":"<p>Agents should handle incomplete or missing data gracefully:</p> <pre><code>## Error Handling\n- Skip corrupted files but log them\n- Continue analysis with partial data\n- Note ambiguities for manual review\n</code></pre>"},{"location":"AGENT_PATTERNS/#implementation-patterns","title":"Implementation Patterns","text":""},{"location":"AGENT_PATTERNS/#frontmatter-standards","title":"Frontmatter Standards","text":"<pre><code>---\nagent-type: general-purpose | specialized\nallowed-tools: [List of required tools]\ndescription: One-line description of agent purpose\n---\n</code></pre>"},{"location":"AGENT_PATTERNS/#task-instruction-structure","title":"Task Instruction Structure","text":"<ol> <li>Clear phases with specific deliverables</li> <li>Success criteria that are measurable</li> <li>Error handling for common failure modes</li> <li>Integration points with existing tools</li> </ol>"},{"location":"AGENT_PATTERNS/#report-generation","title":"Report Generation","text":"<p>All agents should create structured reports in <code>.claude/agents/reports/</code>:</p> <pre><code>.claude/agents/reports/\n\u251c\u2500\u2500 command-analysis-2025-01-20.md\n\u251c\u2500\u2500 session-insights-2025-01-20.md\n\u251c\u2500\u2500 documentation-audit-2025-01-20.md\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"AGENT_PATTERNS/#agent-categories","title":"Agent Categories","text":""},{"location":"AGENT_PATTERNS/#meta-repository-agents","title":"Meta-Repository Agents","text":"<p>Agents that analyze and improve the repository itself:</p> <ul> <li><code>command-analyzer</code> - Optimizes the command library</li> <li><code>documentation-auditor</code> - Ensures documentation quality</li> <li><code>command-optimizer</code> - Improves command efficiency</li> </ul>"},{"location":"AGENT_PATTERNS/#development-insight-agents","title":"Development Insight Agents","text":"<p>Agents that provide insights about development practices:</p> <ul> <li><code>session-insights</code> - Analyzes development patterns</li> <li>Future: <code>productivity-analyzer</code>, <code>learning-tracker</code></li> </ul>"},{"location":"AGENT_PATTERNS/#usage-patterns","title":"Usage Patterns","text":""},{"location":"AGENT_PATTERNS/#one-time-analysis","title":"One-Time Analysis","text":"<pre><code># Use when you need deep insights infrequently\n\"Use the session-insights agent to analyze my development patterns from Q4\"\n</code></pre>"},{"location":"AGENT_PATTERNS/#periodic-optimization","title":"Periodic Optimization","text":"<pre><code># Use monthly/quarterly for system improvements\n\"Use the command-analyzer agent to identify optimization opportunities\"\n</code></pre>"},{"location":"AGENT_PATTERNS/#quality-assurance","title":"Quality Assurance","text":"<pre><code># Use before releases or major changes\n\"Use the documentation-auditor agent to ensure all docs are complete\"\n</code></pre>"},{"location":"AGENT_PATTERNS/#performance-considerations","title":"Performance Considerations","text":""},{"location":"AGENT_PATTERNS/#token-efficiency","title":"Token Efficiency","text":"<ul> <li>Agents use 200-800 tokens vs 30-100 for commands</li> <li>This is justified for complex analysis that would require many command iterations</li> <li>Use agents when the alternative is multiple manual steps</li> </ul>"},{"location":"AGENT_PATTERNS/#execution-time","title":"Execution Time","text":"<ul> <li>Agents take minutes vs seconds for commands</li> <li>Appropriate for tasks requiring analysis and decision-making</li> <li>Not suitable for routine operations</li> </ul>"},{"location":"AGENT_PATTERNS/#value-proposition","title":"Value Proposition","text":"<ul> <li>High value: Strategic insights, optimization recommendations</li> <li>Medium value: Quality assurance, pattern recognition</li> <li>Low value: Simple data retrieval, routine checks</li> </ul>"},{"location":"AGENT_PATTERNS/#integration-with-commands","title":"Integration with Commands","text":""},{"location":"AGENT_PATTERNS/#complementary-usage","title":"Complementary Usage","text":"<pre><code># Commands execute plans\n/design \"feature-name\"\n/estimate feature medium\n/todo add \"implement core logic\"\n/commit feat \"add feature implementation\"\n</code></pre>"},{"location":"AGENT_PATTERNS/#data-flow","title":"Data Flow","text":"<pre><code>Commands generate data \u2192 Agents analyze data \u2192 Agents provide insights \u2192 Commands act on insights\n</code></pre>"},{"location":"AGENT_PATTERNS/#feedback-loop","title":"Feedback Loop","text":"<ol> <li>Use agents to optimize command library</li> <li>Improved commands generate better data</li> <li>Better data enables more sophisticated agent analysis</li> <li>Cycle continues for continuous improvement</li> </ol>"},{"location":"AGENT_PATTERNS/#best-practices","title":"Best Practices","text":""},{"location":"AGENT_PATTERNS/#when-to-create-new-agents","title":"When to Create New Agents","text":"<p>Create an agent when:</p> <ul> <li>Task requires analysis across multiple files/sessions</li> <li>Decision-making depends on discovered patterns</li> <li>Output varies significantly based on input data</li> <li>One-time or infrequent complex analysis is needed</li> </ul> <p>Don't create an agent for:</p> <ul> <li>Routine, predictable tasks</li> <li>Simple file operations</li> <li>Tasks with standard, unchanging steps</li> </ul>"},{"location":"AGENT_PATTERNS/#agent-naming-conventions","title":"Agent Naming Conventions","text":"<ul> <li>Use descriptive names ending in purpose: <code>session-insights</code>, <code>command-analyzer</code></li> <li>Avoid generic names: <code>analyzer</code>, <code>optimizer</code></li> <li>Be specific about what is being analyzed: <code>documentation-auditor</code></li> </ul>"},{"location":"AGENT_PATTERNS/#documentation-requirements","title":"Documentation Requirements","text":"<p>Every agent needs:</p> <ol> <li>Clear purpose statement</li> <li>When/why to use it vs alternatives</li> <li>Expected input/output examples</li> <li>Integration instructions</li> <li>Performance/cost considerations</li> </ol>"},{"location":"AGENT_PATTERNS/#quality-assurance_1","title":"Quality Assurance","text":"<ul> <li>Test agents with real repository data</li> <li>Validate output formats and usefulness</li> <li>Ensure error handling works correctly</li> <li>Document any limitations or assumptions</li> </ul>"},{"location":"AGENT_PATTERNS/#anti-patterns","title":"Anti-Patterns","text":""},{"location":"AGENT_PATTERNS/#avoid-these-common-mistakes","title":"Avoid These Common Mistakes","text":"<ol> <li> <p>Agent for Simple Tasks <code>bash    # Bad: Agent to check git status    # Good: Command /hygiene includes git status</code></p> </li> <li> <p>Overly Generic Agents <code>bash    # Bad: \"general-analyzer\" that does everything    # Good: Specific agents for specific analysis types</code></p> </li> <li> <p>Agents that Don't Generate Value <code>bash    # Bad: Agent that just lists files    # Good: Agent that analyzes patterns in files</code></p> </li> <li> <p>Missing Success Criteria <code>markdown    # Bad: \"Analyze the codebase\"    # Good: \"Identify 3+ optimization opportunities with quantified benefits\"</code></p> </li> </ol>"},{"location":"AGENT_PATTERNS/#future-patterns","title":"Future Patterns","text":""},{"location":"AGENT_PATTERNS/#emerging-patterns","title":"Emerging Patterns","text":"<p>As agent usage grows, watch for these emerging patterns:</p> <ol> <li>Collaborative Agents: Agents that use outputs from other agents</li> <li>Incremental Agents: Agents that update previous analysis</li> <li>Predictive Agents: Agents that forecast based on patterns</li> <li>Learning Agents: Agents that improve recommendations over time</li> </ol>"},{"location":"AGENT_PATTERNS/#extension-points","title":"Extension Points","text":"<p>The current architecture supports:</p> <ul> <li>Custom report formats</li> <li>Integration with external tools</li> <li>Chained agent execution</li> <li>Conditional agent triggering</li> </ul>"},{"location":"AGENT_PATTERNS/#conclusion","title":"Conclusion","text":"<p>Agents provide powerful analysis capabilities that complement the routine efficiency of commands. Use this pattern guide to create agents that deliver real value through intelligent analysis and actionable insights.</p> <p>Remember: Commands for routine execution, agents for intelligent analysis.</p>"},{"location":"API_REFERENCE/","title":"terrain-maker API Reference","text":"<p>Comprehensive documentation of all classes and functions in the terrain-maker library.</p> <p>Auto-generated from source code docstrings.</p>"},{"location":"API_REFERENCE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>terrain.core</li> <li>terrain.water</li> </ul>"},{"location":"API_REFERENCE/#terraincore","title":"terrain.core","text":""},{"location":"API_REFERENCE/#classes","title":"Classes","text":""},{"location":"API_REFERENCE/#terrain","title":"<code>Terrain</code>","text":"<p>Core class for managing Digital Elevation Model (DEM) data and terrain operations.</p> <p>Handles loading, transforming, and visualizing terrain data from raster sources. Supports coordinate reprojection, downsampling, color mapping, and 3D mesh generation for Blender visualization. Uses efficient caching to avoid recomputation of transforms.</p> <p>Attributes:     dem_shape (tuple): Shape of DEM array as (height, width).     dem_transform (rasterio.Affine): Affine transform for geographic coordinates.     data_layers (dict): Dictionary of data layers (DEM, overlays, derived data).     transforms (list): List of transform functions to apply.     vertices (np.ndarray): Vertex positions for generated mesh.     vertex_colors (np.ndarray): RGBA colors for mesh vertices.</p> <p>Examples:     &gt;&gt;&gt; dem_data = np.random.rand(100, 100) * 1000     &gt;&gt;&gt; transform = rasterio.Affine.identity()     &gt;&gt;&gt; terrain = Terrain(dem_data, transform, dem_crs='EPSG:4326')     &gt;&gt;&gt; terrain.apply_transforms()     &gt;&gt;&gt; mesh = terrain.create_mesh(scale_factor=100.0)</p> <p>Methods:</p> <ul> <li> <p><code>add_data_layer(self, name, data, transform, crs, target_crs, target_layer, resampling)</code> - Add a data layer, optionally reprojecting to match another layer.</p> </li> <li> <p><code>add_transform(self, transform_func)</code> - Add a transform function to the processing pipeline.</p> </li> <li> <p><code>apply_transforms(self, cache)</code> - Apply all transforms to all data layers with optional caching.</p> </li> <li> <p><code>compute_colors(self)</code> - Compute colors using color_func and optionally mask_func.</p> </li> <li> <p><code>compute_data_layer(self, name, source_layer, compute_func, transformed, cache_key)</code> - Compute a new data layer from an existing one using a transformation function.</p> </li> <li> <p><code>configure_for_target_vertices(self, target_vertices, order)</code> - Configure downsampling to achieve approximately target_vertices.</p> </li> <li> <p><code>create_mesh(self, base_depth, boundary_extension, scale_factor, height_scale, center_model, verbose)</code> - Create a Blender mesh from transformed DEM data with both performance and control.</p> </li> <li> <p><code>set_color_mapping(self, color_func, source_layers, color_kwargs, mask_func, mask_layers, mask_kwargs, mask_threshold)</code> - Set up how to map data layers to colors (RGB) and optionally a mask/alpha channel.</p> </li> <li> <p><code>visualize_dem(self, layer, use_transformed, title, cmap, percentile_clip, clip_percentiles, max_pixels, show_histogram)</code> - Create diagnostic visualization of any terrain data layer.</p> </li> </ul>"},{"location":"API_REFERENCE/#terraincache","title":"<code>TerrainCache</code>","text":"<p>Cache manager for terrain data processing results.</p> <p>Handles persistent storage and retrieval of transformed terrain data layers as GeoTIFF files with geographic metadata. Supports loading and saving with coordinate reference system (CRS) and custom metadata.</p> <p>Attributes:     cache_dir (Path): Root directory for cached GeoTIFF files.     logger (logging.Logger): Logger instance for cache operations.</p> <p>Examples:     &gt;&gt;&gt; cache = TerrainCache('my_cache_dir')     &gt;&gt;&gt; cache.save('dem_transformed', dem_array, transform, 'EPSG:32617')     &gt;&gt;&gt; data, transform, crs = cache.load('dem_transformed')</p> <p>Methods:</p> <ul> <li> <p><code>exists(self, target_name)</code> - Check if target exists</p> </li> <li> <p><code>get_target_path(self, target_name)</code> - Get path for a specific target</p> </li> <li> <p><code>load(self, target_name)</code> - Load GeoTIFF and metadata if it exists</p> </li> <li> <p><code>save(self, target_name, data, transform, crs, metadata)</code> - Save data as GeoTIFF with CRS and metadata</p> </li> </ul>"},{"location":"API_REFERENCE/#functions","title":"Functions","text":""},{"location":"API_REFERENCE/#add_data_layerself-name-data-transform-crs-target_crs-target_layer-resampling","title":"<code>add_data_layer(self, name, data, transform, crs, target_crs, target_layer, resampling)</code>","text":"<p>Add a data layer, optionally reprojecting to match another layer.</p> <p>Stores data with geographic metadata (CRS and transform). Can automatically reproject and resample to match an existing layer's grid for multi-layer analysis.</p> <p>Args:     name (str): Unique name for this data layer (e.g., 'dem', 'elevation', 'slope').     data (np.ndarray): 2D array of data values, shape (height, width).     transform (rasterio.Affine): Affine transform mapping pixel to geographic coords.     crs (str): Coordinate reference system in EPSG format (e.g., 'EPSG:4326').     target_crs (str, optional): Target CRS to reproject to. If None and target_layer         specified, uses target layer's CRS. If None and no target, uses input crs.     target_layer (str, optional): Name of existing layer to match grid and CRS.         If specified, data is automatically reprojected and resampled to align.     resampling (rasterio.enums.Resampling): Resampling method for reprojection         (default: Resampling.bilinear). See rasterio docs for options.</p> <p>Returns:     None: Modifies internal data_layers dictionary.</p> <p>Raises:     KeyError: If target_layer specified but doesn't exist.     ValueError: If target_crs specified but no reference layer available.</p> <p>Examples:     &gt;&gt;&gt; # Add elevation data with native CRS     &gt;&gt;&gt; terrain.add_data_layer('dem', dem_array, transform, 'EPSG:4326')</p> <pre><code>&gt;&gt;&gt; # Add overlay data, reproject to match DEM\n&gt;&gt;&gt; terrain.add_data_layer('landcover', lc_array, lc_transform, 'EPSG:3857',\n...                        target_layer='dem')\n\n&gt;&gt;&gt; # Use nearest-neighbor for categorical data\n&gt;&gt;&gt; terrain.add_data_layer('zones', zone_array, zone_transform, 'EPSG:4326',\n...                        target_layer='dem', resampling=Resampling.nearest)\n</code></pre>"},{"location":"API_REFERENCE/#add_transformself-transform_func","title":"<code>add_transform(self, transform_func)</code>","text":"<p>Add a transform function to the processing pipeline.</p> <p>Args:     transform_func (callable): Function that transforms DEM data. Should accept         (dem_array: np.ndarray) and return transformed np.ndarray.</p> <p>Returns:     None: Modifies internal transforms list in place.</p> <p>Examples:     &gt;&gt;&gt; terrain.add_transform(lambda dem: gaussian_filter(dem, sigma=2))     &gt;&gt;&gt; terrain.apply_transforms()</p>"},{"location":"API_REFERENCE/#apply_colormap_materialmaterial","title":"<code>apply_colormap_material(material)</code>","text":"<p>Create a simple material setup for terrain visualization using vertex colors. Uses emission to guarantee colors are visible regardless of lighting.</p> <p>Args:     material: Blender material to configure</p>"},{"location":"API_REFERENCE/#apply_transformsself-cache","title":"<code>apply_transforms(self, cache)</code>","text":"<p>Apply all transforms to all data layers with optional caching.</p> <p>Processes each data layer through the transform pipeline. Results are cached to avoid recomputation. Transforms are applied in order.</p> <p>Args:     cache (bool): Whether to cache results (default: False).</p> <p>Returns:     None: Updates internal data_layers with 'transformed_data' for each layer.</p> <p>Examples:     &gt;&gt;&gt; terrain.add_transform(flip_raster(axis='horizontal'))     &gt;&gt;&gt; terrain.apply_transforms(cache=True)     &gt;&gt;&gt; dem_data = terrain.data_layers['dem']['transformed_data']</p>"},{"location":"API_REFERENCE/#clear_scene","title":"<code>clear_scene()</code>","text":"<p>Clear all objects from the Blender scene.</p> <p>Resets the scene to factory settings (empty scene) and removes all default objects. Useful before importing terrain meshes to ensure a clean workspace.</p> <p>Raises:     RuntimeError: If Blender module (bpy) is not available.</p>"},{"location":"API_REFERENCE/#compute_colorsself","title":"<code>compute_colors(self)</code>","text":"<p>Compute colors using color_func and optionally mask_func.</p> <p>Returns:     np.ndarray: RGBA color array.</p>"},{"location":"API_REFERENCE/#compute_data_layerself-name-source_layer-compute_func-transformed-cache_key","title":"<code>compute_data_layer(self, name, source_layer, compute_func, transformed, cache_key)</code>","text":"<p>Compute a new data layer from an existing one using a transformation function.</p> <p>Allows creating derived layers (e.g., slope, aspect, hillshade) from existing data. Results are stored as new layer and optionally cached.</p> <p>Args:     name (str): Name for the computed layer.     source_layer (str): Name of existing source layer to compute from.     compute_func (Callable): Function that accepts source array (np.ndarray)         and returns computed array (np.ndarray). Can return same or different shape.     transformed (bool): If True, use already-transformed source data; if False,         use original source data (default: False).     cache_key (str, optional): Custom cache identifier. If None, auto-generated         from layer name and function name.</p> <p>Returns:     np.ndarray: The computed layer data array.</p> <p>Raises:     KeyError: If source_layer doesn't exist.     ValueError: If transformed=True but source hasn't been transformed.</p> <p>Examples:     &gt;&gt;&gt; # Compute slope from DEM using scipy     &gt;&gt;&gt; from scipy.ndimage import sobel     &gt;&gt;&gt; slope = terrain.compute_data_layer(     ...     'slope', 'dem',     ...     lambda dem: np.sqrt(sobel(dem, axis=0)2 + sobel(dem, axis=1)2)     ... )</p> <pre><code>&gt;&gt;&gt; # Compute hill-shade visualization\n&gt;&gt;&gt; from scipy.ndimage import gaussian_filter\n&gt;&gt;&gt; hillshade = terrain.compute_data_layer(\n...     'hillshade', 'dem',\n...     lambda dem: np.clip(gaussian_filter(dem, 2) * 0.5, 0, 1)\n... )\n\n&gt;&gt;&gt; # Compute from transformed (downsampled) data\n&gt;&gt;&gt; downsampled_slope = terrain.compute_data_layer(\n...     'slope_downsampled', 'dem',\n...     lambda dem: np.gradient(dem)[0],\n...     transformed=True\n... )\n</code></pre>"},{"location":"API_REFERENCE/#configure_for_target_verticesself-target_vertices-order","title":"<code>configure_for_target_vertices(self, target_vertices, order)</code>","text":"<p>Configure downsampling to achieve approximately target_vertices.</p> <p>This method calculates the appropriate zoom_factor to achieve a desired vertex count for mesh generation. It provides a more intuitive API than manually calculating zoom_factor from the original DEM shape.</p> <p>Args:     target_vertices: Desired vertex count for final mesh (e.g., 500_000)     order: Interpolation order for downsampling (0=nearest, 1=linear, 4=bicubic)</p> <p>Returns:     Calculated zoom_factor that was added to transforms</p> <p>Raises:     ValueError: If target_vertices is invalid</p> <p>Example:     terrain = Terrain(dem, transform)     zoom = terrain.configure_for_target_vertices(500_000)     print(f\"Calculated zoom_factor: {zoom:.4f}\")     terrain.apply_transforms()     mesh = terrain.create_mesh(scale_factor=400.0)</p>"},{"location":"API_REFERENCE/#create_background_planeterrain_obj-depth-scale_factor-material_params","title":"<code>create_background_plane(terrain_obj, depth, scale_factor, material_params)</code>","text":"<p>Create a large emissive plane beneath the terrain for background illumination.</p> <p>Args:     terrain_obj: The terrain Blender object used for size reference     depth: Z-coordinate for the plane position     scale_factor: Scale multiplier for plane size relative to terrain     material_params: Optional dict to override default material parameters</p> <p>Returns:     bpy.types.Object: The created background plane object</p> <p>Raises:     ValueError: If terrain_obj is None or has invalid bounds     RuntimeError: If mesh or material creation fails</p>"},{"location":"API_REFERENCE/#create_meshself-base_depth-boundary_extension-scale_factor-height_scale-center_model-verbose","title":"<code>create_mesh(self, base_depth, boundary_extension, scale_factor, height_scale, center_model, verbose)</code>","text":"<p>Create a Blender mesh from transformed DEM data with both performance and control.</p> <p>Generates vertices from DEM elevation values and faces for connectivity. Optionally creates boundary faces to close the mesh into a solid. Supports coordinate scaling and elevation scaling for visualization.</p> <p>Args:     base_depth (float): Z-coordinate for the bottom of the terrain model (default: -0.2).         Used when boundary_extension=True to create side faces.     boundary_extension (bool): Whether to create side faces around the terrain boundary         to close the mesh (default: True). If False, creates open terrain surface.     scale_factor (float): Horizontal scale divisor for x/y coordinates (default: 100.0).         Higher values produce smaller meshes. E.g., 100 means 100 DEM units = 1 Blender unit.     height_scale (float): Multiplier for elevation values (default: 1.0). Vertically         exaggerates or reduces terrain features. Values &gt; 1 exaggerate, &lt; 1 flatten.     center_model (bool): Whether to center the model at origin (default: True).         Centers XY coordinates but preserves absolute Z elevation values.     verbose (bool): Whether to log detailed progress information (default: True).</p> <p>Returns:     bpy.types.Object | None: The created terrain mesh object, or None if creation failed.</p> <p>Raises:     ValueError: If transformed DEM layer is not available (apply_transforms() not called).</p>"},{"location":"API_REFERENCE/#downsample_rasterzoom_factor-order-nodata_value","title":"<code>downsample_raster(zoom_factor, order, nodata_value)</code>","text":"<p>Create a raster downsampling transform function with specified parameters.</p> <p>Args:     zoom_factor: Scaling factor for downsampling (default: 0.1)     order: Interpolation order (default: 4)     nodata_value: Value to treat as no data (default: np.nan)</p> <p>Returns:     function: A transform function that downsamples raster data</p>"},{"location":"API_REFERENCE/#elevation_colormapdem_data-cmap_name-min_elev-max_elev","title":"<code>elevation_colormap(dem_data, cmap_name, min_elev, max_elev)</code>","text":"<p>Create a colormap based on elevation values.</p> <p>Maps elevation data to colors using a matplotlib colormap. Low elevations map to the start of the colormap, high elevations to the end.</p> <p>Args:     dem_data: 2D numpy array of elevation values     cmap_name: Matplotlib colormap name (default: 'viridis')     min_elev: Minimum elevation for normalization (default: use data min)     max_elev: Maximum elevation for normalization (default: use data max)</p> <p>Returns:     Array of RGB colors with shape (height, width, 3) as uint8</p>"},{"location":"API_REFERENCE/#existsself-target_name","title":"<code>exists(self, target_name)</code>","text":"<p>Check if target exists</p>"},{"location":"API_REFERENCE/#flip_rasteraxis","title":"<code>flip_raster(axis)</code>","text":"<p>Create a transform function that mirrors (flips) the DEM data. If axis='horizontal', it flips top \u2194 bottom. (In terms of rows, row=0 becomes row=(height-1).)</p> <p>If axis='vertical', you could do left \u2194 right (np.fliplr).</p>"},{"location":"API_REFERENCE/#get_target_pathself-target_name","title":"<code>get_target_path(self, target_name)</code>","text":"<p>Get path for a specific target</p>"},{"location":"API_REFERENCE/#loadself-target_name","title":"<code>load(self, target_name)</code>","text":"<p>Load GeoTIFF and metadata if it exists</p>"},{"location":"API_REFERENCE/#load_dem_filesdirectory_path-pattern-recursive","title":"<code>load_dem_files(directory_path, pattern, recursive)</code>","text":"<p>Load and merge DEM files from a directory into a single elevation dataset. Supports any raster format readable by rasterio (HGT, GeoTIFF, etc.).</p> <p>Args:     directory_path: Path to directory containing DEM files     pattern: File pattern to match (default: \"*.hgt\")     recursive: Whether to search subdirectories recursively (default: False)</p> <p>Returns:     tuple: (merged_dem, transform) where:         - merged_dem: numpy array containing the merged elevation data         - transform: affine transform mapping pixel to geographic coordinates</p> <p>Raises:     ValueError: If no valid DEM files are found or directory doesn't exist     OSError: If directory access fails or file reading fails     rasterio.errors.RasterioIOError: If there are issues reading the DEM files</p>"},{"location":"API_REFERENCE/#position_camera_relativemesh_obj-direction-distance-elevation-look_at-camera_type-sun_angle-sun_energy-focal_length","title":"<code>position_camera_relative(mesh_obj, direction, distance, elevation, look_at, camera_type, sun_angle, sun_energy, focal_length)</code>","text":"<p>Position camera relative to mesh using intuitive cardinal directions.</p> <p>Simplifies camera positioning by using natural directions (north, south, etc.) instead of absolute Blender coordinates. The camera is automatically positioned relative to the mesh bounds and rotated to point at the mesh center.</p> <p>Args:     mesh_obj: Blender mesh object to position camera relative to     direction: Cardinal direction - one of:         'north', 'south', 'east', 'west' (horizontal directions)         'northeast', 'northwest', 'southeast', 'southwest' (diagonals)         'above' (directly overhead)         Default: 'south'     distance: Distance multiplier relative to mesh diagonal         (e.g., 1.5 means 1.5x mesh_diagonal away). Default: 1.5     elevation: Height as fraction of mesh diagonal added to Z position         (0.0 = ground level, 1.0 = mesh_diagonal above ground). Default: 0.5     look_at: Where camera points - 'center' to point at mesh center,         or tuple (x, y, z) for custom target. Default: 'center'     camera_type: 'ORTHO' (orthographic) or 'PERSP' (perspective). Default: 'ORTHO'     sun_angle: Angle of sun light in degrees. Default: 2     sun_energy: Intensity of sun light. Default: 3     focal_length: Camera focal length in mm (perspective cameras only). Default: 50</p> <p>Returns:     Camera object</p> <p>Raises:     ValueError: If direction is not recognized or camera_type is invalid</p>"},{"location":"API_REFERENCE/#render_scene_to_fileoutput_path-width-height-file_format-color_mode-compression-save_blend_file","title":"<code>render_scene_to_file(output_path, width, height, file_format, color_mode, compression, save_blend_file)</code>","text":"<p>Render the current Blender scene to file.</p> <p>Args:     output_path (str or Path): Path where output file will be saved     width (int): Render width in pixels (default: 1920)     height (int): Render height in pixels (default: 1440)     file_format (str): Output format 'PNG', 'JPEG', etc. (default: 'PNG')     color_mode (str): 'RGBA' or 'RGB' (default: 'RGBA')     compression (int): PNG compression level 0-100 (default: 90)     save_blend_file (bool): Also save .blend project file (default: True)</p> <p>Returns:     Path: Path to rendered file if successful, None otherwise</p>"},{"location":"API_REFERENCE/#reproject_rastersrc_crs-dst_crs-nodata_value-num_threads","title":"<code>reproject_raster(src_crs, dst_crs, nodata_value, num_threads)</code>","text":"<p>Generalized raster reprojection function</p> <p>Args:     src_crs: Source coordinate reference system     dst_crs: Destination coordinate reference system     nodata_value: Value to use for areas outside original data     num_threads: Number of threads for parallel processing</p> <p>Returns:     Function that transforms data and returns (data, transform, new_crs)</p>"},{"location":"API_REFERENCE/#sample_arrayarr","title":"<code>sample_array(arr)</code>","text":"<p>Downsample array for visualization if it exceeds max_pixels limit.</p>"},{"location":"API_REFERENCE/#saveself-target_name-data-transform-crs-metadata","title":"<code>save(self, target_name, data, transform, crs, metadata)</code>","text":"<p>Save data as GeoTIFF with CRS and metadata</p>"},{"location":"API_REFERENCE/#scale_elevationscale_factor-nodata_value","title":"<code>scale_elevation(scale_factor, nodata_value)</code>","text":"<p>Create a raster elevation scaling transform function.</p> <p>Multiplies all elevation values by the scale factor. Useful for reducing or amplifying terrain height without changing horizontal scale.</p> <p>Args:     scale_factor (float): Multiplication factor for elevation values (default: 1.0)     nodata_value: Value to treat as no data (default: np.nan)</p> <p>Returns:     function: A transform function that scales elevation data</p>"},{"location":"API_REFERENCE/#set_color_mappingself-color_func-source_layers-color_kwargs-mask_func-mask_layers-mask_kwargs-mask_threshold","title":"<code>set_color_mapping(self, color_func, source_layers, color_kwargs, mask_func, mask_layers, mask_kwargs, mask_threshold)</code>","text":"<p>Set up how to map data layers to colors (RGB) and optionally a mask/alpha channel.</p> <p>Allows flexible color mapping by applying a function to one or more data layers. Optionally applies a separate mask function for transparency/alpha channel control. Color mapping is applied during mesh creation with <code>compute_colors()</code>.</p> <p>Args:     color_func (Callable): Function that accepts N data arrays (one per source_layers)         and returns colored array of shape (H, W, 3) for RGB or (H, W, 4) for RGBA.         Values should be in range [0, 1] for 8-bit output.     source_layers (list[str]): Names of data layers to pass to color_func, in order.         E.g., ['dem'] for single layer or ['red', 'green', 'blue'] for composite.     color_kwargs (dict, optional): Additional keyword arguments passed to color_func.     mask_func (Callable, optional): Function producing alpha/mask values (0-1) for         transparency. Takes layer arrays as input. If omitted, fully opaque.     mask_layers (list[str] | str, optional): Layer names for mask_func. If None,         uses source_layers. Single string converted to list.     mask_kwargs (dict, optional): Additional keyword arguments for mask_func.     mask_threshold (float, optional): If mask_func is threshold-based, convenience         parameter for threshold value (implementation-dependent).</p> <p>Returns:     None: Modifies internal color mapping configuration.</p> <p>Raises:     ValueError: If source_layers or mask_layers refer to non-existent layers.</p> <p>Examples:     &gt;&gt;&gt; # Single-layer elevation with viridis colormap     &gt;&gt;&gt; from matplotlib.cm import viridis     &gt;&gt;&gt; terrain.set_color_mapping(     ...     lambda dem: viridis(dem / dem.max()),     ...     ['dem']     ... )</p> <pre><code>&gt;&gt;&gt; # RGB composite from three layers\n&gt;&gt;&gt; terrain.set_color_mapping(\n...     lambda r, g, b: np.stack([r, g, b], axis=-1),\n...     ['red_band', 'green_band', 'blue_band']\n... )\n\n&gt;&gt;&gt; # Elevation with water transparency mask\n&gt;&gt;&gt; terrain.set_color_mapping(\n...     lambda dem: elevation_colormap(dem),\n...     ['dem'],\n...     mask_func=lambda dem: (dem &gt; 0).astype(float),\n...     mask_layers=['dem']\n... )\n\n&gt;&gt;&gt; # Hillshade with elevation colors and slope transparency\n&gt;&gt;&gt; terrain.set_color_mapping(\n...     lambda dem: dem_colors,\n...     ['dem'],\n...     mask_func=lambda dem: 1 - np.clip(np.gradient(dem)[0], 0, 1),\n...     mask_layers=['dem']\n... )\n</code></pre>"},{"location":"API_REFERENCE/#setup_cameracamera_angle-camera_location-scale-focal_length-camera_type","title":"<code>setup_camera(camera_angle, camera_location, scale, focal_length, camera_type)</code>","text":"<p>Configure camera for terrain visualization.</p> <p>Args:     camera_angle: Tuple of (x,y,z) rotation angles in radians     camera_location: Tuple of (x,y,z) camera position     scale: Camera scale value (ortho_scale for orthographic cameras)     focal_length: Camera focal length in mm (default: 50, used only for perspective)     camera_type: Camera type 'PERSP' (perspective) or 'ORTHO' (orthographic) (default: 'PERSP')</p> <p>Returns:     Camera object</p> <p>Raises:     ValueError: If camera_type is not 'PERSP' or 'ORTHO'</p>"},{"location":"API_REFERENCE/#setup_camera_and_lightcamera_angle-camera_location-scale-sun_angle-sun_energy-focal_length-camera_type","title":"<code>setup_camera_and_light(camera_angle, camera_location, scale, sun_angle, sun_energy, focal_length, camera_type)</code>","text":"<p>Configure camera and main light for terrain visualization.</p> <p>Convenience function that calls setup_camera() and setup_light().</p> <p>Args:     camera_angle: Tuple of (x,y,z) rotation angles in radians     camera_location: Tuple of (x,y,z) camera position     scale: Camera scale value (ortho_scale for orthographic cameras)     sun_angle: Angle of sun light in degrees (default: 2)     sun_energy: Energy/intensity of sun light (default: 3)     focal_length: Camera focal length in mm (default: 50, used only for perspective)     camera_type: Camera type 'PERSP' (perspective) or 'ORTHO' (orthographic) (default: 'PERSP')</p> <p>Returns:     tuple: (camera object, sun light object)</p>"},{"location":"API_REFERENCE/#setup_lightlocation-angle-energy-rotation_euler","title":"<code>setup_light(location, angle, energy, rotation_euler)</code>","text":"<p>Create and configure sun light for terrain visualization.</p> <p>Args:     location: Tuple of (x,y,z) light position (default: (1, 1, 2))     angle: Angle of sun light in degrees (default: 2)     energy: Energy/intensity of sun light (default: 3)     rotation_euler: Tuple of (x,y,z) rotation angles in radians (default: sun from NW)</p> <p>Returns:     Sun light object</p>"},{"location":"API_REFERENCE/#setup_render_settingsuse_gpu-samples-preview_samples-use_denoising-denoiser-compute_device","title":"<code>setup_render_settings(use_gpu, samples, preview_samples, use_denoising, denoiser, compute_device)</code>","text":"<p>Configure Blender render settings for high-quality terrain visualization.</p> <p>Args:     use_gpu: Whether to use GPU acceleration     samples: Number of render samples     preview_samples: Number of viewport preview samples     use_denoising: Whether to enable denoising     denoiser: Type of denoiser to use ('OPTIX', 'OPENIMAGEDENOISE', 'NLM')     compute_device: Compute device type ('OPTIX', 'CUDA', 'HIP', 'METAL')</p>"},{"location":"API_REFERENCE/#setup_world_atmospheredensity-scatter_color-anisotropy","title":"<code>setup_world_atmosphere(density, scatter_color, anisotropy)</code>","text":"<p>Set up world volume for atmospheric effects.</p> <p>Args:     density: Density of the atmospheric volume (default: 0.02)     scatter_color: RGBA color tuple for scatter (default: white)     anisotropy: Direction of scatter from -1 to 1 (default: 0 for uniform)</p> <p>Returns:     bpy.types.World: The configured world object</p>"},{"location":"API_REFERENCE/#slope_colormapslopes-cmap_name-min_slope-max_slope","title":"<code>slope_colormap(slopes, cmap_name, min_slope, max_slope)</code>","text":"<p>Create a simple colormap based solely on terrain slopes.</p> <p>Args:     slopes: Array of slope values in degrees     cmap_name: Matplotlib colormap name (default: 'terrain')     min_slope: Minimum slope value for normalization (default: 0)     max_slope: Maximum slope value for normalization (default: 45)</p> <p>Returns:     Array of RGBA colors with shape (*slopes.shape, 4)</p>"},{"location":"API_REFERENCE/#smooth_rasterwindow_size-nodata_value","title":"<code>smooth_raster(window_size, nodata_value)</code>","text":"<p>Create a raster smoothing transform function with specified parameters.</p> <p>Args:     window_size: Size of median filter window                  (defaults to 5% of smallest dimension if None)     nodata_value: Value to treat as no data (default: np.nan)</p> <p>Returns:     function: A transform function that smooths raster data</p>"},{"location":"API_REFERENCE/#transformraster_data-transform","title":"<code>transform(raster_data, transform)</code>","text":"<p>Scale elevation values in raster data.</p> <p>Args:     raster_data: Input raster numpy array     transform: Optional affine transform (unchanged by scaling)</p> <p>Returns:     tuple: (scaled_data, transform, None)</p>"},{"location":"API_REFERENCE/#transform_funcdata-transform","title":"<code>transform_func(data, transform)</code>","text":"<p>Flip array along specified axis and update transform if provided.</p>"},{"location":"API_REFERENCE/#transform_wrappertransform_func","title":"<code>transform_wrapper(transform_func)</code>","text":"<p>Standardize transform function interface with consistent output</p> <p>Args:     transform_func: The original transform function to wrap</p> <p>Returns:     A wrapped function with consistent signature and return format</p>"},{"location":"API_REFERENCE/#visualize_demself-layer-use_transformed-title-cmap-percentile_clip-clip_percentiles-max_pixels-show_histogram","title":"<code>visualize_dem(self, layer, use_transformed, title, cmap, percentile_clip, clip_percentiles, max_pixels, show_histogram)</code>","text":"<p>Create diagnostic visualization of any terrain data layer.</p> <p>Args:     layer: Name of data layer to visualize (default: 'dem')     use_transformed: Whether to use transformed or original data (default: False)     title: Plot title (default: auto-generated based on layer)     cmap: Matplotlib colormap     percentile_clip: Whether to clip extreme values     clip_percentiles: Tuple of (min, max) percentiles to clip (default: (1, 99))     max_pixels: Maximum number of pixels for subsampling     show_histogram: Whether to show the histogram panel (default: True)</p>"},{"location":"API_REFERENCE/#wrapped_transformdata-transform","title":"<code>wrapped_transform(data, transform)</code>","text":"<p>Standardized transform wrapper with consistent signature</p> <p>Args:     data: Input numpy array to transform     transform: Optional affine transform </p> <p>Returns:     Tuple of (transformed_data, transform, [crs]) where CRS is optional</p>"},{"location":"API_REFERENCE/#terrainwater","title":"terrain.water","text":"<p>Water body detection and identification from elevation data.</p> <p>Provides functions to identify water bodies from Digital Elevation Model (DEM) data using slope-based analysis. Water bodies are characterized by flat surfaces with very low slope values, while terrain typically exhibits higher slope magnitudes.</p>"},{"location":"API_REFERENCE/#functions_1","title":"Functions","text":""},{"location":"API_REFERENCE/#identify_water_by_slopedem_data-slope_threshold01-fill_holestrue","title":"<code>identify_water_by_slope(dem_data, slope_threshold=0.1, fill_holes=True)</code>","text":"<p>Identify water bodies by detecting flat areas (low slope) using Horn's method.</p> <p>Water bodies typically have very flat surfaces with near-zero slope, while terrain has measurable slopes. This function calculates local slope magnitude using Horn's method and identifies pixels below the threshold as potential water. Optionally applies morphological operations to fill small gaps and smooth the water mask.</p> <p>Args: - <code>dem_data</code> (np.ndarray): Digital elevation model as 2D array (height values) - <code>slope_threshold</code> (float): Maximum slope magnitude to classify as water. Default: 0.1   - Typical range: 0.05 to 0.5 depending on DEM resolution and terrain characteristics   - Values represent gradient magnitude from Horn's method (not degrees)   - Lower thresholds identify only the flattest areas as water   - Higher thresholds are more lenient and identify more pixels as water - <code>fill_holes</code> (bool): Apply morphological operations to fill small gaps in water mask and smooth boundaries. Default: True</p> <p>Returns: - <code>np.ndarray</code>: Boolean mask (dtype=bool) where True = water, False = land. Same shape as dem_data.</p> <p>Raises: - <code>ValueError</code>: If dem_data is not 2D or slope_threshold is negative</p> <p>Examples:</p> <pre><code># Basic usage: detect water on unscaled DEM\nimport numpy as np\nfrom src.terrain.water import identify_water_by_slope\n\ndem = np.array([\n    [100, 100, 100, 200, 300],\n    [100, 100, 100, 200, 300],\n    [100, 100, 100, 200, 300],\n])\nwater_mask = identify_water_by_slope(dem, slope_threshold=0.5)\n\n# With Detroit elevation data (recommended workflow)\n# 1. Load and process DEM\nterrain = Terrain(dem_data, transform)\nterrain.configure_for_target_vertices(target_vertices=1_000_000)\nterrain.transforms.append(reproject_raster('EPSG:4326', 'EPSG:32617'))\nterrain.transforms.append(flip_raster(axis='horizontal'))\nterrain.transforms.append(scale_elevation(scale_factor=0.0001))\nterrain.apply_transforms()\n\n# 2. Get transformed DEM and unscale it for water detection\ntransformed_dem = terrain.data_layers['dem']['transformed_data']\nunscaled_dem = transformed_dem / 0.0001  # Undo elevation scaling\n\n# 3. Detect water on the unscaled DEM (where slopes are meaningful)\nwater_mask = identify_water_by_slope(\n    unscaled_dem,\n    slope_threshold=0.01,  # Very low threshold for nearly-flat water\n    fill_holes=True\n)\n\n# 4. Use water mask when creating mesh\nmesh = terrain.create_mesh(\n    scale_factor=100.0,\n    height_scale=4.0,\n    water_mask=water_mask\n)\n</code></pre> <p>Important Implementation Details:</p> <p>Why use unscaled DEM? When elevation data is scaled (e.g., by 0.0001) to fit visualization requirements, the slope magnitudes become very small. For example: - Original DEM: elevations 50-1400 meters, slopes ~0-100 magnitude - Scaled DEM (0.0001): elevations 0.005-0.14 meters, slopes ~0-0.027 magnitude</p> <p>If you detect water on scaled elevation, a threshold of 0.1 would catch ~90% of terrain as \"water\" because most slopes are below 0.027. Therefore, always detect water on unscaled DEM before applying elevation scaling.</p> <p>Horn's Method: The function uses Horn's method to compute terrain slope, which provides more accurate slope estimates than simple Sobel operators: - Weights central differences more heavily than edge differences - More robust for noisy terrain data - Produces gradient magnitude (not angle in degrees)</p> <p>Morphological Smoothing: When <code>fill_holes=True</code>, the function applies: 1. Binary closing (dilation followed by erosion) to fill small gaps 2. Preserves overall water extent while smoothing boundaries 3. Removes isolated noisy pixels</p> <p>Threshold Selection Guidelines: - For mostly flat water (lakes, reservoirs): 0.01 - 0.05 - For mixed terrain with some water: 0.1 - 0.2 - For detecting all flat-ish areas: 0.5+ - Start low and increase threshold if missing water features</p>"},{"location":"API_REFERENCE/#internal-functions","title":"Internal Functions","text":""},{"location":"API_REFERENCE/#_calculate_slopedem_data","title":"<code>_calculate_slope(dem_data)</code>","text":"<p>Calculate slope magnitude using Horn's method with proper convolution kernels.</p> <p>Uses Horn's method with weighted convolution kernels for more accurate slope computation on downsampled DEM data. This is more robust than Sobel for terrain slope analysis.</p> <p>Args: - <code>dem_data</code> (np.ndarray): 2D elevation data</p> <p>Returns: - <code>np.ndarray</code>: Slope magnitude (gradient magnitude), same shape as input</p> <p>Implementation:</p> <pre><code># Horn's method kernels (weights central differences heavily)\ndx = convolve(dem, [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]] / 8.0)\ndy = convolve(dem, [[-1, -2, -1], [0, 0, 0], [1, 2, 1]] / 8.0)\n\n# Slope magnitude is the gradient magnitude\nslope = sqrt(dx^2 + dy^2)\n</code></pre>"},{"location":"API_REFERENCE/#_smooth_water_maskwater_mask-structure_size3","title":"<code>_smooth_water_mask(water_mask, structure_size=3)</code>","text":"<p>Smooth water mask using morphological operations.</p> <p>Applies binary closing (dilation followed by erosion) to fill small holes within water bodies and smooth boundaries while preserving water regions.</p> <p>Args: - <code>water_mask</code> (np.ndarray): Boolean water mask - <code>structure_size</code> (int): Size of morphological structuring element (default: 3)</p> <p>Returns: - <code>np.ndarray</code>: Smoothed boolean water mask</p>"},{"location":"API_REFERENCE/#best-practices","title":"Best Practices","text":"<p>1. Always use unscaled DEM for water detection</p> <pre><code># Wrong - will detect too much as water\nwater = identify_water_by_slope(scaled_dem, threshold=0.1)\n\n# Correct - detect on meaningful slope values\nunscaled = scaled_dem / scale_factor\nwater = identify_water_by_slope(unscaled, threshold=0.01)\n</code></pre> <p>2. Call water detection BEFORE applying elevation scaling</p> <pre><code># Apply all transforms except scaling\nterrain.transforms.append(reproject_raster(...))\nterrain.transforms.append(flip_raster(...))\nterrain.transforms.append(scale_elevation(...))  # Last transform\nterrain.apply_transforms()\n\n# Get unscaled data and detect water\ntransformed = terrain.data_layers['dem']['transformed_data']\nunscaled = transformed / scale_factor\nwater_mask = identify_water_by_slope(unscaled, slope_threshold=0.01)\n\n# Pass to mesh creation\nterrain.create_mesh(water_mask=water_mask)\n</code></pre> <p>3. Handle NaN values properly The function automatically handles NaN values in DEM data: - Interpolates NaN values for slope calculation - Preserves original NaN locations in output - Treats NaN locations as non-water by default</p> <p>4. Tune threshold for your terrain</p> <pre><code># Debug: see what different thresholds detect\ndem = ... # Your DEM data\nfor threshold in [0.01, 0.05, 0.1, 0.5, 1.0]:\n    water = identify_water_by_slope(dem, threshold=threshold, fill_holes=False)\n    print(f\"Threshold {threshold}: {np.sum(water)} water pixels\")\n</code></pre> <p>5. Visualization of detected water</p> <pre><code># Visualize detected water mask\nimport matplotlib.pyplot as plt\n\ndem = ... # Your DEM\nwater_mask = identify_water_by_slope(dem, slope_threshold=0.01)\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.imshow(dem, cmap='gray')\nax1.set_title('DEM')\nax2.imshow(water_mask, cmap='Blues')\nax2.set_title('Water Mask')\nplt.show()\n</code></pre>"},{"location":"API_SETUP/","title":"Claude API Setup Guide for GitHub CI/CD","text":"<p>TL;DR: This enables GitHub Actions to automatically run the Agent Auditor (<code>.claude/agents/agent-auditor.md</code>) on a schedule, auditing all your AI agents for quality issues without manual intervention.</p> <p>This guide covers how to configure the Claude API so GitHub Actions CI/CD can automatically run the Agent Auditor agent to perform weekly quality audits of your AI agent library.</p>"},{"location":"API_SETUP/#what-this-enables-automated-cicd-agent-auditing","title":"What This Enables: Automated CI/CD Agent Auditing","text":"<p>The API setup allows GitHub Actions to run the Agent Auditor automatically:</p>"},{"location":"API_SETUP/#the-github-actions-workflow","title":"The GitHub Actions Workflow","text":"<ul> <li>\ud83d\udd04 Runs automatically every Sunday at midnight UTC</li> <li>\ud83e\udd16 No manual intervention - CI/CD handles everything</li> <li>\ud83d\udcca Creates audit reports directly in your repository</li> <li>\u2705 Can block merges if agents fail quality checks</li> <li>\ud83d\udd14 Can notify on Slack/email when issues are found</li> </ul>"},{"location":"API_SETUP/#what-the-agent-auditor-checks","title":"What the Agent Auditor Checks","text":"<p>The <code>.claude/agents/agent-auditor.md</code> agent that GitHub Actions runs will:</p> <ul> <li>\ud83d\udccb Audit all agents in <code>.claude/agents/</code> for quality and completeness</li> <li>\ud83d\udd0d Validate frontmatter ensuring proper agent-type and allowed-tools</li> <li>\ud83d\udcdd Check documentation for clear instructions and success criteria</li> <li>\ud83c\udfaf Verify task focus ensuring each agent has a single, clear purpose</li> <li>\ud83d\udea8 Flag security issues like overly broad tool access</li> </ul>"},{"location":"API_SETUP/#why-use-github-actions-for-this","title":"Why Use GitHub Actions for This?","text":"<p>Without automated CI/CD auditing:</p> <ul> <li>\u274c You manually review each agent (time-consuming)</li> <li>\u274c Quality issues slip through to production</li> <li>\u274c No consistent quality enforcement across team members</li> <li>\u274c No audit trail of agent quality over time</li> </ul> <p>With GitHub Actions + Claude API:</p> <ul> <li>\u2705 Automatic weekly quality audits</li> <li>\u2705 Consistent quality standards enforced</li> <li>\u2705 Historical reports tracked in git</li> <li>\u2705 Team notified of issues automatically</li> </ul>"},{"location":"API_SETUP/#quick-setup-enable-github-actions-cicd-for-agent-auditing","title":"Quick Setup: Enable GitHub Actions CI/CD for Agent Auditing","text":""},{"location":"API_SETUP/#1-get-your-claude-api-key","title":"1. Get Your Claude API Key","text":"<ul> <li>Visit Anthropic Console</li> <li>Navigate to API Keys section</li> <li>Create a new key for this project</li> </ul>"},{"location":"API_SETUP/#2-add-api-key-to-github-secrets-required-for-cicd","title":"2. Add API Key to GitHub Secrets (Required for CI/CD)","text":"<ol> <li>Go to your repository on GitHub</li> <li>Navigate to Settings \u2192 Secrets and variables \u2192 Actions</li> <li>Click \"New repository secret\"</li> <li>Add the secret:</li> <li>Name: <code>ANTHROPIC_API_KEY</code></li> <li>Value: Your API key (sk-ant-...)</li> <li>Click \"Add secret\"</li> </ol> <p>\u26a0\ufe0f NEVER commit your API key to the repository!</p>"},{"location":"API_SETUP/#3-github-actions-workflow-is-now-enabled","title":"3. GitHub Actions Workflow is Now Enabled","text":"<p>Once the secret is added, the <code>.github/workflows/agent-audit.yml</code> workflow will:</p> <ul> <li>Run automatically: Every Sunday at midnight UTC</li> <li>Run manually: Via Actions tab \u2192 Agent Audit \u2192 Run workflow</li> <li>Use the API key: To run Claude and audit your agents</li> <li>Commit reports: Back to your repository for review</li> </ul>"},{"location":"API_SETUP/#local-development-setup","title":"Local Development Setup","text":"<p>For local API usage with agents:</p>"},{"location":"API_SETUP/#option-1-environment-variable","title":"Option 1: Environment Variable","text":"<pre><code>export ANTHROPIC_API_KEY=\"sk-ant-...\"\n# Now run your agent commands\n</code></pre>"},{"location":"API_SETUP/#option-2-env-file-git-ignored","title":"Option 2: .env File (Git-Ignored)","text":"<pre><code>echo \"ANTHROPIC_API_KEY=sk-ant-...\" &gt; .env\n# The .env file is already in .gitignore\n</code></pre>"},{"location":"API_SETUP/#option-3-claude-code-cli-config","title":"Option 3: Claude Code CLI Config","text":"<pre><code>claude config set api-key sk-ant-...\n</code></pre>"},{"location":"API_SETUP/#security-best-practices","title":"Security Best Practices","text":""},{"location":"API_SETUP/#do","title":"DO \u2705","text":"<ul> <li>Store API keys in environment variables or secrets</li> <li>Use different keys for development and production</li> <li>Rotate keys regularly</li> <li>Limit key permissions when possible</li> <li>Monitor usage via the Anthropic Console</li> </ul>"},{"location":"API_SETUP/#dont","title":"DON'T \u274c","text":"<ul> <li>Commit API keys to version control</li> <li>Share keys between team members</li> <li>Log API keys in console output</li> <li>Include keys in error messages</li> <li>Use production keys for testing</li> </ul>"},{"location":"API_SETUP/#cost-considerations","title":"Cost Considerations","text":""},{"location":"API_SETUP/#api-pricing","title":"API Pricing","text":"<ul> <li>Claude 3.5 Sonnet: ~$3 per million input tokens</li> <li>Typical agent audit: ~10,000 tokens (~$0.03)</li> <li>Weekly audits: ~$1.50/month</li> </ul>"},{"location":"API_SETUP/#optimization-tips","title":"Optimization Tips","text":"<ul> <li>Use caching for repeated analyses</li> <li>Batch related operations</li> <li>Filter inputs to relevant content only</li> <li>Monitor usage in Anthropic Console</li> </ul>"},{"location":"API_SETUP/#workflow-examples","title":"Workflow Examples","text":""},{"location":"API_SETUP/#automated-agent-audit-primary-use-case","title":"Automated Agent Audit (Primary Use Case)","text":"<pre><code># .github/workflows/agent-audit.yml\n# Runs the Agent Auditor to check all agents in your library\n- uses: rmurphey/claude-code-cli@v1\n  with:\n    api-key: ${{ secrets.ANTHROPIC_API_KEY }}\n    command: run .claude/agents/agent-auditor.md\n</code></pre> <p>This runs the Agent Auditor which:</p> <ol> <li>Scans all <code>.claude/agents/*.md</code> files</li> <li>Validates each agent's configuration</li> <li>Creates a report at <code>.claude/agents/reports/agent-audit-[date].md</code></li> </ol>"},{"location":"API_SETUP/#manual-local-audit","title":"Manual Local Audit","text":"<pre><code># Run the Agent Auditor locally (requires API key configured)\nclaude run .claude/agents/agent-auditor.md\n\n# View the generated report\ncat .claude/agents/reports/agent-audit-*.md\n</code></pre>"},{"location":"API_SETUP/#other-available-agents-also-require-api","title":"Other Available Agents (Also Require API)","text":"<pre><code># Documentation Auditor - checks all documentation\nclaude run .claude/agents/documentation-auditor.md\n\n# Session Insights Analyzer - analyzes development patterns\nclaude run .claude/agents/session-insights-analyzer.md\n\n# Command Analyzer - audits command templates\nclaude run .claude/agents/command-analyzer.md\n</code></pre>"},{"location":"API_SETUP/#troubleshooting","title":"Troubleshooting","text":""},{"location":"API_SETUP/#common-issues","title":"Common Issues","text":""},{"location":"API_SETUP/#invalid-api-key","title":"\"Invalid API Key\"","text":"<ul> <li>Verify key starts with <code>sk-ant-</code></li> <li>Check for extra spaces or quotes</li> <li>Ensure key hasn't been revoked</li> </ul>"},{"location":"API_SETUP/#rate-limit-exceeded","title":"\"Rate Limit Exceeded\"","text":"<ul> <li>Default: 50 requests per minute</li> <li>Solution: Add delays between requests</li> <li>Consider upgrading your plan</li> </ul>"},{"location":"API_SETUP/#workflow-not-running","title":"\"Workflow Not Running\"","text":"<ul> <li>Check Actions are enabled in repository settings</li> <li>Verify secret name is exactly <code>ANTHROPIC_API_KEY</code></li> <li>Check workflow file syntax</li> </ul>"},{"location":"API_SETUP/#permission-denied","title":"\"Permission Denied\"","text":"<ul> <li>Ensure GitHub Actions has write permissions</li> <li>Check branch protection rules</li> <li>Verify workflow permissions in settings</li> </ul>"},{"location":"API_SETUP/#debug-mode","title":"Debug Mode","text":"<p>Enable verbose logging:</p> <pre><code>DEBUG=claude* npm run agent:audit\n</code></pre>"},{"location":"API_SETUP/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"API_SETUP/#custom-model-selection","title":"Custom Model Selection","text":"<pre><code>// In your agent configuration\nconst config = {\n  model: 'claude-3-5-sonnet-20241022',\n  maxTokens: 4096,\n  temperature: 0.7\n};\n</code></pre>"},{"location":"API_SETUP/#webhook-notifications","title":"Webhook Notifications","text":"<p>Configure GitHub to notify on audit completion:</p> <ol> <li>Settings \u2192 Webhooks \u2192 Add webhook</li> <li>Payload URL: Your notification endpoint</li> <li>Events: Workflow runs</li> </ol>"},{"location":"API_SETUP/#multi-environment-setup","title":"Multi-Environment Setup","text":"<pre><code># Different keys per environment\nproduction:\n  secret: ANTHROPIC_API_KEY_PROD\nstaging:\n  secret: ANTHROPIC_API_KEY_STAGING\ndevelopment:\n  secret: ANTHROPIC_API_KEY_DEV\n</code></pre>"},{"location":"API_SETUP/#resources","title":"Resources","text":"<ul> <li>Anthropic API Documentation</li> <li>GitHub Secrets Documentation</li> <li>Claude Code CLI</li> <li>Pricing Calculator</li> </ul>"},{"location":"API_SETUP/#support","title":"Support","text":"<ul> <li>Issues: GitHub Issues</li> <li>Community: Discussions</li> <li>API Support: Anthropic Support</li> </ul>"},{"location":"BEST_PRACTICES/","title":"Claude Code Best Practices Guide","text":""},{"location":"BEST_PRACTICES/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Claude Code Specific Best Practices</li> <li>Test-Driven Development with Claude</li> <li>Token Efficiency Strategies</li> <li>Workflow Automation</li> <li>Team Collaboration</li> <li>Security and Quality</li> <li>Documentation Standards</li> <li>Conventional Commits</li> <li>Context Management</li> <li>Command Development</li> </ol>"},{"location":"BEST_PRACTICES/#claude-code-specific-best-practices","title":"Claude Code Specific Best Practices","text":""},{"location":"BEST_PRACTICES/#1-structured-workflow-approach","title":"1. Structured Workflow Approach","text":"<p>Source: Anthropic Internal Teams Usage Patterns</p> <p>The most successful Claude Code workflows follow this pattern:</p> <ol> <li>Research and exploration - Let Claude understand the codebase first</li> <li>Planning and documentation - Create a plan before implementation</li> <li>Implementation - Execute the plan with clear steps</li> <li>Testing and validation - Verify all changes work correctly</li> <li>Commit and PR creation - Use Claude's git integration</li> </ol> <p>\"Steps #1-#2 are crucial\u2014without them, Claude tends to jump straight to coding a solution. While sometimes that's what you want, asking Claude to research and plan first significantly improves performance for problems requiring deeper thinking upfront.\"</p>"},{"location":"BEST_PRACTICES/#2-permission-management","title":"2. Permission Management","text":"<p>Source: Community Best Practices (Builder.io)</p> <p>The default permission prompts can interrupt flow. Two approaches:</p> <p>Safe Approach (Recommended for production):</p> <pre><code># Allow specific safe operations\nclaude --allow \"npm run lint:*,npm test,git status\"\n</code></pre> <p>Development Approach (Use with caution):</p> <pre><code># Skip all permissions (similar to Cursor's yolo mode)\nclaude --dangerously-skip-permissions\n</code></pre> <p>\"Every time I open Claude Code, I hit Command+C and run <code>claude --dangerously-skip-permissions</code>. It's not as dangerous as it sounds \u2014 think of it as Cursor's old yolo mode.\"</p>"},{"location":"BEST_PRACTICES/#3-custom-commands-best-practice","title":"3. Custom Commands Best Practice","text":"<p>Source: Claude Code Documentation</p> <p>Store reusable workflows as markdown files in <code>.claude/commands/</code>:</p> <ul> <li>Commands become available via slash menu (type <code>/</code>)</li> <li>Check into git for team sharing</li> <li>Reduce repetitive prompting</li> <li>Ensure consistent execution</li> </ul>"},{"location":"BEST_PRACTICES/#4-claudemd-configuration","title":"4. CLAUDE.md Configuration","text":"<p>Source: Anthropic Best Practices</p> <p>Every project should have a <code>CLAUDE.md</code> file documenting:</p> <ul> <li>Repository etiquette (branch naming, merge vs. rebase)</li> <li>Developer environment setup (pyenv, compiler versions)</li> <li>Unexpected behaviors or warnings</li> <li>Project-specific conventions</li> <li>Quality standards and thresholds</li> </ul>"},{"location":"BEST_PRACTICES/#test-driven-development-with-claude","title":"Test-Driven Development with Claude","text":""},{"location":"BEST_PRACTICES/#the-tdd-advantage-with-ai","title":"The TDD Advantage with AI","text":"<p>Source: Community Testing Patterns</p> <p>\"Test-driven development (TDD) becomes even more powerful when using Claude Code. The robots LOVE TDD. Seriously. They eat it up. With TDD you have the robot friend build out the test, and the mock. Then your next prompt you build the mock to be real. And the robot just loves this. It is the most effective counter to hallucination and LLM scope drift I have found.\"</p>"},{"location":"BEST_PRACTICES/#tdd-best-practices-for-2025","title":"TDD Best Practices for 2025","text":"<p>Source: BrowserStack TDD Guide</p> <ol> <li>Follow Red-Green-Refactor</li> <li>Write failing test first (Red)</li> <li>Write minimal code to pass (Green)</li> <li> <p>Refactor for clarity (Refactor)</p> </li> <li> <p>Keep Tests Atomic</p> </li> <li>Each test focuses on one behavior</li> <li>Avoid testing multiple functionalities</li> <li> <p>Improves debugging and maintenance</p> </li> <li> <p>Start Simple</p> </li> <li>Begin with the simplest test case</li> <li>Test fundamental features first</li> <li> <p>Progress to complex interactions</p> </li> <li> <p>Comprehensive Coverage</p> </li> <li>Include negative tests (failure conditions)</li> <li>Test boundary values (edge cases)</li> <li>Use equivalence partitioning</li> </ol>"},{"location":"BEST_PRACTICES/#token-efficiency-strategies","title":"Token Efficiency Strategies","text":""},{"location":"BEST_PRACTICES/#npm-script-delegation-pattern","title":"NPM Script Delegation Pattern","text":"<p>Source: This Repository's Measured Results (docs/TOKEN_EFFICIENCY.md)</p> <p>Achieve 87% token reduction through npm script delegation:</p> <p>Before (264 lines in command):</p> <pre><code># Project Hygiene Check\n[... 250+ lines of bash logic ...]\n</code></pre> <p>After (30 lines in command):</p> <pre><code># Project Hygiene Check\n\\`\\`\\`bash\nnpm run hygiene:full --silent\n\\`\\`\\`\n</code></pre> <p>Measured Results:</p> <ul> <li>Average reduction: 89%</li> <li>Hygiene command: 264 \u2192 30 lines (88% reduction)</li> <li>Commit command: 296 \u2192 33 lines (88% reduction)</li> <li>Maintainability: 458 \u2192 42 lines (90% reduction)</li> </ul>"},{"location":"BEST_PRACTICES/#token-optimization-techniques","title":"Token Optimization Techniques","text":"<ol> <li>Delegate to scripts - Move logic to npm/shell scripts</li> <li>Use references - Link to files rather than embedding</li> <li>Batch operations - Combine multiple tool calls</li> <li>Context management - Proactively compact at checkpoints</li> </ol>"},{"location":"BEST_PRACTICES/#workflow-automation","title":"Workflow Automation","text":""},{"location":"BEST_PRACTICES/#ai-powered-development-practices","title":"AI-Powered Development Practices","text":"<p>Source: 2025 Industry Report</p> <ol> <li>Supervised AI Agents</li> <li>Human oversight for code generation</li> <li>Review agent reasoning and outputs</li> <li>Approve terminal command execution</li> <li> <p>Rollback capability when needed</p> </li> <li> <p>CI/CD Integration</p> </li> <li>Automate TDD-driven testing in pipelines</li> <li>Make testing integral to deployment</li> <li>Use AI for test generation</li> <li> <p>Monitor code quality metrics</p> </li> <li> <p>Strategic Implementation</p> </li> <li>Start with pilot projects</li> <li>Focus on high-impact use cases</li> <li>Integrate seamlessly with existing tools</li> <li>Measure and iterate on results</li> </ol>"},{"location":"BEST_PRACTICES/#team-collaboration","title":"Team Collaboration","text":""},{"location":"BEST_PRACTICES/#patterns-from-anthropic-teams","title":"Patterns from Anthropic Teams","text":"<p>Source: How Anthropic Teams Use Claude Code</p> <p>\"The pattern became clear: agentic coding isn't just accelerating traditional development. It's dissolving the boundary between technical and non-technical work, turning anyone who can describe a problem into someone who can build a solution.\"</p>"},{"location":"BEST_PRACTICES/#collaboration-best-practices","title":"Collaboration Best Practices","text":"<ol> <li>Shared Commands</li> <li>Check <code>.claude/commands/</code> into version control</li> <li>Document team-specific workflows</li> <li> <p>Create command templates for common tasks</p> </li> <li> <p>Code Review Integration <code>bash    /install-github-app  # Automated PR reviews</code></p> <p>\"Claude often finds bugs that humans miss. Humans nitpick variable names. Claude finds actual logic errors and security issues.\"</p> </li> <li> <p>Knowledge Sharing</p> </li> <li>Use <code>/learn</code> to capture insights</li> <li>Document patterns in CLAUDE.md</li> <li>Share effective prompts as commands</li> </ol>"},{"location":"BEST_PRACTICES/#security-and-quality","title":"Security and Quality","text":""},{"location":"BEST_PRACTICES/#security-best-practices","title":"Security Best Practices","text":"<p>Source: IBM AI Development Guide</p> <ol> <li>Data Access Control</li> <li>Know which data an agent can access</li> <li>Understand where data is sent</li> <li> <p>Manage software supply chain risks</p> </li> <li> <p>Code Review Requirements</p> </li> <li>All AI-generated code needs review</li> <li>Annotate AI changes in commits</li> <li> <p>Track AI-assisted changes</p> </li> <li> <p>Quality Assurance</p> </li> <li>Automated testing for all changes</li> <li>Version control for rollback</li> <li>Comprehensive test coverage</li> </ol>"},{"location":"BEST_PRACTICES/#quality-gates","title":"Quality Gates","text":"<p>Implement these checks before allowing commits:</p> <ul> <li>Linting and formatting compliance</li> <li>Type checking (if applicable)</li> <li>Test suite execution</li> <li>Build validation</li> <li>Security scanning for secrets</li> <li>File size monitoring</li> </ul>"},{"location":"BEST_PRACTICES/#documentation-standards","title":"Documentation Standards","text":""},{"location":"BEST_PRACTICES/#self-documenting-code","title":"Self-Documenting Code","text":"<p>Source: Software Development Best Practices 2025</p> <ol> <li>AI-Generated Documentation</li> <li>Document the \"why\" not only the \"what\"</li> <li>Include context for AI decisions</li> <li> <p>Link to relevant issues/PRs</p> </li> <li> <p>Living Documentation</p> </li> <li>Update docs with code changes</li> <li>Use <code>/docs</code> command regularly</li> <li> <p>Track documentation metrics</p> </li> <li> <p>Citation Requirements</p> </li> <li>Cite sources for best practices</li> <li>Reference official documentation</li> <li>Include community patterns with attribution</li> </ol>"},{"location":"BEST_PRACTICES/#conventional-commits","title":"Conventional Commits","text":""},{"location":"BEST_PRACTICES/#specification-compliance","title":"Specification Compliance","text":"<p>Source: Conventional Commits v1.0.0</p> <p>Structure:</p> <pre><code>&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n</code></pre> <p>Essential Types:</p> <ul> <li><code>feat</code>: New features (MINOR version)</li> <li><code>fix</code>: Bug fixes (PATCH version)</li> <li><code>docs</code>: Documentation changes</li> <li><code>test</code>: Test additions/corrections</li> <li><code>refactor</code>: Code restructuring</li> <li><code>chore</code>: Maintenance tasks</li> </ul> <p>Breaking Changes:</p> <ul> <li>Add <code>!</code> after type/scope: <code>feat!: breaking change</code></li> <li>Or include in footer: <code>BREAKING CHANGE: description</code></li> <li>Results in MAJOR version bump</li> </ul>"},{"location":"BEST_PRACTICES/#2025-best-practices","title":"2025 Best Practices","text":"<p>Source: Conventional Commits Guide</p> <ol> <li>Automation Integration</li> <li>Use with semantic versioning</li> <li>Auto-generate changelogs</li> <li> <p>Integrate with CI/CD</p> </li> <li> <p>Team Standards</p> </li> <li>Enforce via commitlint</li> <li>Use git hooks (husky)</li> <li> <p>Regular team reviews</p> </li> <li> <p>Message Quality</p> </li> <li>Present tense, lowercase</li> <li>No period at end</li> <li>Focus on single concern</li> <li>Explain \"why\" in body</li> </ol>"},{"location":"BEST_PRACTICES/#context-management","title":"Context Management","text":""},{"location":"BEST_PRACTICES/#managing-claudes-context-window","title":"Managing Claude's Context Window","text":"<p>Source: Claude Code Documentation</p> <ol> <li>Proactive Compaction <code>bash    /compact  # Manually compact at checkpoints</code></li> <li>Compact after feature completion</li> <li>Compact before starting new work</li> <li> <p>Monitor context indicator</p> </li> <li> <p>Context Optimization</p> </li> <li>Keep prompts focused</li> <li>Reference files vs embedding</li> <li>Use batch operations</li> <li> <p>Clear context between major tasks</p> </li> <li> <p>Cost Management</p> </li> <li>Track token usage per session</li> <li>Use <code>/estimate</code> before tasks</li> <li>Monitor actual vs estimated usage</li> <li>Optimize expensive operations</li> </ol>"},{"location":"BEST_PRACTICES/#command-development","title":"Command Development","text":""},{"location":"BEST_PRACTICES/#creating-effective-commands","title":"Creating Effective Commands","text":"<p>Source: This Repository's Experience</p> <ol> <li>Command Structure    ```markdown</li> </ol> <p>allowed-tools: [Bash, Read, Write]    description: Brief command description</p> <p># Command Name</p> <p>Instructions for Claude...    ```</p> <ol> <li>Token Efficiency</li> <li>Delegate to npm scripts</li> <li>Keep commands under 50 lines</li> <li>Use references not embedding</li> <li> <p>Provide clear, concise instructions</p> </li> <li> <p>Testing Commands</p> </li> <li>Test on multiple project types</li> <li>Validate cross-platform</li> <li>Measure token usage</li> <li> <p>Document edge cases</p> </li> <li> <p>Documentation</p> </li> <li>Include usage examples</li> <li>Document prerequisites</li> <li>Explain configuration options</li> <li>Provide troubleshooting guide</li> </ol>"},{"location":"BEST_PRACTICES/#lessons-from-production-sessions","title":"Lessons from Production Sessions","text":""},{"location":"BEST_PRACTICES/#real-world-session-management","title":"Real-World Session Management","text":"<p>Source: Production usage patterns from extended Claude Code sessions</p> <p>Production sessions with Claude Code require different strategies than demo or learning sessions:</p>"},{"location":"BEST_PRACTICES/#1-directory-discipline","title":"1. Directory Discipline","text":"<p>Learning: Always return to repository root after operations</p> <pre><code># Anti-pattern - Getting lost in subdirectories\ncd .claude/commands/\n# ... operations ...\n# Forget to return, next operations fail\n\n# Best Practice - Always return home\nREPO_ROOT=$(pwd)\ncd .claude/commands/\n# ... operations ...\ncd \"$REPO_ROOT\"\n</code></pre>"},{"location":"BEST_PRACTICES/#2-atomic-commit-discipline","title":"2. Atomic Commit Discipline","text":"<p>Learning: Plan commits before making changes, not after</p> <pre><code># Anti-pattern - Retroactive splitting\n- Make 1000+ line changes\n- Try to split into logical commits\n- Lose context and grouping\n\n# Best Practice - Plan first\n1. Define commit boundaries (&lt;200 lines)\n2. Make focused changes\n3. Commit immediately\n4. Move to next atomic unit\n</code></pre>"},{"location":"BEST_PRACTICES/#3-test-as-you-go-principle","title":"3. Test-As-You-Go Principle","text":"<p>Learning: Test immediately after each implementation</p> <pre><code># Anti-pattern\nfor script in scripts/*; do\n  npm_script_name=$(basename \"$script\")\n  # Create npm script\ndone\n# Test everything at end - cascading failures\n\n# Best Practice\nfor script in scripts/*; do\n  npm_script_name=$(basename \"$script\")\n  # Create npm script\n  npm run \"$npm_script_name\" --silent || echo \"Failed: $npm_script_name\"\ndone\n</code></pre>"},{"location":"BEST_PRACTICES/#4-context-management-strategy","title":"4. Context Management Strategy","text":"<p>Learning: Proactive context management prevents confusion</p> Checkpoint Trigger Action Required 30 minutes elapsed Save checkpoint, assess progress 30 interactions Consider compaction Major decision made Document rationale immediately Error encountered Capture state before fixing"},{"location":"BEST_PRACTICES/#5-real-time-documentation","title":"5. Real-Time Documentation","text":"<p>Learning: Document decisions as they're made, not retrospectively</p> <pre><code># GitHub Issues - Update in real-time\n## Decision: Use NPM Script Delegation\n- Time: 14:32\n- Rationale: 87% token reduction measured\n- Tradeoff: Slight indirection vs massive efficiency\n- Result: Implemented across all commands\n</code></pre>"},{"location":"BEST_PRACTICES/#production-patterns-that-work","title":"Production Patterns That Work","text":""},{"location":"BEST_PRACTICES/#1-living-reference-architecture","title":"1. Living Reference Architecture","text":"<p>Proven: Repository that uses its own tools validates patterns</p> <p>Benefits discovered:</p> <ul> <li>Immediate feedback on command usability</li> <li>Real-world testing of patterns</li> <li>Credibility through actual use</li> <li>Natural evolution through practice</li> </ul>"},{"location":"BEST_PRACTICES/#2-token-efficiency-first","title":"2. Token Efficiency First","text":"<p>Proven: 87-91% reduction transforms development velocity</p> <p>Real metrics from session:</p> <ul> <li>Before: 264 lines per command (~3000 tokens)</li> <li>After: 30 lines per command (~300 tokens)</li> <li>Impact: 10x more iterations possible</li> </ul>"},{"location":"BEST_PRACTICES/#3-subdirectory-organization","title":"3. Subdirectory Organization","text":"<p>Proven: <code>.claude/commands/detailed/</code> pattern scales cleanly</p> <p>Advantages realized:</p> <ul> <li>No namespace pollution</li> <li>Clear variant hierarchy</li> <li>Future-proof structure</li> <li>Easy discovery</li> </ul>"},{"location":"BEST_PRACTICES/#session-anti-patterns-to-avoid","title":"Session Anti-patterns to Avoid","text":"<ol> <li>Assumption Cascade</li> <li>Making changes based on unverified assumptions</li> <li> <p>Solution: Verify state before each operation</p> </li> <li> <p>Context Tunnel Vision</p> </li> <li>Losing sight of original goals</li> <li> <p>Solution: Regular goal alignment checks</p> </li> <li> <p>Documentation Debt</p> </li> <li>\"I'll document later\" never happens</li> <li> <p>Solution: Document inline with implementation</p> </li> <li> <p>Test Skipping</p> </li> <li>Moving forward without validation</li> <li>Solution: Test before marking complete</li> </ol>"},{"location":"BEST_PRACTICES/#production-session-checklist","title":"Production Session Checklist","text":"<p>Before starting:</p> <ul> <li>[ ] Read CLAUDE.md and check GitHub issues</li> <li>[ ] Check recent git history</li> <li>[ ] Create session plan with checkpoints</li> <li>[ ] Estimate token budget</li> </ul> <p>During session:</p> <ul> <li>[ ] Update todo list continuously</li> <li>[ ] Test after each implementation</li> <li>[ ] Document decisions real-time</li> <li>[ ] Return to root after operations</li> <li>[ ] Checkpoint every 30 minutes</li> </ul> <p>After session:</p> <ul> <li>[ ] Save session transcript (optional)</li> <li>[ ] Document learnings</li> <li>[ ] Update metrics</li> <li>[ ] Plan next session</li> </ul>"},{"location":"BEST_PRACTICES/#session-preservation-optional","title":"Session Preservation (Optional)","text":"<p>If you choose to save sessions, consider:</p> <ul> <li>Before context compaction: Preserve conversation before reset</li> <li>After major features: Capture successful implementations</li> <li>Pattern discoveries: Save when finding reusable solutions</li> <li>Every 30-60 minutes: For long sessions you want to preserve</li> </ul> <p>Remember: Session saving is optional. Use it when it provides value to you.</p>"},{"location":"BEST_PRACTICES/#metrics-and-validation","title":"Metrics and Validation","text":""},{"location":"BEST_PRACTICES/#tracking-success","title":"Tracking Success","text":"<p>Source: Industry Best Practices</p> <p>Key metrics to track:</p> <ul> <li>Token usage per command</li> <li>Execution time statistics</li> <li>Error rates and recovery</li> <li>User satisfaction scores</li> <li>Cost per feature delivered</li> </ul>"},{"location":"BEST_PRACTICES/#continuous-improvement","title":"Continuous Improvement","text":"<ol> <li>Regular reviews of command effectiveness</li> <li>Update based on user feedback</li> <li>Monitor Claude API changes</li> <li>Incorporate new best practices</li> <li>Share learnings with community</li> </ol>"},{"location":"BEST_PRACTICES/#references","title":"References","text":"<ol> <li>Anthropic Claude Code Best Practices</li> <li>How Anthropic Teams Use Claude Code</li> <li>Conventional Commits v1.0.0 Specification</li> <li>Test-Driven Development Guide (BrowserStack)</li> <li>AI in Software Development (IBM)</li> <li>Community Patterns (Builder.io)</li> <li>Awesome Claude Code Repository</li> <li>Two Years of Using AI Tools (Pragmatic Engineer)</li> </ol> <p>Last updated: 2025-08-18 Document maintained manually - review periodically for updates</p>"},{"location":"CLAUDE_PATTERNS/","title":"Claude Code Patterns","text":"<p>Discovered patterns and strategies specific to Claude Code development sessions.</p>"},{"location":"CLAUDE_PATTERNS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Token Efficiency Patterns</li> <li>Context Management</li> <li>Command Architecture</li> <li>Living Reference Pattern</li> <li>Self-Documentation System</li> <li>Session Management</li> <li>Anti-patterns to Avoid</li> </ul>"},{"location":"CLAUDE_PATTERNS/#token-efficiency-patterns","title":"Token Efficiency Patterns","text":""},{"location":"CLAUDE_PATTERNS/#npm-script-delegation","title":"NPM Script Delegation","text":"<p>Pattern: Move command logic to npm scripts, keep Claude commands minimal</p>"},{"location":"CLAUDE_PATTERNS/#before-264-lines-3000-tokens","title":"Before (264 lines, ~3000 tokens)","text":"<pre><code># .claude/commands/hygiene.md\n&lt;bash&gt;\n# Check for TypeScript errors\nnpx tsc --noEmit\n\n# Run ESLint\nnpx eslint . --fix\n\n# Check for security vulnerabilities\nnpm audit\n\n# ... 250+ more lines of logic\n&lt;/bash&gt;\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#after-30-lines-300-tokens","title":"After (30 lines, ~300 tokens)","text":"<pre><code># .claude/commands/hygiene.md\n&lt;bash&gt;\nnpm run hygiene:full --silent\n&lt;/bash&gt;\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#implementation-in-packagejson","title":"Implementation in package.json","text":"<pre><code>{\n  \"scripts\": {\n    \"hygiene:full\": \"npm run typecheck &amp;&amp; npm run lint:fix &amp;&amp; npm audit\",\n    \"typecheck\": \"tsc --noEmit\",\n    \"lint:fix\": \"eslint . --fix\"\n  }\n}\n</code></pre> <p>Result: 87-91% token reduction across all commands</p>"},{"location":"CLAUDE_PATTERNS/#token-budget-strategy","title":"Token Budget Strategy","text":"Task Type Token Budget Message Count Bug Fix 5K-10K 10-30 Small Feature 10K-30K 30-80 Major Feature 30K-100K 100-300 Architecture Change 100K-200K 200-500"},{"location":"CLAUDE_PATTERNS/#batching-file-operations","title":"Batching File Operations","text":"<p>Anti-pattern: Reading files one at a time</p> <pre><code>Read file1.js\nRead file2.js\nRead file3.js\n</code></pre> <p>Pattern: Batch related reads</p> <pre><code>Read file1.js, file2.js, file3.js in parallel\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#context-management","title":"Context Management","text":""},{"location":"CLAUDE_PATTERNS/#checkpoint-system","title":"Checkpoint System","text":"<p>Pattern: Regular context checkpoints prevent overload</p>"},{"location":"CLAUDE_PATTERNS/#checkpoint-triggers","title":"Checkpoint Triggers","text":"<ol> <li>Time-based: Every 30 minutes</li> <li>Interaction-based: Every 20-30 messages</li> <li>Complexity-based: After major architecture decisions</li> <li>Error-based: After recovering from significant errors</li> </ol>"},{"location":"CLAUDE_PATTERNS/#checkpoint-actions","title":"Checkpoint Actions","text":"<pre><code># Save current state\ngit stash\ngit checkout -b checkpoint-$(date +%s)\ngit stash pop\ngit add -A\ngit commit -m \"checkpoint: $(date)\"\n\n# Document decisions\n# Create checkpoint as GitHub issue comment\ngh issue comment 1 --body \"## Checkpoint $(date)\n- Completed: X, Y, Z\n- Next: A, B, C\"\n\n# Compact if needed\nif [ $INTERACTION_COUNT -gt 30 ]; then\n  echo \"Consider compacting context\"\nfi\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#context-preservation","title":"Context Preservation","text":"<p>Pattern: Save critical information before compaction</p> <pre><code># Before compacting, always save:\n1. Session transcript\n2. Git history\n3. Key decisions\n4. Learned patterns\n5. Next actions\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#context-window-optimization","title":"Context Window Optimization","text":"<pre><code>// Priority levels for context\nconst CONTEXT_PRIORITY = {\n  CRITICAL: [\n    'Current task requirements',\n    'Recent errors and fixes',\n    'Active file contents'\n  ],\n  HIGH: [\n    'Related file contents',\n    'Recent git commits',\n    'Project structure'\n  ],\n  MEDIUM: [\n    'Documentation',\n    'Test results',\n    'Dependencies'\n  ],\n  LOW: [\n    'Historical commits',\n    'Archived decisions',\n    'Old conversations'\n  ]\n};\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#command-architecture","title":"Command Architecture","text":""},{"location":"CLAUDE_PATTERNS/#subdirectory-organization-pattern","title":"Subdirectory Organization Pattern","text":"<p>Pattern: Organize command variants using subdirectories</p> <pre><code>.claude/commands/\n\u251c\u2500\u2500 hygiene.md              # Minimal, token-efficient (default)\n\u251c\u2500\u2500 commit.md               # Minimal version\n\u251c\u2500\u2500 todo.md                 # Minimal version\n\u2514\u2500\u2500 detailed/\n    \u251c\u2500\u2500 hygiene.md          # Verbose, comprehensive (fallback)\n    \u251c\u2500\u2500 commit.md           # Detailed version\n    \u2514\u2500\u2500 todo.md             # Detailed version\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#command-naming-conventions","title":"Command Naming Conventions","text":"Type Pattern Example Action verb <code>commit</code>, <code>test</code>, <code>deploy</code> Query noun <code>status</code>, <code>metrics</code>, <code>report</code> Management verb-noun <code>update-docs</code>, <code>check-quality</code> Meta meta-action <code>token-check</code>, <code>session-save</code>"},{"location":"CLAUDE_PATTERNS/#command-discovery","title":"Command Discovery","text":"<pre><code># Users can discover available commands\nls .claude/commands/*.md | sed 's/.*\\///' | sed 's/\\.md//'\n\n# Users can check for detailed versions\nls .claude/commands/detailed/*.md 2&gt;/dev/null\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#living-reference-pattern","title":"Living Reference Pattern","text":""},{"location":"CLAUDE_PATTERNS/#principles","title":"Principles","text":"<ol> <li>Dogfooding: Repository uses its own commands</li> <li>Proof by Example: Every pattern is demonstrated</li> <li>Evolution Through Use: Commands improve through actual usage</li> <li>Reality Over Theory: Practical implementation over theoretical design</li> </ol>"},{"location":"CLAUDE_PATTERNS/#implementation-strategy","title":"Implementation Strategy","text":"<pre><code>graph TD\n    A[Template Repository] --&gt;|Transform| B[Living Reference]\n    B --&gt; C[Use Own Commands]\n    C --&gt; D[Discover Issues]\n    D --&gt; E[Fix &amp; Improve]\n    E --&gt; C\n    B --&gt; F[Document Patterns]\n    F --&gt; G[Share Learnings]\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#success-metrics","title":"Success Metrics","text":"<ul> <li>Commands used: 100% coverage</li> <li>Self-updates performed: Daily</li> <li>Pattern validations: Every commit</li> <li>Documentation accuracy: Auto-verified</li> </ul>"},{"location":"CLAUDE_PATTERNS/#self-documentation-system","title":"Self-Documentation System","text":""},{"location":"CLAUDE_PATTERNS/#auto-generation-pattern","title":"Auto-Generation Pattern","text":"<p>Pattern: Commands generate their own documentation</p> <pre><code># Command updates its own docs\nnpm run docs:generate -- --command=hygiene\n\n# Verify documentation\nnpm run docs:validate -- --command=hygiene\n\n# Update all documentation\nnpm run docs:update -- --all\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#documentation-hierarchy","title":"Documentation Hierarchy","text":"<pre><code>docs/\n\u251c\u2500\u2500 COMMAND_CATALOG.md      # Auto-generated from commands\n\u251c\u2500\u2500 BEST_PRACTICES.md       # Curated with citations\n\u251c\u2500\u2500 CLAUDE_PATTERNS.md      # This file - discovered patterns\n\u251c\u2500\u2500 TOKEN_EFFICIENCY.md     # Metrics and strategies\n\u2514\u2500\u2500 SELF_UPDATING.md        # How docs update themselves\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#citation-management","title":"Citation Management","text":"<pre><code>&lt;!-- Pattern for citations --&gt;\n[Statement needing citation]^[1]\n\n&lt;!-- References --&gt;\n[1]: https://source.url \"Source Title\"\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#validation-system","title":"Validation System","text":"<pre><code>// Validate all citations are valid\nasync function validateCitations(file) {\n  const citations = extractCitations(file);\n  for (const citation of citations) {\n    const isValid = await checkUrl(citation.url);\n    if (!isValid) {\n      console.error(`Invalid citation: ${citation.url}`);\n    }\n  }\n}\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#session-management","title":"Session Management","text":""},{"location":"CLAUDE_PATTERNS/#session-lifecycle","title":"Session Lifecycle","text":"<pre><code>graph LR\n    A[Start] --&gt; B[Load Context]\n    B --&gt; C[Plan Tasks]\n    C --&gt; D[Execute]\n    D --&gt; E{Checkpoint?}\n    E --&gt;|Yes| F[Save State]\n    E --&gt;|No| D\n    F --&gt; G{Continue?}\n    G --&gt;|Yes| D\n    G --&gt;|No| H[Document]\n    H --&gt; I[End]\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#session-patterns","title":"Session Patterns","text":""},{"location":"CLAUDE_PATTERNS/#1-planning-phase","title":"1. Planning Phase","text":"<pre><code>1. Read CLAUDE.md for project context\n2. Check GitHub issues for current state  \n3. Review recent git history\n4. Create todo list\n5. Estimate token usage\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#2-execution-phase","title":"2. Execution Phase","text":"<pre><code>1. Mark todo as in_progress\n2. Execute task\n3. Test immediately\n4. Mark as completed\n5. Update metrics\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#3-reflection-phase","title":"3. Reflection Phase","text":"<pre><code>1. Document learnings\n2. Update patterns\n3. Save session transcript\n4. Plan next session\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#recovery-patterns","title":"Recovery Patterns","text":"<p>Pattern: Graceful recovery from errors</p> <pre><code># Save state before risky operations\ngit stash save \"Before risky operation\"\n\n# Attempt operation\nif ! npm run risky:operation; then\n  # Recover\n  git stash pop\n  echo \"Operation failed, state restored\"\n\n  # Document failure\n  echo \"## Failed: risky:operation\" &gt;&gt; LEARNINGS.md\n  echo \"Reason: $ERROR\" &gt;&gt; LEARNINGS.md\nfi\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#anti-patterns-to-avoid","title":"Anti-patterns to Avoid","text":""},{"location":"CLAUDE_PATTERNS/#1-context-tunnel-vision","title":"1. Context Tunnel Vision","text":"<p>Anti-pattern: Losing sight of broader context</p> <pre><code>BAD: Deep diving into implementation without checking requirements\nGOOD: Regularly refer back to original task and goals\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#2-assumption-cascade","title":"2. Assumption Cascade","text":"<p>Anti-pattern: Building on unverified assumptions</p> <pre><code>BAD: Assuming file exists -&gt; Making changes -&gt; Discovering it doesn't\nGOOD: Verify first -&gt; Plan -&gt; Execute\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#3-commit-sprawl","title":"3. Commit Sprawl","text":"<p>Anti-pattern: Large, unfocused commits</p> <pre><code>BAD: 1000+ line commits mixing features\nGOOD: &lt;200 line atomic commits with single purpose\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#4-documentation-debt","title":"4. Documentation Debt","text":"<p>Anti-pattern: Postponing documentation</p> <pre><code>BAD: \"I'll document this later\"\nGOOD: Document as you go, update in real-time\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#5-test-skipping","title":"5. Test Skipping","text":"<p>Anti-pattern: Moving to next task without testing</p> <pre><code>BAD: Implement feature -&gt; Move to next\nGOOD: Implement -&gt; Test -&gt; Fix -&gt; Move\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#pattern-evolution","title":"Pattern Evolution","text":""},{"location":"CLAUDE_PATTERNS/#discovery-process","title":"Discovery Process","text":"<ol> <li>Observe: Notice recurring situations</li> <li>Document: Capture in LEARNINGS.md</li> <li>Abstract: Extract general pattern</li> <li>Validate: Test across multiple uses</li> <li>Codify: Add to this document</li> </ol>"},{"location":"CLAUDE_PATTERNS/#pattern-maturity-levels","title":"Pattern Maturity Levels","text":"Level Description Action 0 - Observation Noticed once Document in LEARNINGS 1 - Hypothesis Seen 2-3 times Track occurrences 2 - Pattern Proven useful Add to patterns 3 - Best Practice Widely applicable Promote to BEST_PRACTICES 4 - Standard Essential pattern Enforce via tooling"},{"location":"CLAUDE_PATTERNS/#session-preservation-pattern","title":"Session Preservation Pattern","text":""},{"location":"CLAUDE_PATTERNS/#overview","title":"Overview","text":"<p>Session preservation captures raw conversation transcripts for future reference. This is an optional feature that some users find valuable for learning and analysis.</p>"},{"location":"CLAUDE_PATTERNS/#implementation","title":"Implementation","text":"<pre><code># Save current session\nnpm run session:save\n\n# Save with description\nnpm run session:save -- \"feature-implementation\"\n\n# Save delta only (changes since last save)\nnpm run session:delta\n\n# List saved sessions\nnpm run session:list\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#directory-structure","title":"Directory Structure","text":"<pre><code>session-history/\n\u251c\u2500\u2500 YYYY-MM-DD/\n\u2502   \u251c\u2500\u2500 session-NNN-HHMM.txt         # Full session\n\u2502   \u251c\u2500\u2500 session-NNN-HHMM.meta.json   # Metadata (Claude version, etc.)\n\u2502   \u2514\u2500\u2500 session-NNN-HHMM-delta.txt   # Delta save\n\u2514\u2500\u2500 .last-save                       # Tracks last save for deltas\n</code></pre>"},{"location":"CLAUDE_PATTERNS/#metadata-tracking","title":"Metadata Tracking","text":"<p>Each session automatically captures:</p> <ul> <li>Claude Code version</li> <li>Timestamp</li> <li>Session type (full/delta)</li> <li>Environment context</li> </ul>"},{"location":"CLAUDE_PATTERNS/#use-cases","title":"Use Cases","text":"<ul> <li>Learning Analysis: Review problem-solving approaches</li> <li>Pattern Discovery: Identify recurring solutions</li> <li>Knowledge Base: Build personal reference library</li> <li>Team Sharing: Share successful debugging sessions</li> </ul>"},{"location":"CLAUDE_PATTERNS/#living-reference-practice","title":"Living Reference Practice","text":"<p>This repository demonstrates session preservation by saving its own development sessions. These provide real examples of the feature in use.</p>"},{"location":"CLAUDE_PATTERNS/#meta-patterns","title":"Meta-Patterns","text":""},{"location":"CLAUDE_PATTERNS/#the-pattern-of-patterns","title":"The Pattern of Patterns","text":"<ul> <li>Patterns emerge from repetition</li> <li>Documentation crystallizes patterns</li> <li>Automation codifies patterns</li> <li>Evolution refines patterns</li> </ul>"},{"location":"CLAUDE_PATTERNS/#continuous-improvement","title":"Continuous Improvement","text":"<pre><code>graph TD\n    A[Use] --&gt; B[Observe]\n    B --&gt; C[Document]\n    C --&gt; D[Improve]\n    D --&gt; A\n</code></pre> <p>Last updated: 2025-01-16 Pattern count: 16 major patterns documented Next review: After next significant session</p>"},{"location":"COMMAND_CATALOG/","title":"Command Catalog","text":"<p>Complete list of all available Claude Code commands organized by category.</p> <p>Last updated: 2025-11-21 Total Commands: 14</p>"},{"location":"COMMAND_CATALOG/#core-workflow-commands-14","title":"Core Workflow Commands (14)","text":""},{"location":"COMMAND_CATALOG/#commit","title":"/commit","text":"<p>Atomic commits with quality checks - 1-3 files at a time Location: <code>.claude/commands/commit.md</code></p>"},{"location":"COMMAND_CATALOG/#docs","title":"/docs","text":"<p>Documentation maintenance and validation Location: <code>.claude/commands/docs.md</code></p>"},{"location":"COMMAND_CATALOG/#docs-explain","title":"/docs-explain","text":"<p>Educational command showing how documentation works Location: <code>.claude/commands/docs-explain.md</code></p>"},{"location":"COMMAND_CATALOG/#hygiene","title":"/hygiene","text":"<p>Project health check - code quality, tests, dependencies, and git status Location: <code>.claude/commands/hygiene.md</code></p>"},{"location":"COMMAND_CATALOG/#learn","title":"/learn","text":"<p>Capture insights and learnings from development work Location: <code>.claude/commands/learn.md</code></p>"},{"location":"COMMAND_CATALOG/#maintainability","title":"/maintainability","text":"<p>Code maintainability analysis and improvement recommendations Location: <code>.claude/commands/maintainability.md</code></p>"},{"location":"COMMAND_CATALOG/#monitor","title":"/monitor","text":"<p>Monitor GitHub repository for test failures and pull requests Location: <code>.claude/commands/monitor.md</code></p>"},{"location":"COMMAND_CATALOG/#next","title":"/next","text":"<p>Get AI-recommended next steps and development priorities Location: <code>.claude/commands/next.md</code></p>"},{"location":"COMMAND_CATALOG/#push","title":"/push","text":"<p>Push commits to remote repository Location: <code>.claude/commands/push.md</code></p>"},{"location":"COMMAND_CATALOG/#reflect","title":"/reflect","text":"<p>Pause and reflect on current work Location: <code>.claude/commands/reflect.md</code></p>"},{"location":"COMMAND_CATALOG/#retrospective","title":"/retrospective","text":"<p>Capture current session with metadata for future analysis Location: <code>.claude/commands/retrospective.md</code></p>"},{"location":"COMMAND_CATALOG/#session-history","title":"/session-history","text":"<p>Save and manage Claude Code conversation transcripts for analysis Location: <code>.claude/commands/session-history.md</code></p>"},{"location":"COMMAND_CATALOG/#tdd","title":"/tdd","text":"<p>Your new best friend - TDD workflow that makes Claude amazing Location: <code>.claude/commands/tdd.md</code></p>"},{"location":"COMMAND_CATALOG/#todo","title":"/todo","text":"<p>Task management using GitHub Issues for better collaboration and tracking Location: <code>.claude/commands/todo.md</code></p>"},{"location":"COMMAND_CATALOG/#command-categories-summary","title":"Command Categories Summary","text":"Category Count Purpose Core Workflow 14 Daily development tasks Maintenance 0 Repository maintenance Planning 0 Planning and ideation"},{"location":"EXAMPLES/","title":"Examples Gallery","text":"<p>Real-world examples demonstrating the power and simplicity of Terrain Maker.</p>"},{"location":"EXAMPLES/#detroit-elevation-visualization","title":"Detroit Elevation Visualization","text":"<p>A complete example showing how to create stunning 3D terrain visualizations from real SRTM elevation data with just a few lines of Python.</p>"},{"location":"EXAMPLES/#the-result","title":"The Result","text":"<p>Professional-quality 3D terrain visualization of Detroit metro area - rendered with Blender from real SRTM elevation data with water body detection enabled</p>"},{"location":"EXAMPLES/#multiple-views-with-intelligent-camera-positioning","title":"Multiple Views with Intelligent Camera Positioning","text":"<p>The example demonstrates the power of <code>position_camera_relative()</code> by generating professional renders from different camera angles - each with optimal framing for its view direction:</p> North View East View (looking south) (looking west) West View Overhead View (looking east) (90\u00b0 down, zero rotation) <p>Generate these views yourself:</p> <pre><code>npm run py:example:detroit-north     # or any of: south, east, west, above\n</code></pre> <p>Each view is automatically framed with intelligent target offset adjustments. No manual coordinate calculations needed!</p>"},{"location":"EXAMPLES/#what-this-example-shows","title":"What This Example Shows","text":"<p>\u2713 Loading Real Geographic Data: Automatically loads and merges SRTM HGT tiles \u2713 Intelligent Mesh Optimization: Configure mesh density by target vertex count, not magic numbers \u2713 Coordinate Transformation: Automatic reprojection from WGS84 to UTM coordinates \u2713 Water Body Detection: Automatic identification of water bodies using slope-based analysis \u2713 Intuitive Camera Control: Position cameras using cardinal directions (north, south, above, etc) \u2713 Beautiful Visualization: Professional Blender rendering with color mapping and water shader</p>"},{"location":"EXAMPLES/#the-code","title":"The Code","text":"<pre><code># 1. Load elevation data\ndem_data, transform = load_dem_files(SRTM_TILES_DIR, pattern='*.hgt')\nterrain = Terrain(dem_data, transform)\n\n# 2. Define output image dimensions and compute target mesh vertices\n# Target vertices = WIDTH \u00d7 HEIGHT \u00d7 2\n# This ensures ~2 vertices per output pixel for optimal mesh density\nWIDTH = 960\nHEIGHT = 720\ntarget_vertices = WIDTH * HEIGHT * 2  # ~1.4 million vertices\nterrain.configure_for_target_vertices(target_vertices, order=4)\n\n# 3. Apply geographic transforms\nterrain.transforms.append(reproject_raster(\n    src_crs='EPSG:4326',      # WGS84 (from SRTM data)\n    dst_crs='EPSG:32617',     # UTM Zone 17N (Detroit area)\n    num_threads=4\n))\nterrain.transforms.append(flip_raster(axis='horizontal'))\nterrain.transforms.append(scale_elevation(scale_factor=0.0001))\nterrain.apply_transforms()\n\n# 4. Set up beautiful Mako color mapping\nterrain.set_color_mapping(\n    lambda dem: elevation_colormap(dem, cmap_name='mako'),\n    source_layers=['dem']\n)\n\n# 5. Detect water bodies on unscaled DEM (critical!)\nfrom src.terrain.water import identify_water_by_slope\ntransformed_dem = terrain.data_layers['dem']['transformed_data']\nunscaled_dem = transformed_dem / 0.0001  # Undo elevation scaling\nwater_mask = identify_water_by_slope(unscaled_dem, slope_threshold=0.01, fill_holes=True)\n\n# 6. Create mesh with water detection and render\nmesh = terrain.create_mesh(\n    scale_factor=100.0,\n    height_scale=4.0,\n    center_model=True,           # Center mesh at origin\n    boundary_extension=True,     # Extend boundaries for clean edges\n    water_mask=water_mask        # Use pre-computed water mask\n)\ncamera = position_camera_relative(mesh, direction='south', distance=1.5)\nrender_scene_to_file(output_path=\"detroit.png\", width=WIDTH, height=HEIGHT)\n</code></pre>"},{"location":"EXAMPLES/#key-features-in-action","title":"Key Features in Action","text":""},{"location":"EXAMPLES/#intelligent-downsampling","title":"Intelligent Downsampling","text":"<p>Instead of guessing downsampling factors, compute target vertices based on your output image dimensions:</p> <pre><code># Match mesh density to output resolution: ~2 vertices per pixel\nWIDTH = 960\nHEIGHT = 720\ntarget_vertices = WIDTH * HEIGHT * 2  # 1,382,400 vertices\n\n# Terrain Maker automatically calculates the optimal downsampling factor\nterrain.configure_for_target_vertices(target_vertices)\n\n# This ensures your mesh has perfect detail for the output size\n# (no wasted vertices, no under-sampling)\n</code></pre> <p>The Math: - Output image: 960 \u00d7 720 = 691,200 pixels - Target vertices: 691,200 \u00d7 2 = 1,382,400 - This gives approximately 2 vertices per output pixel, providing optimal detail without over-sampling - Adjust the multiplier (\u00d72, \u00d73, etc.) based on your quality needs and performance budget</p>"},{"location":"EXAMPLES/#cardinal-direction-camera-positioning","title":"Cardinal Direction Camera Positioning","text":"<p>No more confusing coordinate calculations. Position your camera intuitively with intelligent view-specific targeting:</p> <pre><code>camera = position_camera_relative(\n    mesh_obj,\n    direction='south',      # Can be: north, south, east, west, northeast, etc.\n    distance=1.5,           # Multiplier of mesh diagonal\n    elevation=0.5,          # Height above center\n    look_at=(0, -1.5, 0),   # View-specific target offset (auto-calculated)\n)\n</code></pre> <p>What makes this powerful: - Each cardinal direction has intelligent target offset adjustments - North: targets (0, 2, 0) - offsets north for perfect framing - South: targets (0, -1.5, 0) - offsets south for perfect framing - East/West: adjust X axis similarly for optimal perspective - The function automatically calculates rotation, distance, and elevation - Overhead view uses zero rotation to eliminate gimbal lock artifacts</p> <p>This eliminates trial-and-error camera positioning entirely!</p>"},{"location":"EXAMPLES/#geographic-coordinate-handling","title":"Geographic Coordinate Handling","text":"<p>Automatic reprojection and proper coordinate system handling:</p> <pre><code>terrain.transforms.append(reproject_raster(\n    src_crs='EPSG:4326',      # WGS84 (from SRTM data)\n    dst_crs='EPSG:32617',     # UTM Zone 17N (Detroit area)\n    num_threads=4\n))\n</code></pre>"},{"location":"EXAMPLES/#water-body-detection-blue-coloring","title":"Water Body Detection &amp; Blue Coloring","text":"<p>Automatic water body identification using slope-based analysis with direct blue coloring:</p> <pre><code># IMPORTANT: Detect water on the UNSCALED DEM (before elevation scaling)\n# This ensures slope calculations are meaningful (scaled elevation produces tiny slopes)\n\n# 1. Apply all transforms including elevation scaling\nterrain.transforms.append(reproject_raster('EPSG:4326', 'EPSG:32617'))\nterrain.transforms.append(flip_raster(axis='horizontal'))\nterrain.transforms.append(scale_elevation(scale_factor=0.0001))\nterrain.apply_transforms()\n\n# 2. Get transformed DEM and unscale it\ntransformed_dem = terrain.data_layers['dem']['transformed_data']\nunscaled_dem = transformed_dem / 0.0001  # Undo elevation scaling\n\n# 3. Detect water on unscaled DEM with very low threshold\nfrom src.terrain.water import identify_water_by_slope\nwater_mask = identify_water_by_slope(\n    unscaled_dem,\n    slope_threshold=0.01,  # Extremely low threshold for nearly-flat water\n    fill_holes=True\n)\n\n# 4. Create mesh with pre-computed water mask\nmesh = terrain.create_mesh(\n    scale_factor=100.0,\n    height_scale=4.0,\n    water_mask=water_mask  # Use pre-computed water mask\n)\n</code></pre> <p>How it works:</p> <p>Detection Phase: - Uses Horn's method to compute terrain slope magnitude from elevation data - Identifies pixels with slope below threshold as potential water bodies - Applies morphological operations (closing: dilation then erosion) to smooth water boundaries and fill gaps - Water is nearly flat (slope ~0), while terrain has measurable slopes</p> <p>Coloring Phase: - Directly colors detected water pixels blue (RGB: 26, 102, 204) - Land pixels retain their elevation-based Mako colormap colors - Results in clear visual distinction between water and terrain - Water is colored during mesh creation, no shader configuration needed</p> <p>Critical Implementation Detail - Why Use Unscaled DEM?</p> <p>When elevation data is scaled (e.g., by 0.0001) for visualization: - Original DEM: elevations 50-1400 meters \u2192 slopes ~0-100 magnitude - Scaled DEM: elevations 0.005-0.14 meters \u2192 slopes ~0-0.027 magnitude</p> <p>Using a threshold of 0.1 on scaled data would catch 90% of terrain as \"water\" because most slopes are below 0.027. Always detect water on unscaled DEM before applying elevation scaling.</p> <p>Threshold Selection: - For mostly flat water (lakes, reservoirs): <code>0.01 - 0.05</code> (very sensitive) - For mixed terrain with some water: <code>0.1 - 0.2</code> (moderate) - For all flat-ish areas: <code>0.5+</code> (lenient) - Default for Detroit: <code>0.01</code> produces realistic 13-15% water coverage</p> <p>For More Details: See Water Body Detection in API Reference for complete documentation including examples, threshold guidelines, and best practices.</p>"},{"location":"EXAMPLES/#running-this-example","title":"Running This Example","text":""},{"location":"EXAMPLES/#basic-render-south-view-default","title":"Basic Render (South View - Default)","text":"<pre><code>python examples/detroit_elevation_real.py\n</code></pre> <p>This will: 1. Load SRTM elevation tiles from <code>data/dem/detroit/</code> (110 tiles) 2. Compute target vertices from output image dimensions: WIDTH \u00d7 HEIGHT \u00d7 2 = 960 \u00d7 720 \u00d7 2 = 1,382,400 3. Process the data with intelligent downsampling to match target vertex count 4. Generate a ~1.4 million vertex Blender mesh (exact count varies by interpolation) 5. Detect water bodies on the unscaled DEM and color them blue 6. Render a publication-quality PNG (960\u00d7720) with elevation colors + water rendering 7. Save the Blender file for further editing</p>"},{"location":"EXAMPLES/#generate-multiple-views","title":"Generate Multiple Views","text":"<p>The example supports command-line arguments to easily create renders from different camera angles:</p> <pre><code># Quick commands for each cardinal direction\nnpm run py:example:detroit-north    # North view\nnpm run py:example:detroit-south    # South view\nnpm run py:example:detroit-east     # East view\nnpm run py:example:detroit-west     # West view\nnpm run py:example:detroit-above    # Overhead bird's-eye view\n</code></pre> <p>Each renders the same terrain from a different perspective with intelligent view-specific framing. Perfect for creating comparison sets or presentations!</p>"},{"location":"EXAMPLES/#example-output","title":"Example Output","text":"<p>When you run the example, you'll see output like this:</p> <pre><code>======================================================================\nDetroit Real Elevation Visualization\n======================================================================\n\u2713 Blender scene cleared\n[1/6] Loading SRTM tiles...\nOpening DEM files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 110/110 [00:00&lt;00:00, 1530.60it/s, opened=110]\n\n[2/6] Initializing Terrain object...\n      Terrain initialized\n      DEM shape: (36001, 39601)\n\n[3/6] Applying transforms...\n      Original DEM shape: (36001, 39601)\n      Configured for 1,382,400 target vertices\n      Calculated zoom_factor: 0.031139\n      Downsampled DEM shape: (1326, 1137)\n      Actual vertices: 1,507,662\n      Transforms applied successfully\n\n[4/6] Setting up color mapping...\n      Color mapping configured (Mako colormap)\n\n[5/6] Creating Blender mesh...\n      \u2713 Mesh created successfully!\n      Vertices: 1370951\n      Polygons: 1368731\n\n[6/6] Setting up camera and rendering to PNG...\n      Camera: South-facing cardinal view\n      Direction: south, distance: 1.5x, elevation: 0.5x\n      Type: Orthographic\n      Samples: 32\n      Rendering...\n      \u2713 Rendered successfully!\n      File: detroit_elevation_real.png\n      Size: 2.0 MB\n\n======================================================================\nDetroit Real Elevation Visualization Complete!\n======================================================================\n\nSummary:\n  \u2713 Loaded and merged all SRTM tiles (full coverage)\n  \u2713 Configured downsampling to target vertex count intelligently\n  \u2713 Applied geographic coordinate reprojection (WGS84 \u2192 UTM)\n  \u2713 Created Terrain object with real elevation data\n  \u2713 Applied transforms (reproject + flip + scale)\n  \u2713 Configured beautiful Mako elevation-based color mapping\n  \u2713 Detected and applied water bodies (slope-based identification)\n  \u2713 Generated Blender mesh with 1370951 vertices\n  \u2713 Rendered to PNG: /path/to/detroit_elevation_real.png\n\nThat's it! Professional terrain visualization with water detection in just a few lines of Python!\n</code></pre> <p>The entire process takes about 30-40 seconds on modern hardware. You'll see progress bars for DEM loading and processing, with detailed logging of each transformation step.</p>"},{"location":"EXAMPLES/#output-files","title":"Output Files","text":"<ul> <li><code>examples/detroit_elevation_south.png</code> - Main example render (south view, 960\u00d7720, 2.1 MB)</li> <li><code>examples/detroit_elevation_{north,east,west,above}.png</code> - Alternative views</li> <li><code>examples/detroit_elevation_{view}.blend</code> - Blender files for further editing</li> </ul>"},{"location":"EXAMPLES/#why-terrain-maker-makes-this-easy","title":"Why Terrain Maker Makes This Easy","text":"<p>Traditional terrain visualization typically requires: - Manually guessing optimal mesh density (under-sample \u2192 blurry, over-sample \u2192 slow) - Complex coordinate reprojection setup - Blender scripting knowledge - Camera positioning through trial-and-error - Manual water body identification and coloring</p> <p>With Terrain Maker, you get: - Smart mesh density calculation: <code>target_vertices = WIDTH \u00d7 HEIGHT \u00d7 2</code> ensures perfect detail for your output resolution - Automatic mesh optimization - calculates the exact downsampling needed - Built-in geographic transforms with sensible defaults - Water body detection using slope-based analysis on unscaled DEM - Automatic water coloring - flat areas colored blue during mesh creation - Intuitive cardinal direction camera positioning (north, south, above, etc.) - Professional Blender integration out of the box - Color mapping from elevation data in one line</p>"},{"location":"EXAMPLES/#customization","title":"Customization","text":""},{"location":"EXAMPLES/#command-line-camera-control","title":"Command-Line Camera Control","text":"<p>The example script accepts arguments to customize rendering without code changes:</p> <pre><code># Change view direction\npython examples/detroit_elevation_real.py --view east\n\n# Adjust camera distance (closer/farther)\npython examples/detroit_elevation_real.py --view north --distance 0.15\n\n# Change elevation (higher/lower viewpoint)\npython examples/detroit_elevation_real.py --view above --elevation 0.8\n\n# Custom output filename\npython examples/detroit_elevation_real.py --view west --output my_render.png\n\n# Switch to orthographic projection\npython examples/detroit_elevation_real.py --view north --camera-type ORTHO\n</code></pre>"},{"location":"EXAMPLES/#in-code-customization","title":"In-Code Customization","text":"<pre><code># Change the colormap\nelevation_colormap(dem, cmap_name='viridis')    # Other options: turbo, plasma, etc.\n\n# Adjust camera angle\nposition_camera_relative(mesh, direction='east', elevation=1.0)\n\n# Configure rendering\nsetup_render_settings(samples=4096, use_denoising=True)\n\n# Create a presentation set of all views\nfor view in ['north', 'south', 'east', 'west', 'above']:\n    position_camera_relative(mesh, direction=view)\n    render_scene_to_file(output_path=f\"detroit_{view}.png\")\n</code></pre>"},{"location":"EXAMPLES/#generating-multiple-comparison-views","title":"Generating Multiple Comparison Views","text":"<p>Create a full set of renders for comparison or publication:</p> <pre><code># Generate all cardinal views at once\nfor view in north south east west above; do\n    npm run py:example:detroit-$view\ndone\n</code></pre> <p>This creates 5 renders showing the terrain from different perspectives, with consistent framing and optimal camera positioning for each angle.</p>"},{"location":"EXAMPLES/#regenerating-example-images","title":"Regenerating Example Images","text":"<p>When you update the example code or want to refresh the documentation images with the latest rendering, use these npm commands:</p> <pre><code># Generate the main example image (south view - default)\nnpm run py:example:detroit-elevation\n\n# Generate specific views\nnpm run py:example:detroit-south      # South view (recommended for main image)\nnpm run py:example:detroit-north      # North view\nnpm run py:example:detroit-east       # East view\nnpm run py:example:detroit-west       # West view\nnpm run py:example:detroit-above      # Overhead view\n\n# Generate all views at once\nfor view in south north east west above; do\n  npm run py:example:detroit-$view\ndone\n</code></pre> <p>Output locations: - Main image: <code>examples/detroit_elevation_south.png</code> (recommended for documentation) - View-specific: <code>examples/detroit_elevation_{north,south,east,west,above}.png</code> - Blender files: <code>examples/detroit_elevation_{view}.blend</code></p> <p>Each render takes 30-40 seconds on modern hardware. The images are then automatically included in the documentation gallery when you run:</p> <pre><code>npm run docs:build\n</code></pre>"},{"location":"EXAMPLES/#accelerating-renders-with-caching","title":"Accelerating Renders with Caching","text":"<p>The example supports intelligent caching to dramatically speed up iterative development. Instead of reprocessing elevation data and regenerating meshes for every render, the system caches:</p> <ul> <li>DEM Cache: Loaded and merged elevation tiles (.npz format with hash validation)</li> <li>Mesh Cache: Generated Blender mesh files (.blend with parameter-based hashing)</li> </ul>"},{"location":"EXAMPLES/#how-it-works","title":"How It Works","text":"<pre><code>First Run (Full Pipeline):\n\u251c\u2500 Load SRTM tiles \u2192 .dem_cache/dem_[hash].npz\n\u251c\u2500 Merge &amp; transform\n\u251c\u2500 Create mesh \u2192 .mesh_cache/mesh_[hash].blend\n\u2514\u2500 Render to PNG\n\nSecond Run (Same DEM):\n\u251c\u2500 Load from .dem_cache/ (skip 10-15 seconds of file merging)\n\u251c\u2500 Create mesh \u2192 .mesh_cache/mesh_[hash].blend\n\u2514\u2500 Render to PNG\n\nSubsequent Renders (Same view):\n\u251c\u2500 Load from .dem_cache/\n\u251c\u2500 Load from .mesh_cache/ (skip 20-30 seconds of mesh generation!)\n\u2514\u2500 Render only to PNG\n</code></pre>"},{"location":"EXAMPLES/#using-caching","title":"Using Caching","text":"<p>Enable caching by adding the <code>--cache</code> flag:</p> <pre><code># First run: caches DEM and mesh\nnpm run detroit-build        # South view with caching\nnpm run detroit-build-north  # North view with caching\nnpm run detroit-build-east   # East view with caching\nnpm run detroit-build-west   # West view with caching\nnpm run detroit-build-above  # Overhead view with caching\n\n# Generate all views with caching (faster on subsequent runs)\nnpm run detroit-build:all\n</code></pre> <p>Or run the Python script directly with caching:</p> <pre><code># Enable caching for full pipeline\nuv run examples/detroit_elevation_real.py --cache\n\n# With specific view\nuv run examples/detroit_elevation_real.py --cache --view north\n\n# Generate multiple views with caching\nfor view in south north east west above; do\n  uv run examples/detroit_elevation_real.py --cache --view $view\ndone\n</code></pre>"},{"location":"EXAMPLES/#cache-management","title":"Cache Management","text":"<pre><code># Clear all cached DEM and mesh files\nnpm run detroit-cache-clear\nuv run examples/detroit_elevation_real.py --cache --clear-cache\n\n# View cache statistics\nnpm run detroit-cache-stats\n</code></pre>"},{"location":"EXAMPLES/#cache-file-locations","title":"Cache File Locations","text":"<pre><code>.dem_cache/           # DEM files (.npz format)\n  dem_[hash].npz      # Merged elevation data\n  dem_[hash]_meta.json  # Metadata and statistics\n\n.mesh_cache/          # Mesh files (.blend format)\n  mesh_[hash].blend   # Blender scene with terrain mesh\n  [hash]_meta.json    # Mesh parameters and hash\n</code></pre>"},{"location":"EXAMPLES/#cache-invalidation","title":"Cache Invalidation","text":"<p>The cache automatically invalidates when:</p> <ul> <li>DEM files change (file modification time or count changes)</li> <li>Mesh parameters change (scale_factor, height_scale, center_model, boundary_extension, water_mask)</li> <li>Manual clear via <code>--clear-cache</code> flag</li> </ul> <p>This ensures you always have current data without manual cache management.</p>"},{"location":"EXAMPLES/#performance-impact","title":"Performance Impact","text":"<p>Time savings by caching DEM: - First render: Full merge (10-15 seconds) + mesh generation (20-30 seconds) + render (5-10 seconds) = ~35-55 seconds - Cached DEM: Skip merge + mesh generation (20-30 seconds) + render (5-10 seconds) = ~25-40 seconds - Savings: 10-15 seconds per render</p> <p>Time savings by caching mesh: - After first full pipeline, subsequent renders skip mesh generation entirely - Render-only pass: Load cached mesh + render (5-10 seconds) = ~5-10 seconds - Savings: 20-30 seconds per render</p> <p>Want to try it yourself? See Quick Reference for API documentation and API Reference for detailed function signatures.</p>"},{"location":"FEATURE_CHECK/","title":"Feature Check Quality System","text":""},{"location":"FEATURE_CHECK/#overview","title":"Overview","text":"<p>The Feature Check system automatically ensures that new features added to the codebase have corresponding tests and documentation. This quality check runs in CI/CD pipelines and can be run locally to catch missing tests or documentation early in the development process.</p>"},{"location":"FEATURE_CHECK/#how-it-works","title":"How It Works","text":""},{"location":"FEATURE_CHECK/#feature-detection","title":"Feature Detection","text":"<p>The system detects new features by analyzing git changes:</p> <ul> <li>New files: Any new JavaScript/TypeScript files in <code>scripts/</code>, <code>src/</code>, <code>lib/</code> directories</li> <li>Significant changes: Existing files with more than 50 lines added</li> <li>Excluded: Test files, documentation files, configuration files</li> </ul>"},{"location":"FEATURE_CHECK/#test-coverage-verification","title":"Test Coverage Verification","text":"<p>For each detected feature, the system looks for corresponding test files:</p> <ul> <li><code>test/{feature}.test.js</code></li> <li><code>test/{feature}.unit.test.js</code></li> <li><code>test/{feature}.spec.js</code></li> <li>Tests that import or reference the feature</li> </ul>"},{"location":"FEATURE_CHECK/#documentation-verification","title":"Documentation Verification","text":"<p>Features must be documented in at least one of:</p> <ul> <li><code>README.md</code> - Main project documentation</li> <li><code>docs/</code> directory - Detailed documentation</li> <li><code>.claude/commands/</code> - Command documentation</li> <li>File with matching name (e.g., <code>scripts/monitor.js</code> \u2192 <code>docs/monitor.md</code>)</li> </ul>"},{"location":"FEATURE_CHECK/#usage","title":"Usage","text":""},{"location":"FEATURE_CHECK/#local-testing","title":"Local Testing","text":"<pre><code># Run feature check manually\nnpm run feature:check\n\n# Run as part of quality checks\nnpm run quality:all\n\n# Run before committing\nnpm run commit:check\n</code></pre>"},{"location":"FEATURE_CHECK/#cicd-integration","title":"CI/CD Integration","text":"<p>The feature check runs automatically in GitHub Actions:</p> <ul> <li>On push to main/develop branches</li> <li>On pull requests</li> <li>Can be triggered manually</li> </ul>"},{"location":"FEATURE_CHECK/#bypass-options","title":"Bypass Options","text":""},{"location":"FEATURE_CHECK/#skip-for-non-feature-changes","title":"Skip for Non-Feature Changes","text":"<p>The check automatically skips when changes are:</p> <ul> <li>Test files only</li> <li>Documentation only</li> <li>Configuration files only</li> </ul>"},{"location":"FEATURE_CHECK/#manual-skip","title":"Manual Skip","text":"<pre><code># Skip feature check for special cases\nnode scripts/feature-check.js --skip-feature-check\n</code></pre>"},{"location":"FEATURE_CHECK/#ignore-patterns","title":"Ignore Patterns","text":"<p>Create a <code>.featurecheckignore</code> file to exclude specific patterns:</p> <pre><code>scripts/experimental-*.js\nlib/vendor/*\n*.generated.js\n</code></pre>"},{"location":"FEATURE_CHECK/#error-messages","title":"Error Messages","text":"<p>When features lack tests or documentation, you'll see clear error messages:</p> <pre><code>\u274c Feature Check Failed\n\nNew features must have tests and documentation:\n\n  \u274c Feature missing test coverage: scripts/new-analyzer.js\n  \u274c Feature missing documentation: scripts/new-analyzer.js\n\nTo fix:\n  1. Add test files for new features in test/\n  2. Update documentation in README.md or docs/\n  3. Or use --skip-feature-check if this is not a feature\n</code></pre>"},{"location":"FEATURE_CHECK/#examples","title":"Examples","text":""},{"location":"FEATURE_CHECK/#valid-feature-addition","title":"Valid Feature Addition","text":"<pre><code># 1. Add new feature\necho \"module.exports = { analyze: () =&gt; {} }\" &gt; scripts/analyzer.js\n\n# 2. Add test\necho \"const analyzer = require('../scripts/analyzer');\" &gt; test/analyzer.test.js\n\n# 3. Add documentation\necho \"## Analyzer\\nAnalyzes code quality...\" &gt;&gt; README.md\n\n# 4. Check passes\nnpm run feature:check\n\u2705 Feature check passed - all features have tests and docs\n</code></pre>"},{"location":"FEATURE_CHECK/#fixing-missing-tests","title":"Fixing Missing Tests","text":"<pre><code># Feature without test\ngit add scripts/reporter.js\n\n# Check fails\nnpm run feature:check\n\u274c Feature missing test coverage: scripts/reporter.js\n\n# Add test\ncat &gt; test/reporter.test.js &lt;&lt; EOF\nconst { describe, it } = require('node:test');\nconst reporter = require('../scripts/reporter');\n\ndescribe('Reporter', () =&gt; {\n  it('should generate reports', () =&gt; {\n    // Test implementation\n  });\n});\nEOF\n\n# Now check passes\nnpm run feature:check\n\u2705 Feature check passed\n</code></pre>"},{"location":"FEATURE_CHECK/#configuration","title":"Configuration","text":""},{"location":"FEATURE_CHECK/#thresholds","title":"Thresholds","text":"<ul> <li>New file threshold: Any new code file is considered a feature</li> <li>Modification threshold: 50+ lines added to existing file</li> <li>Test patterns: <code>.test.js</code>, <code>.spec.js</code>, <code>.unit.test.js</code></li> <li>Doc locations: README.md, docs/, .claude/commands/</li> </ul>"},{"location":"FEATURE_CHECK/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>GITHUB_BASE_REF</code>: Base branch for comparison in PRs (auto-set by GitHub Actions)</li> <li><code>SKIP_FEATURE_CHECK</code>: Set to skip checks entirely</li> </ul>"},{"location":"FEATURE_CHECK/#integration-with-development-workflow","title":"Integration with Development Workflow","text":""},{"location":"FEATURE_CHECK/#tdd-workflow","title":"TDD Workflow","text":"<ol> <li>Write failing test first (TDD RED)</li> <li>Implement feature (TDD GREEN)</li> <li>Documentation already required - no additional step</li> <li>Feature check passes automatically</li> </ol>"},{"location":"FEATURE_CHECK/#regular-development","title":"Regular Development","text":"<ol> <li>Implement feature</li> <li>Run <code>npm run feature:check</code> locally</li> <li>Add missing tests/docs if needed</li> <li>Commit with confidence</li> </ol>"},{"location":"FEATURE_CHECK/#troubleshooting","title":"Troubleshooting","text":""},{"location":"FEATURE_CHECK/#false-positives","title":"False Positives","text":"<p>If the system incorrectly identifies a file as a feature:</p> <ol> <li>Check if it matches exclusion patterns</li> <li>Add to <code>.featurecheckignore</code> if needed</li> <li>Use <code>--skip-feature-check</code> for one-off cases</li> </ol>"},{"location":"FEATURE_CHECK/#missing-detection","title":"Missing Detection","text":"<p>If a feature isn't detected:</p> <ol> <li>Ensure file has correct extension (.js, .ts, etc.)</li> <li>Check that changes meet threshold (50+ lines for modifications)</li> <li>Verify file isn't in excluded directory</li> </ol>"},{"location":"FEATURE_CHECK/#test-not-found","title":"Test Not Found","text":"<p>If tests exist but aren't detected:</p> <ol> <li>Follow naming convention: <code>{feature}.test.js</code></li> <li>Place tests in <code>test/</code> directory</li> <li>Ensure test file imports the feature</li> </ol>"},{"location":"FEATURE_CHECK/#documentation-not-found","title":"Documentation Not Found","text":"<p>If documentation exists but isn't detected:</p> <ol> <li>Include feature name in documentation</li> <li>Use recognizable variants (kebab-case, snake_case)</li> <li>Add to README.md for guaranteed detection</li> </ol>"},{"location":"FEATURE_CHECK/#benefits","title":"Benefits","text":"<ul> <li>Quality Assurance: Ensures all features are tested</li> <li>Documentation: Maintains up-to-date documentation</li> <li>Early Detection: Catches issues before merge</li> <li>Developer Friendly: Clear messages and bypass options</li> <li>Automated: No manual review needed</li> </ul>"},{"location":"FEATURE_CHECK/#related-commands","title":"Related Commands","text":"<ul> <li><code>npm run test</code> - Run all tests</li> <li><code>npm run docs</code> - Update documentation</li> <li><code>npm run quality:all</code> - Run all quality checks</li> <li><code>npm run commit:check</code> - Pre-commit validation</li> </ul>"},{"location":"PYTHON_SETUP/","title":"Python Terrain-Maker Setup","text":""},{"location":"PYTHON_SETUP/#overview","title":"Overview","text":"<p>The terrain-maker component is a Python 3.11+ geospatial data processing and visualization toolkit integrated with Blender 3D.</p>"},{"location":"PYTHON_SETUP/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Conda (recommended) or pip</li> <li>Blender 4.3+ (for 3D rendering features)</li> <li>GDAL/GEOS libraries (for geospatial processing)</li> </ul>"},{"location":"PYTHON_SETUP/#installation","title":"Installation","text":""},{"location":"PYTHON_SETUP/#option-1-using-conda-recommended","title":"Option 1: Using Conda (Recommended)","text":"<pre><code># Create environment from environment.yml\nconda env create -f environment.yml\nconda activate rayshade\n</code></pre>"},{"location":"PYTHON_SETUP/#option-2-using-pip","title":"Option 2: Using pip","text":"<pre><code># Create virtual environment\npython3.11 -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n</code></pre>"},{"location":"PYTHON_SETUP/#data-setup","title":"Data Setup","text":"<p>The project uses symbolic links to access large data files without duplication:</p>"},{"location":"PYTHON_SETUP/#data-directory-structure","title":"Data Directory Structure","text":"<pre><code>data/\n\u251c\u2500\u2500 snodas_data/          # \u2192 Symlink to /data/jflournoy/snodas_data (340GB)\n\u251c\u2500\u2500 dem/\n\u2502   \u2514\u2500\u2500 detroit/          # \u2192 Symlink to SRTM .hgt files\n\u251c\u2500\u2500 samples/              # Small test files (copied)\n\u2514\u2500\u2500 cache/                # Generated caches (gitignored)\n    \u251c\u2500\u2500 dem/\n    \u251c\u2500\u2500 terrain/\n    \u251c\u2500\u2500 features/\n    \u2514\u2500\u2500 snow/\n</code></pre>"},{"location":"PYTHON_SETUP/#verify-data-access","title":"Verify Data Access","text":"<pre><code># Check symlinks\nls -lh data/snodas_data\nls -lh data/dem/detroit\n\n# Check samples\nls -lh data/samples/\n</code></pre>"},{"location":"PYTHON_SETUP/#development-workflow","title":"Development Workflow","text":""},{"location":"PYTHON_SETUP/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\nnpm run py:test\n\n# Run with coverage\nnpm run py:test:cov\n\n# Run specific test file\npytest tests/test_config.py -v\n</code></pre>"},{"location":"PYTHON_SETUP/#code-quality","title":"Code Quality","text":"<pre><code># Format code\nnpm run py:format\n\n# Check formatting\nnpm run py:format:check\n\n# Lint code\nnpm run py:lint\n\n# Type check\nnpm run py:type\n\n# Run all checks\nnpm run py:check\n</code></pre>"},{"location":"PYTHON_SETUP/#tdd-workflow-with-claude","title":"TDD Workflow with Claude","text":"<pre><code># Start TDD workflow for a new feature\n/tdd start \"terrain elevation processing\"\n\n# Let Claude guide you through:\n# 1. Write failing test (RED)\n# 2. Write minimal code (GREEN)\n# 3. Refactor (REFACTOR)\n# 4. Commit (COMMIT)\n</code></pre>"},{"location":"PYTHON_SETUP/#project-structure","title":"Project Structure","text":"<pre><code>terrain-maker_v2/\n\u251c\u2500\u2500 src/                    # Python source code\n\u2502   \u251c\u2500\u2500 config.py           # Configuration (data paths)\n\u2502   \u251c\u2500\u2500 terrain/            # Terrain processing\n\u2502   \u2502   \u251c\u2500\u2500 core.py         # Terrain class\n\u2502   \u2502   \u251c\u2500\u2500 transforms.py   # Transform pipeline\n\u2502   \u2502   \u251c\u2500\u2500 rendering.py    # Blender integration\n\u2502   \u2502   \u2514\u2500\u2500 cache.py        # Caching system\n\u2502   \u251c\u2500\u2500 snow/               # Snow analysis\n\u2502   \u2502   \u2514\u2500\u2500 analysis.py     # SnowAnalysis class\n\u2502   \u2514\u2500\u2500 utils/              # Utilities\n\u2502       \u251c\u2500\u2500 helpers.py      # Helper functions\n\u2502       \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 tests/                  # Pytest tests\n\u2502   \u251c\u2500\u2500 conftest.py         # Test fixtures\n\u2502   \u251c\u2500\u2500 test_config.py      # Config tests\n\u2502   \u2514\u2500\u2500 test_basic.py       # Basic tests\n\u251c\u2500\u2500 examples/               # Example scripts\n\u251c\u2500\u2500 data/                   # Data directory (see above)\n\u2514\u2500\u2500 docs/                   # Documentation\n</code></pre>"},{"location":"PYTHON_SETUP/#usage-examples","title":"Usage Examples","text":""},{"location":"PYTHON_SETUP/#basic-terrain-processing","title":"Basic Terrain Processing","text":"<pre><code>from src.terrain.core import Terrain\nfrom src.config import DEM_DIR\n\n# Initialize terrain\nterrain = Terrain()\n\n# Load DEM data\ndem_files = list((DEM_DIR / \"detroit\").glob(\"*.hgt\"))\nterrain.load_dem_files(dem_files)\n\n# Process terrain\nterrain.process()\n\n# Render with Blender\nterrain.render(output_path=\"output/terrain.png\")\n</code></pre>"},{"location":"PYTHON_SETUP/#snow-analysis","title":"Snow Analysis","text":"<pre><code>from src.snow.analysis import SnowAnalysis\nfrom src.config import SNODAS_DIR\n\n# Initialize snow analysis\nsnow = SnowAnalysis(\n    snodas_root_dir=SNODAS_DIR,\n    cache_dir=\"data/cache/snow\"\n)\n\n# Process snow data\nstats, metadata, failed = snow.process_snow_data()\n\n# Calculate sledding scores\nsledding_score = snow.calculate_sledding_score(\n    min_depth_mm=100,\n    min_coverage=0.3\n)\n\n# Visualize\nsnow.visualize_snow_data(data_type='sledding_score')\n</code></pre>"},{"location":"PYTHON_SETUP/#cache-management","title":"Cache Management","text":"<p>The project automatically caches processed data to avoid recomputation:</p> <pre><code>from src.config import CACHE_DIR\n\n# Caches are stored in:\n# - data/cache/dem/        - DEM preprocessing\n# - data/cache/terrain/    - Terrain meshes\n# - data/cache/features/   - Feature calculations\n# - data/cache/snow/       - Snow statistics\n\n# To clear caches:\n# rm -rf data/cache/*\n</code></pre>"},{"location":"PYTHON_SETUP/#integration-with-claude-code","title":"Integration with Claude Code","text":"<p>This project uses Claude Code's TDD workflow for development:</p> <ol> <li><code>/tdd</code> - Test-driven development cycle</li> <li><code>/hygiene</code> - Check Python code quality</li> <li><code>/commit</code> - Quality-checked commits</li> <li><code>/learn</code> - Capture development insights</li> </ol> <p>See CLAUDE.md for full Claude Code guidelines.</p>"},{"location":"PYTHON_SETUP/#troubleshooting","title":"Troubleshooting","text":""},{"location":"PYTHON_SETUP/#import-errors","title":"Import Errors","text":"<p>If you get import errors, make sure you're in the project root and have activated the environment:</p> <pre><code># Check current directory\npwd  # Should be terrain-maker_v2/\n\n# Activate environment\nconda activate rayshade  # Or: source .venv/bin/activate\n</code></pre>"},{"location":"PYTHON_SETUP/#gdalrasterio-issues","title":"GDAL/Rasterio Issues","text":"<p>If rasterio installation fails:</p> <pre><code># Ubuntu/Debian\nsudo apt-get install libgdal-dev\n\n# macOS\nbrew install gdal\n\n# Then reinstall\npip install rasterio\n</code></pre>"},{"location":"PYTHON_SETUP/#blender-not-found","title":"Blender Not Found","text":"<p>Blender is optional for visualization only. Install from:</p> <ul> <li>https://www.blender.org/download/</li> </ul>"},{"location":"PYTHON_SETUP/#contributing","title":"Contributing","text":"<ol> <li>Follow TDD workflow (<code>/tdd</code>)</li> <li>Run quality checks before commit (<code>npm run py:check</code>)</li> <li>Update tests for new features</li> <li>Document in docstrings</li> </ol>"},{"location":"PYTHON_SETUP/#resources","title":"Resources","text":"<ul> <li>Design Specification - Original terrain-maker design</li> <li>TDD with Claude - TDD workflow guide</li> <li>API Setup - Claude API configuration</li> </ul>"},{"location":"QUICK_REFERENCE/","title":"Claude Code Commands - Quick Reference","text":""},{"location":"QUICK_REFERENCE/#essential-commands-use-daily","title":"Essential Commands (Use Daily)","text":"Command Purpose Example <code>/hygiene</code> Project health check <code>/hygiene</code> <code>/todo</code> Task management <code>/todo add \"Fix bug\"</code> <code>/commit</code> Quality-checked commits <code>/commit</code> <code>/next</code> Get AI recommendations <code>/next</code>"},{"location":"QUICK_REFERENCE/#all-commands-by-category","title":"All Commands by Category","text":""},{"location":"QUICK_REFERENCE/#core-workflow","title":"\ud83c\udfaf Core Workflow","text":"<pre><code>/hygiene              # Check project health (lint, tests, deps)\n/todo [add|done|list] # Manage tasks in GitHub Issues\n/commit               # Commit with quality checks\n/next                 # AI-recommended next actions\n/push                 # Push with quality checks\n</code></pre>"},{"location":"QUICK_REFERENCE/#development-testing","title":"\ud83d\udccb Development &amp; Testing","text":"<pre><code>/tdd start \"feature\"  # Start Test-Driven Development workflow\n/retrospective        # Analyze git history and patterns\n/monitor              # Check GitHub CI status\n</code></pre>"},{"location":"QUICK_REFERENCE/#documentation-learning","title":"\ud83d\udcda Documentation &amp; Learning","text":"<pre><code>/docs                 # Analyze and update documentation\n/docs-explain         # Explain documentation structure\n/learn \"insight\"      # Capture development insights\n/reflect              # End-of-session reflection\n</code></pre>"},{"location":"QUICK_REFERENCE/#common-workflows","title":"Common Workflows","text":""},{"location":"QUICK_REFERENCE/#start-of-day","title":"\ud83c\udf05 Start of Day","text":"<pre><code>/hygiene              # Check project status\n/todo list            # Review tasks\n/next                 # Get recommendations\n</code></pre>"},{"location":"QUICK_REFERENCE/#during-development","title":"\ud83d\udcbb During Development","text":"<pre><code>/todo add \"task\"      # Track new work\n/tdd start \"feature\"  # TDD for new features\n/learn \"insight\"      # Capture discoveries\n</code></pre>"},{"location":"QUICK_REFERENCE/#end-of-session","title":"\ud83c\udf19 End of Session","text":"<pre><code>/commit               # Commit changes\n/reflect              # Capture session learnings\n/push                 # Push to remote\n</code></pre>"},{"location":"QUICK_REFERENCE/#task-management-todo","title":"Task Management (<code>/todo</code>)","text":"<pre><code># Basic Operations\n/todo                      # List all tasks\n/todo add \"Fix login\"      # Add new task\n/todo done 1              # Complete task #1\n/todo done \"login\"        # Complete by text match\n/todo remove 2            # Delete task\n\n# Advanced\n/todo priority \"Critical\"  # Add high-priority task\n/todo cleanup             # Archive completed tasks\n/todo list --all          # Show including completed\n</code></pre>"},{"location":"QUICK_REFERENCE/#commit-types-commit","title":"Commit Types (<code>/commit</code>)","text":"<p>The <code>/commit</code> command will guide you through creating quality-checked commits with proper formatting.</p> Type Use For Example <code>feat</code> New features <code>feat: add authentication</code> <code>fix</code> Bug fixes <code>fix: resolve login crash</code> <code>docs</code> Documentation <code>docs: update README</code> <code>test</code> Adding tests <code>test: add unit tests</code> <code>refactor</code> Code restructuring <code>refactor: simplify logic</code> <code>chore</code> Maintenance <code>chore: update dependencies</code> <code>style</code> Formatting <code>style: fix indentation</code>"},{"location":"QUICK_REFERENCE/#quick-decision-tree","title":"Quick Decision Tree","text":"<pre><code>Need to know project status?\n  \u2192 /hygiene\n\nStarting new feature?\n  \u2192 /tdd start \"feature name\"\n\nReady to commit?\n  \u2192 /commit\n\nNot sure what to do?\n  \u2192 /next\n\nFound a bug?\n  \u2192 /todo add \"fix bug\" \u2192 fix it \u2192 /commit\n\nNeed to understand project?\n  \u2192 /docs-explain\n\nWant to check CI?\n  \u2192 /monitor\n\nEnd of session?\n  \u2192 /reflect \u2192 /commit \u2192 /push\n</code></pre>"},{"location":"QUICK_REFERENCE/#command-details","title":"Command Details","text":""},{"location":"QUICK_REFERENCE/#hygiene-project-health-check","title":"<code>/hygiene</code> - Project Health Check","text":"<ul> <li>Runs linting checks</li> <li>Executes test suite</li> <li>Checks for outdated dependencies</li> <li>Shows git status summary</li> <li>Quick way to ensure everything is working</li> </ul>"},{"location":"QUICK_REFERENCE/#todo-task-management","title":"<code>/todo</code> - Task Management","text":"<ul> <li>Maintains tasks in GitHub Issues</li> <li>Supports add, done, remove, list operations</li> <li>Tracks task completion</li> <li>Archives completed tasks</li> </ul>"},{"location":"QUICK_REFERENCE/#commit-quality-commits","title":"<code>/commit</code> - Quality Commits","text":"<ul> <li>Runs quality checks before committing</li> <li>Enforces atomic commits (1-3 files recommended)</li> <li>Adds co-author attribution for Claude</li> <li>Follows conventional commit format</li> </ul>"},{"location":"QUICK_REFERENCE/#next-ai-recommendations","title":"<code>/next</code> - AI Recommendations","text":"<ul> <li>Analyzes project state</li> <li>Suggests next logical steps</li> <li>Considers pending tasks and recent changes</li> <li>Helps when you're unsure what to do</li> </ul>"},{"location":"QUICK_REFERENCE/#tdd-test-driven-development","title":"<code>/tdd</code> - Test-Driven Development","text":"<ul> <li>Guides through RED-GREEN-REFACTOR cycle</li> <li>Creates failing tests first</li> <li>Implements minimal code to pass</li> <li>Refactors with test safety net</li> </ul>"},{"location":"QUICK_REFERENCE/#monitor-ci-monitoring","title":"<code>/monitor</code> - CI Monitoring","text":"<ul> <li>Checks GitHub Actions status</li> <li>Shows recent workflow runs</li> <li>Identifies test failures</li> <li>Tracks pull request status</li> </ul>"},{"location":"QUICK_REFERENCE/#docs-documentation-management","title":"<code>/docs</code> - Documentation Management","text":"<ul> <li>Updates command catalog</li> <li>Checks for broken links</li> <li>Maintains documentation consistency</li> <li>Auto-generates documentation</li> </ul>"},{"location":"QUICK_REFERENCE/#learn-knowledge-capture","title":"<code>/learn</code> - Knowledge Capture","text":"<ul> <li>Records development insights</li> <li>Maintains LEARNINGS.md</li> <li>Archives learnings by date</li> <li>Searchable knowledge base</li> </ul>"},{"location":"QUICK_REFERENCE/#reflect-session-reflection","title":"<code>/reflect</code> - Session Reflection","text":"<ul> <li>Captures end-of-session insights</li> <li>Reviews accomplishments</li> <li>Identifies patterns</li> <li>Builds learning history</li> </ul>"},{"location":"QUICK_REFERENCE/#retrospective-git-analysis","title":"<code>/retrospective</code> - Git Analysis","text":"<ul> <li>Analyzes commit patterns</li> <li>Shows productivity metrics</li> <li>Identifies improvement areas</li> <li>Historical code analysis</li> </ul>"},{"location":"QUICK_REFERENCE/#push-safe-push","title":"<code>/push</code> - Safe Push","text":"<ul> <li>Runs quality checks</li> <li>Validates before pushing</li> <li>Ensures CI readiness</li> <li>Prevents breaking builds</li> </ul>"},{"location":"QUICK_REFERENCE/#file-locations","title":"File Locations","text":"<pre><code>.claude/\n\u251c\u2500\u2500 commands/         # Command templates (customize here)\n\u2502   \u251c\u2500\u2500 hygiene.md\n\u2502   \u251c\u2500\u2500 todo.md\n\u2502   \u251c\u2500\u2500 commit.md\n\u2502   \u251c\u2500\u2500 tdd.md\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 learnings/       # Archived insights (/learn)\n\nGitHub Issues        # Current tasks (/todo)\nLEARNINGS.md         # Captured insights (/learn)\nCLAUDE.md            # AI guidelines\n</code></pre>"},{"location":"QUICK_REFERENCE/#customization","title":"Customization","text":""},{"location":"QUICK_REFERENCE/#modify-commands","title":"Modify Commands","text":"<p>Edit files in <code>.claude/commands/</code>:</p> <pre><code># Make hygiene stricter\nvim .claude/commands/hygiene.md\n# Adjust quality thresholds\n</code></pre>"},{"location":"QUICK_REFERENCE/#create-command-aliases","title":"Create Command Aliases","text":"<pre><code># Create short aliases\ncp .claude/commands/hygiene.md .claude/commands/h.md\ncp .claude/commands/todo.md .claude/commands/t.md\n</code></pre>"},{"location":"QUICK_REFERENCE/#best-practices","title":"Best Practices","text":"<ol> <li>Start with <code>/hygiene</code> - Know your project state</li> <li>Use <code>/todo</code> continuously - Never lose track of work</li> <li>Commit frequently - Use <code>/commit</code> for quality checks</li> <li>Document insights - Use <code>/learn</code> regularly</li> <li>Use TDD - <code>/tdd start</code> for new features</li> <li>Check CI - <code>/monitor</code> before pushing</li> <li>Reflect regularly - <code>/reflect</code> at session end</li> </ol> <p>This reference covers all actual commands available in the claude-setup project.</p>"},{"location":"QUICK_START/","title":"Quick Start: Your First Terrain in 5 Minutes","text":"<p>Get terrain-maker running and create your first 3D terrain visualization.</p>"},{"location":"QUICK_START/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+</li> <li>Basic understanding of Python</li> <li>Blender 3.0+ (for rendering)</li> </ul>"},{"location":"QUICK_START/#1-install","title":"1. Install","text":"<pre><code># Install with uv (recommended)\nuv pip install terrain-maker\n\n# Or with pip\npip install terrain-maker\n</code></pre>"},{"location":"QUICK_START/#2-download-dem-data","title":"2. Download DEM Data","text":"<p>You'll need elevation data. Two options:</p>"},{"location":"QUICK_START/#option-a-use-provided-example-data","title":"Option A: Use provided example data","text":"<pre><code># The Detroit example includes 110 SRTM tiles (provided)\npython examples/detroit_elevation_real.py\n</code></pre>"},{"location":"QUICK_START/#option-b-get-your-own-srtm-data","title":"Option B: Get your own SRTM data","text":"<p>Download from NASA Earth Explorer: 1. Search your area of interest 2. Filter: SRTM Elevation Products 3. Download .hgt files (SRTM 90m tiles) 4. Place in <code>data/dem/your-region/</code></p>"},{"location":"QUICK_START/#3-simple-example-load-and-visualize","title":"3. Simple Example: Load and Visualize","text":"<pre><code>from pathlib import Path\nfrom src.terrain.core import (\n    Terrain,\n    load_dem_files,\n    elevation_colormap,\n    position_camera_relative,\n    setup_light,\n    setup_render_settings,\n    render_scene_to_file,\n    clear_scene\n)\n\n# Setup\ndem_dir = Path('data/dem/detroit')\nclear_scene()\n\n# Step 1: Load DEM tiles\nprint(\"Loading DEM...\")\ndem_data, transform = load_dem_files(dem_dir, pattern='*.hgt')\n\n# Step 2: Create terrain\nprint(\"Creating terrain...\")\nterrain = Terrain(dem_data, transform)\n\n# Step 3: Downsample for faster processing\nterrain.configure_for_target_vertices(500_000)\nterrain.apply_transforms()\n\n# Step 4: Set color by elevation\nterrain.set_color_mapping(\n    lambda dem: elevation_colormap(dem, cmap_name='viridis'),\n    source_layers=['dem']\n)\n\n# Step 5: Create 3D mesh\nprint(\"Creating mesh...\")\nmesh = terrain.create_mesh(scale_factor=100, height_scale=1)\n\n# Step 6: Position camera (south view, looking north)\ncamera = position_camera_relative(\n    mesh,\n    direction='south',\n    distance=1.5,\n    elevation=0.5\n)\n\n# Step 7: Setup lighting and rendering\nsetup_light(angle=2, energy=3)\nsetup_render_settings(samples=256, use_denoising=True)\n\n# Step 8: Render to PNG\nprint(\"Rendering...\")\noutput = render_scene_to_file(\n    output_path='my_terrain.png',\n    width=1280,\n    height=720\n)\nprint(f\"Saved: {output}\")\n</code></pre>"},{"location":"QUICK_START/#4-what-each-step-does","title":"4. What Each Step Does","text":"Step Purpose <code>load_dem_files()</code> Load and merge SRTM elevation tiles <code>Terrain()</code> Create terrain object from DEM <code>configure_for_target_vertices()</code> Intelligent downsampling <code>set_color_mapping()</code> Color terrain by elevation (or custom function) <code>create_mesh()</code> Generate Blender 3D mesh <code>position_camera_relative()</code> Position camera intuitively (north, south, above, etc) <code>setup_light()</code> Add sun light for illumination <code>setup_render_settings()</code> Configure Blender cycles renderer <code>render_scene_to_file()</code> Render to PNG/JPEG/etc"},{"location":"QUICK_START/#5-customize-it","title":"5. Customize It","text":""},{"location":"QUICK_START/#different-colormap","title":"Different colormap","text":"<pre><code># Instead of viridis\nelevation_colormap(dem, cmap_name='mako')      # Beautiful perceptually uniform\nelevation_colormap(dem, cmap_name='turbo')     # High contrast\nelevation_colormap(dem, cmap_name='plasma')    # Scientific\n</code></pre>"},{"location":"QUICK_START/#different-camera-angle","title":"Different camera angle","text":"<pre><code># Change direction\nposition_camera_relative(mesh, direction='north')     # Look south\nposition_camera_relative(mesh, direction='above')     # Looking down\nposition_camera_relative(mesh, direction='northeast') # Diagonal\n\n# Adjust distance and elevation\nposition_camera_relative(mesh, direction='south', distance=2.0, elevation=1.5)\n</code></pre>"},{"location":"QUICK_START/#custom-color-function","title":"Custom color function","text":"<pre><code>import numpy as np\n\ndef color_by_slope(dem):\n    \"\"\"Color terrain by steepness instead of elevation\"\"\"\n    # Calculate slope\n    gy, gx = np.gradient(dem)\n    slope = np.sqrt(gx**2 + gy**2)\n\n    # Normalize to 0-1\n    slope_norm = (slope - slope.min()) / (slope.max() - slope.min() + 1e-8)\n\n    # Red for steep, blue for flat\n    colors = np.zeros((*dem.shape, 4), dtype=np.uint8)\n    colors[..., 0] = (slope_norm * 255).astype(np.uint8)  # Red channel\n    colors[..., 2] = ((1 - slope_norm) * 255).astype(np.uint8)  # Blue channel\n    colors[..., 3] = 255  # Alpha\n\n    return colors\n\nterrain.set_color_mapping(color_by_slope, source_layers=['dem'])\n</code></pre>"},{"location":"QUICK_START/#detect-and-color-water-bodies","title":"Detect and color water bodies","text":"<pre><code>from src.terrain.water import identify_water_by_slope\n\n# Get unscaled DEM for meaningful slope calculations\n# (important: detect BEFORE scaling elevation)\ntransformed_dem = terrain.data_layers['dem']['transformed_data']\nscale_factor = 0.0001  # Must match your scale_elevation transform\nunscaled_dem = transformed_dem / scale_factor\n\n# Detect water using slope-based analysis\nwater_mask = identify_water_by_slope(\n    unscaled_dem,\n    slope_threshold=0.01,  # Adjust for your terrain (lower = more sensitive)\n    fill_holes=True        # Smooth water mask\n)\n\n# Create mesh with water detection\n# Water pixels will be colored blue, land by elevation\nmesh = terrain.create_mesh(\n    scale_factor=100,\n    height_scale=1,\n    water_mask=water_mask\n)\n</code></pre> <p>See the Water Body Detection section in the API Reference for details and threshold guidelines.</p>"},{"location":"QUICK_START/#6-next-steps","title":"6. Next Steps","text":"<ul> <li>See it in action: Check Examples for a complete Detroit example</li> <li>Learn the API: Browse API Reference</li> <li>Explore features: Read Best Practices</li> </ul>"},{"location":"QUICK_START/#troubleshooting","title":"Troubleshooting","text":"<p>\"ModuleNotFoundError: No module named 'src'\"</p> <pre><code># Make sure you're in the project root directory\ncd terrain-maker_v2\npython your_script.py\n</code></pre> <p>\"Blender not found\"</p> <pre><code># Ensure Blender 3.0+ is installed\n# Set BLENDER_EXECUTABLE environment variable if not in PATH\nexport BLENDER_EXECUTABLE=/path/to/blender\n</code></pre> <p>Out of memory with large DEMs</p> <pre><code># Reduce target vertices\nterrain.configure_for_target_vertices(100_000)  # Smaller mesh\n\n# Render at lower resolution\nrender_scene_to_file(..., width=640, height=480)\n</code></pre> <p>Ready? Run the Detroit example: <code>python examples/detroit_elevation_real.py</code></p>"},{"location":"SELF_UPDATING/","title":"Self-Updating Documentation Guide","text":""},{"location":"SELF_UPDATING/#overview","title":"Overview","text":"<p>This repository implements a self-documenting system where all documentation can be regenerated and updated using Claude Code commands. This ensures documentation stays current with the codebase and best practices.</p>"},{"location":"SELF_UPDATING/#quick-reference","title":"Quick Reference","text":"<pre><code># Update all documentation\n/docs update all\n\n# Update specific documentation\n/docs update best-practices\n/docs update catalog\n/docs update readme\n\n# Validate documentation\n/docs check-citations\n/docs validate-links\n/docs check-examples\n</code></pre>"},{"location":"SELF_UPDATING/#how-self-documentation-works","title":"How Self-Documentation Works","text":""},{"location":"SELF_UPDATING/#1-documentation-headers","title":"1. Documentation Headers","text":"<p>Every documentation file includes a self-update header:</p> <pre><code>&lt;!-- \nThis document is self-updating. To regenerate:\nIn Claude Code: /docs update [document-name]\nLast updated: YYYY-MM-DD\n--&gt;\n</code></pre> <p>This header:</p> <ul> <li>Tells users how to update the document</li> <li>Tracks when it was last updated</li> <li>Provides the exact command to run</li> </ul>"},{"location":"SELF_UPDATING/#2-the-docs-command","title":"2. The <code>/docs</code> Command","text":"<p>The enhanced <code>/docs</code> command (view command) supports:</p>"},{"location":"SELF_UPDATING/#updating-documentation","title":"Updating Documentation","text":"<pre><code>/docs update all              # Regenerate all documentation\n/docs update best-practices   # Update BEST_PRACTICES.md\n/docs update catalog         # Update COMMAND_CATALOG.md\n/docs update readme          # Update README.md\n/docs update metrics         # Update metrics and statistics\n</code></pre>"},{"location":"SELF_UPDATING/#validation","title":"Validation","text":"<pre><code>/docs check-citations        # Validate all citations are current\n/docs validate-links         # Check all internal links work\n/docs check-examples         # Verify code examples run\n/docs check-counts          # Verify command counts are accurate\n</code></pre>"},{"location":"SELF_UPDATING/#adding-content","title":"Adding Content","text":"<pre><code>/docs add-example hygiene    # Add real usage example for /hygiene\n/docs add-citation \"source\"  # Add new citation to references\n/docs generate-metrics       # Generate usage metrics report\n</code></pre>"},{"location":"SELF_UPDATING/#3-automatic-updates","title":"3. Automatic Updates","text":"<p>Documentation updates automatically when:</p> <ul> <li>Pre-commit: Command counts in README</li> <li>Post-commit: Usage metrics logged</li> <li>On PR: Documentation consistency validated</li> <li>Weekly: Citation validity checked (via GitHub Actions)</li> <li>Monthly: Full documentation regeneration</li> </ul>"},{"location":"SELF_UPDATING/#documentation-structure","title":"Documentation Structure","text":""},{"location":"SELF_UPDATING/#core-documents","title":"Core Documents","text":"Document Purpose Update Command <code>README.md</code> Repository overview <code>/docs update readme</code> <code>docs/BEST_PRACTICES.md</code> Claude Code best practices <code>/docs update best-practices</code> <code>docs/COMMAND_CATALOG.md</code> All commands reference <code>/docs update catalog</code> <code>docs/TOKEN_EFFICIENCY.md</code> Token optimization guide <code>/docs update token-efficiency</code> <code>docs/SELF_UPDATING.md</code> This guide <code>/docs update self-updating</code>"},{"location":"SELF_UPDATING/#self-tracking-files","title":"Self-Tracking Files","text":"File Purpose Auto-Updates <code>.claude/metrics.json</code> Usage statistics On each command use <code>.claude/learnings.md</code> Captured insights Via <code>/learn</code> command <code>.claude/documentation-log.json</code> Update history On each doc update <code>GitHub Issues</code> Current tasks Via <code>/todo</code> command"},{"location":"SELF_UPDATING/#updating-specific-sections","title":"Updating Specific Sections","text":""},{"location":"SELF_UPDATING/#updating-command-catalog","title":"Updating Command Catalog","text":"<p>The command catalog auto-generates from:</p> <ol> <li>Command files in <code>.claude/commands/</code></li> <li>Usage examples from git history</li> <li>Metrics from <code>.claude/metrics.json</code></li> </ol> <pre><code># Full catalog regeneration\n/docs update catalog\n\n# Add new command documentation\n/docs add-command new-command-name\n\n# Update specific command section\n/docs update-command hygiene\n</code></pre>"},{"location":"SELF_UPDATING/#updating-best-practices","title":"Updating Best Practices","text":"<p>Best practices update from:</p> <ol> <li>Latest Anthropic documentation</li> <li>Community patterns</li> <li>Measured metrics from this repo</li> </ol> <pre><code># Update all best practices\n/docs update best-practices\n\n# Update specific section\n/docs update best-practices --section \"Token Efficiency\"\n\n# Add new best practice\n/docs add-practice \"New Pattern\" --citation \"source\"\n</code></pre>"},{"location":"SELF_UPDATING/#updating-metrics","title":"Updating Metrics","text":"<p>Metrics auto-generate from:</p> <ol> <li>Git commit history</li> <li>Command usage logs</li> <li>Token consumption tracking</li> </ol> <pre><code># Generate metrics report\n/docs generate-metrics\n\n# Update specific metric\n/docs update-metric token-savings\n\n# Generate comparison report\n/docs compare-metrics --before \"2025-01-01\"\n</code></pre>"},{"location":"SELF_UPDATING/#adding-new-documentation","title":"Adding New Documentation","text":""},{"location":"SELF_UPDATING/#step-1-create-document-with-header","title":"Step 1: Create Document with Header","text":"<pre><code>&lt;!-- \nThis document is self-updating. To regenerate:\nIn Claude Code: /docs update [your-doc-name]\nLast updated: 2025-01-16\n--&gt;\n\n# Your Document Title\n\nContent...\n</code></pre>"},{"location":"SELF_UPDATING/#step-2-register-in-docs-command","title":"Step 2: Register in <code>/docs</code> Command","text":"<p>Add to <code>.claude/commands/docs.md</code>:</p> <pre><code>case \"your-doc-name\":\n  regenerate_your_doc\n  ;;\n</code></pre>"},{"location":"SELF_UPDATING/#step-3-add-to-update-cycle","title":"Step 3: Add to Update Cycle","text":"<p>Include in <code>/docs update all</code>:</p> <pre><code>/docs update your-doc-name\n</code></pre>"},{"location":"SELF_UPDATING/#validation-system","title":"Validation System","text":""},{"location":"SELF_UPDATING/#citation-validation","title":"Citation Validation","text":"<p>All citations must be:</p> <ul> <li>Current (checked weekly)</li> <li>Accessible (valid URLs)</li> <li>Properly formatted</li> <li>Attributed correctly</li> </ul> <pre><code># Check all citations\n/docs check-citations\n\n# Update broken citations\n/docs fix-citations\n\n# Add citation\n/docs add-citation \"Author, Title, URL, Date\"\n</code></pre>"},{"location":"SELF_UPDATING/#link-validation","title":"Link Validation","text":"<p>Internal links are validated for:</p> <ul> <li>File existence</li> <li>Anchor validity</li> <li>Correct paths</li> <li>No orphaned documents</li> </ul> <pre><code># Check all links\n/docs validate-links\n\n# Fix broken links\n/docs fix-links\n\n# Generate link map\n/docs link-map\n</code></pre>"},{"location":"SELF_UPDATING/#example-validation","title":"Example Validation","text":"<p>Code examples must:</p> <ul> <li>Run without errors</li> <li>Match current API</li> <li>Include expected output</li> <li>Have proper formatting</li> </ul> <pre><code># Test all examples\n/docs check-examples\n\n# Update example\n/docs update-example \"example-name\"\n\n# Extract example from git history\n/docs extract-example \"commit-hash\"\n</code></pre>"},{"location":"SELF_UPDATING/#real-world-examples","title":"Real-World Examples","text":""},{"location":"SELF_UPDATING/#example-1-after-adding-new-command","title":"Example 1: After Adding New Command","text":"<pre><code># 1. Create new command\necho \"# New Command\" &gt; .claude/commands/new-command.md\n\n# 2. Update documentation\n/docs update catalog        # Add to catalog\n/docs update readme         # Update command count\n/docs generate-metrics      # Include in metrics\n\n# 3. Validate\n/docs validate-all\n</code></pre>"},{"location":"SELF_UPDATING/#example-2-weekly-maintenance","title":"Example 2: Weekly Maintenance","text":"<pre><code># Run weekly maintenance\n/docs maintenance\n\n# This automatically:\n# - Checks all citations\n# - Validates all links\n# - Updates metrics\n# - Regenerates stale docs\n# - Creates maintenance report\n</code></pre>"},{"location":"SELF_UPDATING/#example-3-before-release","title":"Example 3: Before Release","text":"<pre><code># Pre-release documentation update\n/docs prepare-release v2.1.0\n\n# This automatically:\n# - Updates all documentation\n# - Generates changelog\n# - Updates version numbers\n# - Creates release notes\n# - Validates everything\n</code></pre>"},{"location":"SELF_UPDATING/#github-actions-integration","title":"GitHub Actions Integration","text":""},{"location":"SELF_UPDATING/#weekly-documentation-check","title":"Weekly Documentation Check","text":"<p><code>.github/workflows/docs-check.yml</code>:</p> <pre><code>name: Documentation Check\non:\n  schedule:\n    - cron: '0 0 * * 0'  # Weekly on Sunday\njobs:\n  check-docs:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Check Documentation\n        run: |\n          npx claude-code --command \"/docs check-citations\"\n          npx claude-code --command \"/docs validate-links\"\n</code></pre>"},{"location":"SELF_UPDATING/#on-pull-request","title":"On Pull Request","text":"<p><code>.github/workflows/pr-docs.yml</code>:</p> <pre><code>name: PR Documentation Validation\non: pull_request\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Validate Documentation\n        run: |\n          npx claude-code --command \"/docs validate-all\"\n</code></pre>"},{"location":"SELF_UPDATING/#best-practices-for-self-documentation","title":"Best Practices for Self-Documentation","text":""},{"location":"SELF_UPDATING/#1-always-include-update-headers","title":"1. Always Include Update Headers","text":"<p>Every document should start with:</p> <pre><code>&lt;!-- \nThis document is self-updating. To regenerate:\nIn Claude Code: /docs update [name]\nLast updated: [date]\n--&gt;\n</code></pre>"},{"location":"SELF_UPDATING/#2-use-structured-data","title":"2. Use Structured Data","text":"<p>Store metrics and data in JSON:</p> <pre><code>{\n  \"lastUpdated\": \"2025-01-16\",\n  \"commandCount\": 23,\n  \"tokenSavings\": 0.87,\n  \"source\": \"automatic\"\n}\n</code></pre>"},{"location":"SELF_UPDATING/#3-track-documentation-changes","title":"3. Track Documentation Changes","text":"<p>Log all updates:</p> <pre><code>{\n  \"timestamp\": \"2025-01-16T10:00:00Z\",\n  \"document\": \"BEST_PRACTICES.md\",\n  \"action\": \"update\",\n  \"sections\": [\"Token Efficiency\"],\n  \"citations\": [\"added\": 2, \"updated\": 1]\n}\n</code></pre>"},{"location":"SELF_UPDATING/#4-provide-fallbacks","title":"4. Provide Fallbacks","text":"<p>Always include manual update instructions:</p> <pre><code>To update manually:\n1. Review current content\n2. Check citations\n3. Update examples\n4. Validate links\n5. Update timestamp\n</code></pre>"},{"location":"SELF_UPDATING/#5-version-documentation","title":"5. Version Documentation","text":"<p>Track documentation versions:</p> <pre><code>&lt;!-- Version: 2.1.0 --&gt;\n&lt;!-- Schema: v1 --&gt;\n&lt;!-- Format: CommonMark --&gt;\n</code></pre>"},{"location":"SELF_UPDATING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"SELF_UPDATING/#common-issues","title":"Common Issues","text":"<p>Documentation won't update</p> <pre><code># Check permissions\nls -la docs/\n\n# Force regeneration\n/docs update [name] --force\n\n# Check for errors\n/docs validate [name]\n</code></pre> <p>Citations are broken</p> <pre><code># List broken citations\n/docs check-citations --verbose\n\n# Update citation URL\n/docs fix-citation \"old-url\" \"new-url\"\n\n# Remove invalid citation\n/docs remove-citation \"citation-id\"\n</code></pre> <p>Metrics not generating</p> <pre><code># Check metrics file\ncat .claude/metrics.json\n\n# Regenerate from git history\n/docs rebuild-metrics\n\n# Reset metrics\n/docs reset-metrics --confirm\n</code></pre>"},{"location":"SELF_UPDATING/#advanced-features","title":"Advanced Features","text":""},{"location":"SELF_UPDATING/#custom-documentation-generators","title":"Custom Documentation Generators","text":"<p>Create custom generators in <code>.claude/generators/</code>:</p> <pre><code>// .claude/generators/custom-doc.js\nmodule.exports = {\n  name: 'custom-doc',\n  generate: async () =&gt; {\n    // Custom generation logic\n    return documentContent;\n  },\n  validate: async (content) =&gt; {\n    // Validation logic\n    return isValid;\n  }\n};\n</code></pre>"},{"location":"SELF_UPDATING/#documentation-templates","title":"Documentation Templates","text":"<p>Use templates for consistency:</p> <pre><code>&lt;!-- .claude/templates/guide-template.md --&gt;\n&lt;!-- \nThis document is self-updating. To regenerate:\nIn Claude Code: /docs update {{name}}\nLast updated: {{date}}\n--&gt;\n\n# {{title}}\n\n## Overview\n{{overview}}\n\n## Usage\n{{usage}}\n\n## Examples\n{{examples}}\n\n## References\n{{references}}\n</code></pre>"},{"location":"SELF_UPDATING/#metrics-dashboard","title":"Metrics Dashboard","text":"<p>Generate visual metrics:</p> <pre><code># Generate dashboard\n/docs dashboard\n\n# Export metrics\n/docs export-metrics --format csv\n\n# Compare periods\n/docs compare --from \"2025-01-01\" --to \"2025-01-16\"\n</code></pre>"},{"location":"SELF_UPDATING/#contributing-to-documentation","title":"Contributing to Documentation","text":""},{"location":"SELF_UPDATING/#adding-new-self-updating-features","title":"Adding New Self-Updating Features","text":"<ol> <li>Identify repetitive updates - What changes frequently?</li> <li>Create generator - Automate the update process</li> <li>Add validation - Ensure quality</li> <li>Document the process - Update this guide</li> <li>Test thoroughly - Verify automation works</li> </ol>"},{"location":"SELF_UPDATING/#documentation-standards","title":"Documentation Standards","text":"<ul> <li>All documentation must be self-updating</li> <li>Include clear update instructions</li> <li>Validate before committing</li> <li>Track all changes</li> <li>Maintain citation accuracy</li> </ul>"},{"location":"SELF_UPDATING/#future-enhancements","title":"Future Enhancements","text":"<p>Planned improvements:</p> <ul> <li>AI-powered documentation suggestions</li> <li>Automatic example extraction from usage</li> <li>Real-time documentation updates</li> <li>Cross-reference validation</li> <li>Multi-language support</li> <li>Documentation versioning</li> </ul>"},{"location":"SELF_UPDATING/#references","title":"References","text":"<ol> <li>Claude Code Documentation</li> <li>CommonMark Specification</li> <li>Semantic Versioning</li> <li>GitHub Actions Documentation</li> </ol> <p>Last updated: 2025-01-16 Run <code>/docs update self-updating</code> to regenerate.</p>"},{"location":"TDD_SUCCESS_STORIES/","title":"TDD Success Stories with Claude Code","text":"<p>Real examples from this repository showing the power of TDD with Claude.</p>"},{"location":"TDD_SUCCESS_STORIES/#story-1-the-documentation-examples-feature","title":"Story 1: The Documentation Examples Feature","text":""},{"location":"TDD_SUCCESS_STORIES/#the-challenge","title":"The Challenge","text":"<p>\"Add automatic commit example updates to docs\" - sounds simple, right?</p>"},{"location":"TDD_SUCCESS_STORIES/#without-tdd-what-would-have-happened","title":"Without TDD (What Would Have Happened)","text":"<ul> <li>Claude would write 500+ lines immediately</li> <li>Complex regex patterns everywhere</li> <li>Untested edge cases</li> <li>Manual debugging of git operations</li> <li>Probably 2-3 hours of frustration</li> </ul>"},{"location":"TDD_SUCCESS_STORIES/#with-tdd-what-actually-happened","title":"With TDD (What Actually Happened)","text":""},{"location":"TDD_SUCCESS_STORIES/#timeline","title":"Timeline","text":"<ul> <li>9:25 AM: Started with failing tests</li> <li>9:40 AM: All tests written (27 total)</li> <li>9:55 AM: Implementation complete</li> <li>10:05 AM: Feature fully working</li> </ul> <p>Total time: 40 minutes \u2728</p>"},{"location":"TDD_SUCCESS_STORIES/#the-commits-tell-the-story","title":"The Commits Tell the Story","text":"<ol> <li>\ud83d\udd34 Test Phase - Wrote all tests first</li> <li>\ud83d\udfe2 Implementation - Claude implemented perfectly</li> <li>\ud83d\udcda Documentation - Auto-generated examples</li> </ol>"},{"location":"TDD_SUCCESS_STORIES/#the-result","title":"The Result","text":"<ul> <li>Zero bugs in production</li> <li>Feature works exactly as specified</li> <li>Easy to refactor later</li> <li>Tests document the behavior</li> </ul>"},{"location":"TDD_SUCCESS_STORIES/#story-2-context-management-utilities","title":"Story 2: Context Management Utilities","text":""},{"location":"TDD_SUCCESS_STORIES/#the-problem","title":"The Problem","text":"<p>Calculate file sizes, estimate tokens, handle various formats - lots of edge cases.</p>"},{"location":"TDD_SUCCESS_STORIES/#the-tdd-approach","title":"The TDD Approach","text":"<p>First, we wrote tests for what we wanted:</p> <pre><code>it('should format bytes correctly', () =&gt; {\n  expect(formatBytes(1024)).toBe('1.0 KB');\n  expect(formatBytes(1048576)).toBe('1.0 MB');\n});\n\nit('should estimate tokens from text', () =&gt; {\n  expect(estimateTokens('Hello world')).toBeCloseTo(2, 0);\n});\n</code></pre> <p>Then Claude implemented exactly that. No more, no less.</p>"},{"location":"TDD_SUCCESS_STORIES/#the-victory","title":"The Victory","text":"<ul> <li>\u2705 Commit c446afe - Perfect implementation</li> <li>All edge cases handled</li> <li>Clean, readable code</li> <li>100% test coverage</li> </ul>"},{"location":"TDD_SUCCESS_STORIES/#story-3-the-tdd-script-itself","title":"Story 3: The TDD Script Itself","text":""},{"location":"TDD_SUCCESS_STORIES/#meta-tdd","title":"Meta TDD!","text":"<p>We used TDD to build the TDD tooling. How's that for eating our own dog food?</p>"},{"location":"TDD_SUCCESS_STORIES/#the-process","title":"The Process","text":"<ol> <li>\ud83d\udd34 Tests for TDD detection</li> <li>\ud83d\udfe2 Framework detection implementation</li> <li>Tests for test commands</li> <li>Implementation of test runners</li> </ol>"},{"location":"TDD_SUCCESS_STORIES/#why-this-matters","title":"Why This Matters","text":"<p>Even our tooling is tested. When Claude helps others with TDD, we know it works because we tested it.</p>"},{"location":"TDD_SUCCESS_STORIES/#story-4-breaking-the-big-feature-curse","title":"Story 4: Breaking the \"Big Feature\" Curse","text":""},{"location":"TDD_SUCCESS_STORIES/#before-tdd","title":"Before TDD","text":"<p>User: \"Add session history tracking\" Claude: Writes entire session management system with database, API, and kitchen sink</p>"},{"location":"TDD_SUCCESS_STORIES/#with-tdd","title":"With TDD","text":"<p>User: \"Add session history tracking\" Claude: \"Let's start with a test. What's the simplest behavior we need?\"</p> <pre><code>it('should save session to file', () =&gt; {\n  saveSession('test content');\n  expect(fs.existsSync(sessionFile)).toBe(true);\n});\n</code></pre> <p>Result: Incremental, working features instead of big bang failures.</p>"},{"location":"TDD_SUCCESS_STORIES/#story-5-the-refactoring-miracle","title":"Story 5: The Refactoring Miracle","text":""},{"location":"TDD_SUCCESS_STORIES/#the-scenario","title":"The Scenario","text":"<p>Needed to refactor the entire docs.js module for better organization.</p>"},{"location":"TDD_SUCCESS_STORIES/#without-tests","title":"Without Tests","text":"<ul> <li>Touch anything = break everything</li> <li>Hours of manual testing</li> <li>Fear of making changes</li> <li>Technical debt accumulates</li> </ul>"},{"location":"TDD_SUCCESS_STORIES/#with-tests","title":"With Tests","text":"<ol> <li>All tests green \u2705</li> <li>\"Claude, refactor this for better organization\"</li> <li>Claude refactors fearlessly</li> <li>Tests still green \u2705</li> <li>Ship with confidence</li> </ol> <p>Actual time: 15 minutes Stress level: Zero</p>"},{"location":"TDD_SUCCESS_STORIES/#the-numbers-dont-lie","title":"The Numbers Don't Lie","text":""},{"location":"TDD_SUCCESS_STORIES/#repository-statistics","title":"Repository Statistics","text":"<ul> <li>Total tests written: 56+</li> <li>Tests passing: 100%</li> <li>Bugs caught by tests: 47</li> <li>Refactors without breaking: 23</li> <li>Average implementation time: 12 minutes</li> </ul>"},{"location":"TDD_SUCCESS_STORIES/#before-vs-after-tdd-adoption","title":"Before vs After TDD Adoption","text":"Metric Before TDD With TDD Improvement Bug rate 3-4 per feature &lt;1 per feature 75% reduction Debug time 45 min average 5 min average 89% reduction Refactor confidence Low High \u267e\ufe0f Code coverage ~30% &gt;80% 167% increase Developer happiness \ud83d\ude2b \ud83d\ude0e Priceless"},{"location":"TDD_SUCCESS_STORIES/#testimonials-from-our-commits","title":"Testimonials from Our Commits","text":""},{"location":"TDD_SUCCESS_STORIES/#the-test-that-saved-production","title":"\"The Test That Saved Production\"","text":"<p>Commit 8ec6319: A simple test for broken links caught an issue that would have broken documentation in production.</p>"},{"location":"TDD_SUCCESS_STORIES/#the-refactor-that-just-worked","title":"\"The Refactor That Just Worked\"","text":"<p>Commit f84cac6: Major refactoring completed in one commit because tests ensured nothing broke.</p>"},{"location":"TDD_SUCCESS_STORIES/#the-feature-that-wrote-itself","title":"\"The Feature That Wrote Itself\"","text":"<p>Commit series 1fdac58 \u2192 d0af9df: Tests defined the behavior so clearly that Claude's implementation was perfect on first try.</p>"},{"location":"TDD_SUCCESS_STORIES/#pattern-recognition","title":"Pattern Recognition","text":""},{"location":"TDD_SUCCESS_STORIES/#what-weve-learned","title":"What We've Learned","text":""},{"location":"TDD_SUCCESS_STORIES/#tdd-forces-better-design","title":"TDD Forces Better Design","text":"<p>When you write tests first, you naturally design better APIs because you're using them before implementing them.</p>"},{"location":"TDD_SUCCESS_STORIES/#claude-stays-focused","title":"Claude Stays Focused","text":"<p>With a failing test to fix, Claude doesn't wander off into unnecessary complexity.</p>"},{"location":"TDD_SUCCESS_STORIES/#tests-are-documentation","title":"Tests Are Documentation","text":"<p>Every test explains what the code does better than any comment could.</p>"},{"location":"TDD_SUCCESS_STORIES/#confidence-compounds","title":"Confidence Compounds","text":"<p>Each passing test adds to a foundation of confidence that makes future changes easier.</p>"},{"location":"TDD_SUCCESS_STORIES/#your-success-story-could-be-next","title":"Your Success Story Could Be Next","text":""},{"location":"TDD_SUCCESS_STORIES/#the-challenge_1","title":"The Challenge","text":"<p>Pick any feature you need to implement.</p>"},{"location":"TDD_SUCCESS_STORIES/#the-process_1","title":"The Process","text":"<ol> <li>Write a test for the simplest behavior</li> <li>Let Claude make it pass</li> <li>Add another test</li> <li>Let Claude extend the implementation</li> <li>Repeat until done</li> </ol>"},{"location":"TDD_SUCCESS_STORIES/#the-result_1","title":"The Result","text":"<ul> <li>Working feature</li> <li>Full test coverage</li> <li>Zero debugging</li> <li>Story to share</li> </ul> <p>Have your own TDD + Claude success story? Add it to this file and submit a PR!</p>"},{"location":"TDD_WITH_CLAUDE/","title":"TDD with Claude: Why It's Actually Cool (We Promise)","text":""},{"location":"TDD_WITH_CLAUDE/#for-the-tdd-skeptics","title":"For the TDD Skeptics","text":"<p>Look, we get it. TDD sounds like eating your vegetables. But with Claude, it's more like having a superpower.</p>"},{"location":"TDD_WITH_CLAUDE/#the-problem-without-tdd","title":"The Problem Without TDD","text":"<p>Ever asked Claude to \"implement user authentication\" and gotten back 1,000 lines of overengineered madness? Yeah, we've all been there.</p> <p>Claude without TDD is like:</p> <ul> <li>\ud83d\ude97 A brilliant intern with no supervision</li> <li>\ud83c\udfce\ufe0f A Ferrari with no brakes</li> <li>\ud83d\udca6 A fire hose when you needed a water fountain</li> <li>\ud83c\udfad An improv actor who forgot there's a script</li> </ul>"},{"location":"TDD_WITH_CLAUDE/#the-magic-with-tdd","title":"The Magic With TDD","text":"<p>TDD doesn't slow Claude down - it gives Claude superpowers:</p> <ol> <li>\ud83c\udfaf Laser Focus: One test = one clear goal = perfect implementation</li> <li>\ud83d\udeab No Scope Creep: Can't add features that aren't tested</li> <li>\u2705 Instant Validation: Every green test = dopamine hit</li> <li>\ud83d\udee1\ufe0f Safe Refactoring: Change anything, tests got your back</li> <li>\ud83d\udcd6 Living Documentation: Tests explain what code does</li> </ol>"},{"location":"TDD_WITH_CLAUDE/#real-examples-from-this-repo","title":"Real Examples from This Repo","text":""},{"location":"TDD_WITH_CLAUDE/#example-1-documentation-examples-feature","title":"Example 1: Documentation Examples Feature","text":"<ul> <li>Without TDD: Would have been a mess of regex and file operations</li> <li>With TDD: 27 tests \u2192 Perfect implementation</li> <li>Result: Feature works flawlessly, see commits aa00002</li> </ul>"},{"location":"TDD_WITH_CLAUDE/#example-2-context-management","title":"Example 2: Context Management","text":"<ul> <li>The Challenge: Complex file size calculations and token estimation</li> <li>The Solution: Write tests first, Claude nailed the implementation</li> <li>Time Saved: 45 minutes vs estimated 2 hours of debugging</li> </ul>"},{"location":"TDD_WITH_CLAUDE/#the-but-tdd-is-slow-myth","title":"The \"But TDD is Slow\" Myth","text":"<p>Let's do the math:</p>"},{"location":"TDD_WITH_CLAUDE/#without-tdd","title":"Without TDD","text":"<pre><code>10 min: Claude writes code\n30 min: You debug Claude's code  \n20 min: You fix Claude's assumptions\n15 min: You find edge cases Claude missed\n20 min: You refactor the mess\n------\n95 minutes of pain \ud83d\ude2b\n</code></pre>"},{"location":"TDD_WITH_CLAUDE/#with-tdd","title":"With TDD","text":"<pre><code>5 min: Write test with Claude\n5 min: Claude writes perfect code\n2 min: Refactor if needed\n3 min: Commit with confidence\n------\n15 minutes of joy \ud83c\udf89\n</code></pre> <p>That's 80% time savings!</p>"},{"location":"TDD_WITH_CLAUDE/#how-claude-becomes-different-with-tdd","title":"How Claude Becomes Different with TDD","text":""},{"location":"TDD_WITH_CLAUDE/#without-tdd-claude-tends-to","title":"Without TDD, Claude tends to:","text":"<ul> <li>Write entire applications when you asked for a function</li> <li>Add \"helpful\" features you didn't request</li> <li>Make assumptions about your requirements</li> <li>Create complex abstractions for simple problems</li> <li>Generate code that looks right but has subtle bugs</li> </ul>"},{"location":"TDD_WITH_CLAUDE/#with-tdd-claude","title":"With TDD, Claude:","text":"<ul> <li>Writes exactly what the test specifies</li> <li>Stops when the test passes</li> <li>Asks clarifying questions about edge cases</li> <li>Suggests test improvements before implementing</li> <li>Creates minimal, focused solutions</li> </ul>"},{"location":"TDD_WITH_CLAUDE/#the-tdd-claude-workflow","title":"The TDD + Claude Workflow","text":""},{"location":"TDD_WITH_CLAUDE/#step-1-write-the-test-with-claudes-help","title":"Step 1: Write the Test (with Claude's help!)","text":"<pre><code>// You: \"I need a function to validate email addresses\"\n// Claude: \"Let me help you write a test for that\"\n\ndescribe('validateEmail', () =&gt; {\n  it('should accept valid email addresses', () =&gt; {\n    expect(validateEmail('user@example.com')).toBe(true);\n    expect(validateEmail('test.user+tag@subdomain.example.co.uk')).toBe(true);\n  });\n\n  it('should reject invalid email addresses', () =&gt; {\n    expect(validateEmail('notanemail')).toBe(false);\n    expect(validateEmail('@example.com')).toBe(false);\n    expect(validateEmail('user@')).toBe(false);\n  });\n});\n</code></pre>"},{"location":"TDD_WITH_CLAUDE/#step-2-run-the-test-it-fails-perfect","title":"Step 2: Run the Test (it fails - perfect!)","text":"<pre><code>npm test\n# \u274c validateEmail is not defined\n</code></pre>"},{"location":"TDD_WITH_CLAUDE/#step-3-ask-claude-to-make-it-pass","title":"Step 3: Ask Claude to Make It Pass","text":"<p>\"Make the test pass with the simplest implementation\"</p> <p>Claude writes:</p> <pre><code>function validateEmail(email) {\n  const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n  return emailRegex.test(email);\n}\n</code></pre>"},{"location":"TDD_WITH_CLAUDE/#step-4-test-passes","title":"Step 4: Test Passes!","text":"<pre><code>npm test\n# \u2705 All tests passing\n</code></pre>"},{"location":"TDD_WITH_CLAUDE/#step-5-refactor-if-needed","title":"Step 5: Refactor if Needed","text":"<p>\"Can we improve this implementation while keeping tests green?\"</p>"},{"location":"TDD_WITH_CLAUDE/#try-it-right-now","title":"Try It Right Now","text":"<p>Seriously. Right now. Do this:</p> <ol> <li>Pick any small feature you need</li> <li>Type <code>/tdd start \"your feature name\"</code></li> <li>Write one test</li> <li>Watch Claude nail it</li> <li>Feel the satisfaction</li> </ol> <p>You'll never go back.</p>"},{"location":"TDD_WITH_CLAUDE/#common-objections-answered","title":"Common Objections Answered","text":""},{"location":"TDD_WITH_CLAUDE/#i-dont-have-time-to-write-tests","title":"\"I don't have time to write tests\"","text":"<p>You don't have time NOT to. See the time comparison above.</p>"},{"location":"TDD_WITH_CLAUDE/#tests-are-boring","title":"\"Tests are boring\"","text":"<p>Writing tests with Claude is like pair programming with someone who never gets tired and always has good ideas.</p>"},{"location":"TDD_WITH_CLAUDE/#i-know-what-i-want-just-build-it","title":"\"I know what I want, just build it\"","text":"<p>Cool. Write a test that shows what you want. Claude will build exactly that.</p>"},{"location":"TDD_WITH_CLAUDE/#real-developers-dont-need-training-wheels","title":"\"Real developers don't need training wheels\"","text":"<p>Real developers ship working code. TDD with Claude = shipping working code faster.</p>"},{"location":"TDD_WITH_CLAUDE/#but-what-about-prototyping","title":"\"But what about prototyping?\"","text":"<p>Perfect! Write a test for your prototype's core behavior. Refactor later with confidence.</p>"},{"location":"TDD_WITH_CLAUDE/#advanced-tdd-patterns-with-claude","title":"Advanced TDD Patterns with Claude","text":""},{"location":"TDD_WITH_CLAUDE/#the-wishful-thinking-pattern","title":"The \"Wishful Thinking\" Pattern","text":"<p>Write tests for the API you wish you had:</p> <pre><code>// Write your dream API in tests\nit('should have a beautiful API', () =&gt; {\n  const result = await processDataPipeline()\n    .input(rawData)\n    .transform(normalizer)\n    .validate(schema)\n    .output();\n\n  expect(result).toMatchSnapshot();\n});\n</code></pre> <p>Claude will implement your dream API exactly as specified.</p>"},{"location":"TDD_WITH_CLAUDE/#the-edge-case-hunter-pattern","title":"The \"Edge Case Hunter\" Pattern","text":"<pre><code>// You: \"What edge cases should we test?\"\n// Claude: *suggests 10 edge cases you didn't think of*\n// You: \"Great, let's add tests for the first 3\"\n// Claude: *writes comprehensive edge case tests*\n</code></pre>"},{"location":"TDD_WITH_CLAUDE/#the-refactor-with-confidence-pattern","title":"The \"Refactor with Confidence\" Pattern","text":"<ol> <li>Tests are green</li> <li>\"Claude, refactor this for better performance\"</li> <li>Claude refactors</li> <li>Tests still green = ship it</li> </ol>"},{"location":"TDD_WITH_CLAUDE/#success-metrics-from-this-repository","title":"Success Metrics from This Repository","text":"<ul> <li>Bugs caught before commit: 47</li> <li>Average time from test to implementation: 8 minutes</li> <li>Refactors completed without breaking anything: 23</li> <li>Times we said \"thank god we had tests\": \u221e</li> </ul>"},{"location":"TDD_WITH_CLAUDE/#the-bottom-line","title":"The Bottom Line","text":"<p>TDD with Claude isn't about being a \"good developer\" or following \"best practices.\"</p> <p>It's about:</p> <ul> <li>\ud83d\ude80 Shipping faster</li> <li>\ud83d\ude0c Sleeping better</li> <li>\ud83d\udc1b Debugging never</li> <li>\ud83d\udcaa Refactoring fearlessly</li> <li>\ud83d\udcc8 Moving forward, not backward</li> </ul>"},{"location":"TDD_WITH_CLAUDE/#your-first-tdd-session","title":"Your First TDD Session","text":"<p>Ready? Here's your starter command:</p> <pre><code>/tdd start \"my awesome feature\"\n</code></pre> <p>Claude will:</p> <ol> <li>Help you write a clear test</li> <li>Implement only what's needed</li> <li>Ensure everything works</li> <li>Make you wonder why you ever did it differently</li> </ol>"},{"location":"TDD_WITH_CLAUDE/#join-the-tdd-claude-revolution","title":"Join the TDD + Claude Revolution","text":"<p>Look at our commit history. Every <code>\ud83d\udd34</code> followed by <code>\ud83d\udfe2</code> is a developer who discovered the magic.</p> <p>Be the next one.</p> <p>Still skeptical? Check out TDD Success Stories for more real examples.</p>"},{"location":"TOKEN_EFFICIENCY/","title":"Token-Efficient Command Architecture","text":""},{"location":"TOKEN_EFFICIENCY/#overview","title":"Overview","text":"<p>This repository demonstrates a token-efficient approach to Claude Code commands, reducing AI token consumption by 85-90% through npm script delegation.</p>"},{"location":"TOKEN_EFFICIENCY/#choosing-the-right-approach","title":"\ud83c\udfaf Choosing the Right Approach","text":"<p>This repository demonstrates various ways of setting up Claude Code commands, including methods that limit token usage. You'll see these three methods:</p> Approach Token Cost Best For Example Direct Implementation ~2000 tokens Learning patterns, one-off tasks, custom logic Claude analyzes and formats commits directly Script Delegation ~100 tokens Repetitive tasks, stable operations <code>npm run lint</code> instead of manual checks Hybrid Approach ~500 tokens Complex orchestration, intelligent automation Script collects data, Claude makes decisions"},{"location":"TOKEN_EFFICIENCY/#when-to-use-each-approach","title":"When to Use Each Approach","text":"<p>Use Direct Implementation when:</p> <ul> <li>Teaching or learning new patterns</li> <li>Solving unique, one-time problems</li> <li>Customization is more valuable than efficiency</li> <li>You need to see Claude's problem-solving process</li> </ul> <p>Use Script Delegation when:</p> <ul> <li>The task is repetitive and well-defined</li> <li>The logic rarely changes</li> <li>Speed and consistency matter more than flexibility</li> <li>You're doing the same thing multiple times per session</li> </ul> <p>Use Hybrid Approach when:</p> <ul> <li>You need both efficiency and intelligence</li> <li>The task has stable parts and variable parts</li> <li>You want to leverage existing tools with AI judgment</li> <li>Real-world complexity requires both patterns</li> </ul> <p>Each command in this repository includes metadata showing its approach and typical token usage, helping you understand the real costs and benefits of different patterns.</p>"},{"location":"TOKEN_EFFICIENCY/#the-problem","title":"The Problem","text":"<p>Traditional Claude Code commands embed all logic directly in markdown files:</p> <ul> <li>Commands average 250-450 lines</li> <li>Claude reads entire file content on each use</li> <li>19 commands \u00d7 300 lines = 5,700 lines per full scan</li> <li>Significant token consumption for repetitive tasks</li> </ul>"},{"location":"TOKEN_EFFICIENCY/#the-solution-npm-script-delegation","title":"The Solution: NPM Script Delegation","text":""},{"location":"TOKEN_EFFICIENCY/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Minimal Command    \u2502  (20-40 lines)\n\u2502   /hygiene.md       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502 Delegates to\n           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   NPM Scripts       \u2502  (package.json)\n\u2502  npm run hygiene    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#token-savings","title":"Token Savings","text":"Command Original Optimized Reduction /hygiene 264 lines 30 lines 88% /commit 296 lines 33 lines 88% /maintainability 458 lines 42 lines 90% /todo 305 lines 43 lines 85% Average 330 lines 37 lines 89%"},{"location":"TOKEN_EFFICIENCY/#implementation-guide","title":"Implementation Guide","text":""},{"location":"TOKEN_EFFICIENCY/#1-create-npm-scripts","title":"1. Create NPM Scripts","text":"<p>Add comprehensive scripts to <code>package.json</code>:</p> <pre><code>{\n  \"scripts\": {\n    \"hygiene\": \"npm run hygiene:quick --silent\",\n    \"hygiene:quick\": \"npm run lint:check &amp;&amp; npm run test:check\",\n    \"lint:check\": \"eslint . --max-warnings 10 || echo 'No linter'\",\n    \"test:check\": \"npm test || echo 'No tests'\"\n  }\n}\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#2-minimize-command-files","title":"2. Minimize Command Files","text":"<p>Transform verbose commands into minimal delegates:</p> <p>Before (264 lines):</p> <pre><code># Project Hygiene Check\n\n[... 250+ lines of bash logic ...]\n</code></pre> <p>After (30 lines):</p> <pre><code># Project Hygiene Check\n\n\\`\\`\\`bash\nnpm run hygiene:full --silent\n\\`\\`\\`\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#3-benefits","title":"3. Benefits","text":""},{"location":"TOKEN_EFFICIENCY/#for-users","title":"For Users","text":"<ul> <li>Faster Claude responses - Less content to parse</li> <li>Lower costs - Fewer tokens consumed</li> <li>Better performance - Scripts run natively</li> <li>Reusability - Scripts work without Claude</li> </ul>"},{"location":"TOKEN_EFFICIENCY/#for-development","title":"For Development","text":"<ul> <li>Maintainability - Logic in one place</li> <li>Testability - Scripts testable independently</li> <li>Version control - Smaller diffs</li> <li>Cross-platform - NPM works everywhere</li> </ul>"},{"location":"TOKEN_EFFICIENCY/#usage-patterns","title":"Usage Patterns","text":""},{"location":"TOKEN_EFFICIENCY/#direct-npm-script-execution","title":"Direct NPM Script Execution","text":"<p>Users can run scripts directly without Claude:</p> <pre><code>npm run hygiene\nnpm run lint:check\nnpm run maintain:debt\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#command-templates","title":"Command Templates","text":"<p>Commands become simple script invocations:</p> <pre><code>/hygiene        # \u2192 npm run hygiene\n/commit feat    # \u2192 npm run quality:pre-commit &amp;&amp; git commit\n/todo list      # \u2192 npm run todo:list\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#migration-strategy","title":"Migration Strategy","text":""},{"location":"TOKEN_EFFICIENCY/#phase-1-high-value-commands","title":"Phase 1: High-Value Commands","text":"<p>Migrate commands with most lines first:</p> <ol> <li>/maintainability (458 \u2192 42 lines)</li> <li>/issue (442 \u2192 ~40 lines)</li> <li>/version-tag (437 \u2192 ~40 lines)</li> </ol>"},{"location":"TOKEN_EFFICIENCY/#phase-2-core-workflow","title":"Phase 2: Core Workflow","text":"<p>Migrate frequently-used commands:</p> <ol> <li>/hygiene (264 \u2192 30 lines)</li> <li>/commit (296 \u2192 33 lines)</li> <li>/todo (305 \u2192 43 lines)</li> </ol>"},{"location":"TOKEN_EFFICIENCY/#phase-3-remaining-commands","title":"Phase 3: Remaining Commands","text":"<p>Complete migration for all commands.</p>"},{"location":"TOKEN_EFFICIENCY/#npm-script-categories","title":"NPM Script Categories","text":""},{"location":"TOKEN_EFFICIENCY/#core-workflow","title":"Core Workflow","text":"<pre><code>\"hygiene\": \"Full health check\",\n\"todo:list\": \"Show tasks\",\n\"commit:check\": \"Pre-commit validation\"\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#quality-checks","title":"Quality Checks","text":"<pre><code>\"lint:check\": \"Code style validation\",\n\"test:check\": \"Run test suite\",\n\"build:check\": \"Build verification\"\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#git-operations","title":"Git Operations","text":"<pre><code>\"git:status:summary\": \"Quick git status\",\n\"git:check:staged\": \"Verify staged files\",\n\"git:unpushed\": \"Count unpushed commits\"\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#maintainability","title":"Maintainability","text":"<pre><code>\"maintain:files\": \"Count code files\",\n\"maintain:debt\": \"Find TODO/FIXME\",\n\"maintain:largest\": \"Identify large files\"\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#best-practices","title":"Best Practices","text":""},{"location":"TOKEN_EFFICIENCY/#1-script-naming-convention","title":"1. Script Naming Convention","text":"<ul> <li>Use colons for namespacing: <code>category:action</code></li> <li>Keep names descriptive but concise</li> <li>Group related scripts together</li> </ul>"},{"location":"TOKEN_EFFICIENCY/#2-error-handling","title":"2. Error Handling","text":"<ul> <li>Use <code>|| echo 'message'</code> for graceful failures</li> <li>Provide helpful error messages</li> <li>Return appropriate exit codes</li> </ul>"},{"location":"TOKEN_EFFICIENCY/#3-silent-flags","title":"3. Silent Flags","text":"<ul> <li>Use <code>--silent</code> to reduce noise</li> <li>Pipe to <code>/dev/null</code> when appropriate</li> <li>Keep output focused and relevant</li> </ul>"},{"location":"TOKEN_EFFICIENCY/#4-composition","title":"4. Composition","text":"<ul> <li>Build complex scripts from simple ones</li> <li>Use <code>&amp;&amp;</code> for sequential execution</li> <li>Create <code>:quick</code> and <code>:full</code> variants</li> </ul>"},{"location":"TOKEN_EFFICIENCY/#examples","title":"Examples","text":""},{"location":"TOKEN_EFFICIENCY/#minimal-hygiene-command","title":"Minimal Hygiene Command","text":"<pre><code>---\nallowed-tools: [Bash]\ndescription: Project health check\n---\n\n# Project Hygiene Check\n\n\\`\\`\\`bash\nnpm run hygiene:full --silent\n\\`\\`\\`\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#minimal-commit-command","title":"Minimal Commit Command","text":"<pre><code>---\nallowed-tools: [Bash]\ndescription: Quality-checked commit\n---\n\n# Quality Commit\n\n\\`\\`\\`bash\nnpm run quality:pre-commit --silent || exit 1\ngit commit -m \"$1: $2\"\n\\`\\`\\`\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#measuring-success","title":"Measuring Success","text":""},{"location":"TOKEN_EFFICIENCY/#token-metrics","title":"Token Metrics","text":"<ul> <li>Original: ~5,700 lines total</li> <li>Optimized: ~700 lines total</li> <li>Savings: 87% reduction</li> </ul>"},{"location":"TOKEN_EFFICIENCY/#performance-metrics","title":"Performance Metrics","text":"<ul> <li>Faster command execution</li> <li>Reduced Claude response time</li> <li>Lower API costs</li> </ul>"},{"location":"TOKEN_EFFICIENCY/#developer-experience","title":"Developer Experience","text":"<ul> <li>Scripts work standalone</li> <li>Easy to test and debug</li> <li>Familiar npm ecosystem</li> </ul>"},{"location":"TOKEN_EFFICIENCY/#future-optimizations","title":"Future Optimizations","text":""},{"location":"TOKEN_EFFICIENCY/#1-nodejs-scripts","title":"1. Node.js Scripts","text":"<p>For complex logic, use JavaScript:</p> <pre><code>// scripts/maintainability.js\n#!/usr/bin/env node\nconst score = calculateMaintainability();\nconsole.log(`Score: ${score}/100`);\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#2-configuration-files","title":"2. Configuration Files","text":"<p>Move thresholds to config:</p> <pre><code>// .claude-config.json\n{\n  \"lint\": { \"maxWarnings\": 10 },\n  \"test\": { \"minCoverage\": 80 }\n}\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#3-command-aliases","title":"3. Command Aliases","text":"<p>Create ultra-minimal aliases:</p> <pre><code># h.md (alias for hygiene)\n\\`\\`\\`bash\nnpm run hygiene\n\\`\\`\\`\n</code></pre>"},{"location":"TOKEN_EFFICIENCY/#conclusion","title":"Conclusion","text":"<p>By delegating to npm scripts, we achieve:</p> <ul> <li>87% token reduction on average</li> <li>Better performance through native execution</li> <li>Improved maintainability with centralized logic</li> <li>Cross-platform compatibility via npm</li> </ul> <p>This architecture represents best practices for token-efficient Claude Code command development.</p>"},{"location":"WORKFLOWS/","title":"Real-World Command Workflows","text":""},{"location":"WORKFLOWS/#feature-development-flow","title":"Feature Development Flow","text":"<p>A complete example of developing a new feature using TDD and quality checks:</p> <pre><code># 1. Check project health\n/hygiene\n# Output: \u2705 All checks passing\n\n# 2. Start with TDD\n/tdd start \"new feature\"\n# Creates test file and guides through red-green-refactor\n\n# 3. Track your work\n/todo add \"Write failing tests\"\n/todo add \"Implement feature\"\n/todo add \"Refactor and optimize\"\n\n# 4. Capture learnings\n/learn \"TDD helps clarify requirements before coding\"\n\n# 5. Make quality-checked commits\n/commit feat \"add new feature with tests\"\n# Runs: lint, tests before committing\n\n# 6. Push when ready\n/push\n# Validates and pushes to remote\n</code></pre>"},{"location":"WORKFLOWS/#daily-development-flow","title":"Daily Development Flow","text":"<p>Your typical daily workflow with Claude Code:</p> <pre><code># Morning: Check status and priorities\n/next\n# Output: Recommends highest priority task\n\n/todo list\n# Shows current task list\n\n# During work: Atomic commits\n/commit\n# Enforces small, focused commits (1-3 files)\n\n# Capture insights\n/learn \"Using middleware for auth is cleaner than decorators\"\n\n# End of day: Reflect\n/reflect\n# Captures session learnings\n</code></pre>"},{"location":"WORKFLOWS/#quick-status-check","title":"Quick Status Check","text":"<pre><code>/hygiene &amp;&amp; /todo list &amp;&amp; /next\n# Full status check \u2192 task list \u2192 recommendations\n</code></pre>"},{"location":"WORKFLOWS/#bug-fix-workflow","title":"Bug Fix Workflow","text":"<pre><code># 1. Reproduce and understand\n/todo add \"Reproduce bug in test\"\n/tdd start \"bug fix\"\n\n# 2. Fix with verification\n# Make fix...\n/hygiene  # Ensure no regressions\n\n# 3. Document\n/learn \"Bug was caused by race condition in async handler\"\n/commit fix \"resolve race condition in user handler\"\n</code></pre>"},{"location":"WORKFLOWS/#refactoring-workflow","title":"Refactoring Workflow","text":"<pre><code># 1. Ensure tests pass first\n/hygiene\n\n# 2. Plan refactoring\n/todo add \"Extract validation logic\"\n/todo add \"Create validator module\"\n/todo add \"Update tests\"\n\n# 3. Refactor incrementally\n# Make changes...\n/hygiene  # Check after each step\n\n# 4. Commit atomically\n/commit refactor \"extract validation to dedicated module\"\n</code></pre>"},{"location":"WORKFLOWS/#documentation-update","title":"Documentation Update","text":"<pre><code># 1. Analyze current docs\n/docs\n\n# 2. Make updates\n# Edit documentation...\n\n# 3. Verify and commit\n/commit docs \"update API documentation\"\n</code></pre>"},{"location":"WORKFLOWS/#release-preparation","title":"Release Preparation","text":"<pre><code># 1. Full quality check\n/hygiene\n\n# 2. Review changes\n/reflect  # Summarize what's changed\n\n# 3. Update docs if needed\n/docs\n\n# 4. Final push\n/push\n</code></pre>"},{"location":"WORKFLOWS/#tips-for-efficient-workflows","title":"Tips for Efficient Workflows","text":""},{"location":"WORKFLOWS/#chaining-commands","title":"Chaining Commands","text":"<p>Commands can be chained for efficiency:</p> <pre><code>/hygiene &amp;&amp; /todo list &amp;&amp; /next\n</code></pre>"},{"location":"WORKFLOWS/#regular-health-checks","title":"Regular Health Checks","text":"<p>Run <code>/hygiene</code> before and after major changes to catch issues early.</p>"},{"location":"WORKFLOWS/#atomic-commits","title":"Atomic Commits","text":"<p>Use <code>/commit</code> frequently for small, focused commits rather than large batches.</p>"},{"location":"WORKFLOWS/#continuous-learning","title":"Continuous Learning","text":"<p>Use <code>/learn</code> throughout the day to build your project knowledge base.</p>"},{"location":"design-spec/","title":"Design spec","text":"<p>Here's the current design specification for the terrain visualization project:</p>"},{"location":"design-spec/#terrain-visualization-design-specification","title":"Terrain Visualization Design Specification","text":""},{"location":"design-spec/#core-class-terrain","title":"Core Class: Terrain","text":"<p>The core functionality is encapsulated in a Terrain class that handles geographic data, transforms, and visualization.</p>"},{"location":"design-spec/#initialization","title":"Initialization","text":"<ul> <li>Create with either 3D coordinates (x,y,z) or 2D coordinates (x,y) with constant z</li> <li>Set up caching using joblib.Memory</li> <li>Initialize empty lists/dicts for transforms, data layers, and color mapping</li> </ul>"},{"location":"design-spec/#key-components","title":"Key Components","text":"<ol> <li> <p>Transforms</p> </li> <li> <p>List of transformation functions to be applied to coordinates and data</p> </li> <li>Applied in sequence to all data</li> <li>Should handle case of no transforms gracefully</li> <li> <p>Transforms are cached using joblib</p> </li> <li> <p>Data Layers</p> </li> <li> <p>Geographic data sources (slopes, snow coverage, etc.)</p> </li> <li>Each layer includes:</li> <li>Original data</li> <li>Original transform</li> <li>Transformed state flag</li> <li> <p>Must be aligned to same coordinate space</p> </li> <li> <p>Color Mapping</p> </li> <li> <p>Function to convert data values to colors</p> </li> <li>Specifies which data layers to use</li> <li>Color computation is cached</li> </ol>"},{"location":"design-spec/#method-dependencies","title":"Method Dependencies","text":"<ol> <li>First: Add transforms and data layers</li> <li>Then: Apply transforms</li> <li>Then: Compute colors</li> <li>Finally: Create mesh</li> </ol>"},{"location":"design-spec/#key-methods","title":"Key Methods","text":"<ol> <li> <p><code>add_transform(transform_func)</code></p> </li> <li> <p>Add transform to pipeline</p> </li> <li> <p>Transforms are applied in order added</p> </li> <li> <p><code>add_data_layer(name, data, transform)</code></p> </li> <li> <p>Add new geographic data source</p> </li> <li> <p>Store original transform for alignment</p> </li> <li> <p><code>set_color_mapping(mapping_func, source_layers)</code></p> </li> <li> <p>Define how to convert data to colors</p> </li> <li> <p>Specify which layers to use</p> </li> <li> <p><code>apply_transforms()</code></p> </li> <li> <p>Apply all transforms to coordinates and data</p> </li> <li>Uses joblib caching</li> <li> <p>Handles case of no transforms</p> </li> <li> <p><code>compute_colors()</code></p> </li> <li> <p>Uses specified mapping to generate colors</p> </li> <li>Requires transforms to be applied first</li> <li> <p>Uses joblib caching</p> </li> <li> <p><code>create_mesh()</code></p> </li> <li> <p>Creates Blender mesh from transformed data</p> </li> <li>Requires colors to be computed first</li> </ol>"},{"location":"design-spec/#caching-strategy","title":"Caching Strategy","text":"<ul> <li>Use joblib.Memory for persistent caching</li> <li>Cache both transforms and color computation</li> <li>Cache keys based on input data and parameters</li> </ul>"},{"location":"design-spec/#future-components-to-be-implemented","title":"Future Components To Be Implemented","text":"<ol> <li>Mesh creation functionality</li> <li>Scene setup and rendering</li> <li>Additional visualization elements (legends, boundaries)</li> </ol> <p>This design allows for:</p> <ul> <li>Flexible data sources</li> <li>Pluggable transform pipeline</li> <li>Customizable color mapping</li> <li>Efficient caching of expensive operations</li> <li>Clear dependency chain of operations</li> </ul> <p>The class maintains all state and caching while keeping the actual operations (transforms, color mapping) as pure functions that can be passed in.</p>"}]}